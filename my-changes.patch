diff --git a/docs/api_logging_rules.md b/.claude/rules/api-logging.md
similarity index 92%
rename from docs/api_logging_rules.md
rename to .claude/rules/api-logging.md
index 55da764e..2c9be8d8 100644
--- a/docs/api_logging_rules.md
+++ b/.claude/rules/api-logging.md
@@ -1,16 +1,27 @@
+---
+paths: src/app/api/**/*.ts, src/pages/api/**/*.ts
+---
+
 # API Logging Rules
 
 Guidelines for logging, error handling, and Sentry integration in API routes.
 
-## App Router Authentication (Recommended)
+## App Router Handler Factories (Recommended)
+
+Four handler factories in `/src/lib/api-helpers/create-handler.ts`:
 
-### Using `createSupabasePostApiHandler` (Preferred)
+| Function                       | Auth     | Method | Use Case               |
+| ------------------------------ | -------- | ------ | ---------------------- |
+| `createGetApiHandler`          | Public   | GET    | Public read endpoints  |
+| `createPostApiHandler`         | Public   | POST   | Public write endpoints |
+| `createGetApiHandlerWithAuth`  | Required | GET    | Authenticated reads    |
+| `createPostApiHandlerWithAuth` | Required | POST   | Authenticated writes   |
 
-Use the HOF wrapper for cleaner API routes with automatic auth, validation, and error handling:
+### Authenticated POST Example
 
 ```typescript
 import { z } from "zod";
-import { createSupabasePostApiHandler } from "@/lib/api-helpers/create-handler";
+import { createPostApiHandlerWithAuth } from "@/lib/api-helpers/create-handler";
 import { apiError, apiWarn } from "@/lib/api-helpers/response";
 
 const ROUTE = "endpoint-name";
@@ -24,7 +35,7 @@ const OutputSchema = z.object({
 	name: z.string(),
 });
 
-export const POST = createSupabasePostApiHandler({
+export const POST = createPostApiHandlerWithAuth({
 	route: ROUTE,
 	inputSchema: InputSchema,
 	outputSchema: OutputSchema,
@@ -53,7 +64,7 @@ export const POST = createSupabasePostApiHandler({
 });
 ```
 
-**`createSupabasePostApiHandler` config:**
+**Handler factory config:**
 
 | Prop           | Type        | Description                            |
 | -------------- | ----------- | -------------------------------------- |
diff --git a/docs/code_style_conventions.md b/.claude/rules/code-style.md
similarity index 96%
rename from docs/code_style_conventions.md
rename to .claude/rules/code-style.md
index c7cb3108..2864ceaa 100644
--- a/docs/code_style_conventions.md
+++ b/.claude/rules/code-style.md
@@ -28,12 +28,16 @@ This is a CRITICAL step that must NEVER be skipped when working on any code-rela
 
 ## React/Next.js Patterns
 
-- **Exports**: Named exports only (no default exports) (no array function for the exports)
+- **Exports**: Named exports preferred
 
   ```typescript
   export function ComponentName () { ... }
   ```
 
+  **Exceptions** (default exports allowed):
+  - Next.js pages (`page.tsx`, `layout.tsx`, `error.tsx`)
+  - Legacy query/mutation hooks (migrating to named exports)
+
 - **Component Structure**:
   - Server components by default
   - Client components explicitly marked with `"use client"`
@@ -160,8 +164,6 @@ Common cases where 'useEffect is NOT needed:
 - **Hooks**: Call hooks at top level, specify all dependencies
 - **Error Boundaries**: Handle errors gracefully with error boundaries
 
-See [`docs/frontend_rules.md`](./frontend_rules.md) for full frontend details.
-
 ## Git Conventions
 
 - **Commits**: Conventional commits format (enforced by commitlint)
diff --git a/docs/frontend_rules.md b/.claude/rules/frontend.md
similarity index 61%
rename from docs/frontend_rules.md
rename to .claude/rules/frontend.md
index 0d7582c6..573a11d8 100644
--- a/docs/frontend_rules.md
+++ b/.claude/rules/frontend.md
@@ -1,6 +1,10 @@
+---
+paths: src/**/*.{ts,tsx}
+---
+
 # Frontend Rules
 
-This document contains comprehensive accessibility and code quality rules for frontend development in this Next.js/React project.
+Comprehensive accessibility and code quality rules for frontend development.
 
 ## Accessibility Rules
 
@@ -65,12 +69,6 @@ This document contains comprehensive accessibility and code quality rules for fr
 - Always use modern CSS features including nesting, custom properties, container queries, subgrid, and color functions.
 - Always use Tailwind v4. Never use Tailwind v3.
 
-### Development Tools and Frameworks
-
-- Always use Vite when a build tool is needed.
-- Always use Biome. Never use ESLint or Prettier unless explicitly instructed.
-- Always use a framework that supports the standard Web Request and Response interface. Never use Express.
-
 ### TypeScript Best Practices
 
 - Always use TypeScript. Never use JavaScript.
@@ -100,6 +98,24 @@ This document contains comprehensive accessibility and code quality rules for fr
 
 ### React/Next.js Specific Rules
 
+**Compound Component Pattern** (for complex UI like Combobox, Menu):
+
+```typescript
+// Export object with subcomponents for composition
+export const Combobox = {
+	Root, // Context provider + main wrapper
+	Input, // Text input
+	Listbox, // Dropdown options container
+	Option, // Individual option
+	Chips, // Selected items display
+	Chip, // Single chip
+};
+
+// Usage: <Combobox.Root><Combobox.Input /><Combobox.Listbox>...</Combobox.Listbox></Combobox.Root>
+```
+
+See `/src/components/ui/recollect/combobox/` for implementation.
+
 - Never use `<img>` elements in Next.js projects. Always use next/image.
 - Never use `<head>` elements in Next.js projects (except in \_document.js).
 - Never import next/document outside of pages/\_document.jsx in Next.js projects.
@@ -111,7 +127,6 @@ This document contains comprehensive accessibility and code quality rules for fr
 - Never use `target="_blank"` without `rel="noopener"`.
 - Never define React components inside other components.
 - Never assign to React component props.
-- Never destructure props inside JSX components in Solid projects.
 - Never insert comments as text nodes.
 - Never assign JSX properties multiple times.
 - Never return the return value of React.render.
@@ -128,7 +143,6 @@ This document contains comprehensive accessibility and code quality rules for fr
 - Always use ES Modules. Never use CommonJS.
 - Always set `"type": "module"` in `package.json`.
 - Always use function declarations. Never use function expressions.
-
 - Never use consecutive spaces in regular expression literals.
 - Never use the `arguments` object.
 - Never use the comma operator.
@@ -165,81 +179,6 @@ This document contains comprehensive accessibility and code quality rules for fr
 - Always remove redundant terms from logical expressions.
 - Always use while loops instead of for loops when you don't need initializer and update expressions.
 
-### Error Handling and Control Flow
-
-- Never reassign const variables.
-- Never use constant expressions in conditions.
-- Never use `Math.min` and `Math.max` to clamp values when the result is constant.
-- Never return a value from a constructor.
-- Never use empty character classes in regular expression literals.
-- Never use empty destructuring patterns.
-- Never call global object properties as functions.
-- Never declare functions and vars that are accessible outside their block.
-- Always ensure builtins are correctly instantiated.
-- Never use super() incorrectly inside classes.
-- Never use variables and function parameters before they're declared.
-- Never use \8 and \9 escape sequences in string literals.
-- Never use literal numbers that lose precision.
-- Never assign a value to itself.
-- Never return a value from a setter.
-- Never compare expressions that modify string case with non-compliant values.
-- Never use lexical declarations in switch clauses.
-- Never use variables that haven't been declared in the document.
-- Never write unreachable code.
-- Always ensure super() is called exactly once on every code path in a class constructor before this is accessed.
-- Never use control flow statements in finally blocks.
-- Never use optional chaining where undefined values aren't allowed.
-
-### Best Practices
-
-- Always include proper error handling and logging.
-- Always include comments explaining complex logic.
-- Never have unused function parameters.
-- Never have unused imports.
-- Never have unused labels.
-- Never have unused private class members.
-- Never have unused variables.
-- Never return a value from a function that has a 'void' return type.
-- Always use isNaN() when checking for NaN.
-- Always include key props in iterators and collection literals.
-- Always ensure "for" loop update clauses move the counter in the right direction.
-- Always ensure typeof expressions are compared to valid values.
-- Always ensure generator functions contain yield.
-- Never use await inside loops.
-- Never use bitwise operators.
-- Never use expressions where the operation doesn't change the value.
-- Always ensure Promise-like statements are handled appropriately.
-- Never use \*\*dirname and \*\*filename in the global scope.
-- Never create import cycles.
-- Never use configured elements.
-- Never hardcode sensitive data like API keys and tokens.
-- Never let variable declarations shadow variables from outer scopes.
-- Never include duplicate polyfills from Polyfill.io.
-- Never use useless backreferences in regular expressions.
-- Never use unnecessary escapes in string literals.
-- Never use useless undefined.
-- Always ensure getters and setters for the same property are next to each other.
-- Always ensure object literals are declared consistently.
-- Always use static Response methods instead of new Response() constructor when possible.
-- Always ensure switch-case statements are exhaustive.
-- Always ensure the `preconnect` attribute is used when using Google Fonts.
-- Always use `Array#{indexOf,lastIndexOf}()` instead of `Array#{findIndex,findLastIndex}()` when looking for the index of an item.
-- Always ensure iterable callbacks return consistent values.
-- Always use `with { type: "json" }` for JSON module imports.
-- Always use numeric separators in numeric literals.
-- Always use object spread instead of `Object.assign()` when constructing new objects.
-- Always use the radix argument when using `parseInt()`.
-- Always ensure JSDoc comment lines start with a single asterisk.
-- Always include a description parameter for `Symbol()`.
-- Never use spread (`...`) syntax on accumulators.
-- Never use the `delete` operator.
-- Never access namespace imports dynamically.
-- Never use namespace imports.
-- Always declare regex literals at the top level.
-- Never use global `eval()`.
-- Never use callbacks in asynchronous tests and hooks.
-- Never export imported variables.
-
 ### Modern JavaScript
 
 - Always use `fetch`. Never use `axios`.
@@ -264,8 +203,6 @@ This document contains comprehensive accessibility and code quality rules for fr
 - Always use `for-of` loops when you need the index to extract an item from the iterated array.
 - Always use `node:assert/strict` over `node:assert`.
 - Always use the `node:` protocol for Node.js builtin modules.
-- Always use the `--experimental-strip-types` flag to run TypeScript. Never use `ts-node` or `tsx`.
-- Always use the built-in `--env-file` flag. Never use the `dotenv` package.
 - Always use Number properties instead of global ones.
 - Always use assignment operator shorthand where possible.
 - Always use template literals over string concatenation.
@@ -274,77 +211,24 @@ This document contains comprehensive accessibility and code quality rules for fr
 - Always use `String.trimStart()` and `String.trimEnd()` over `String.trimLeft()` and `String.trimRight()`.
 - Always use standard constants instead of approximated literals.
 
-### Testing
-
-- Never nest describe() blocks too deeply in test files.
-- Never use export or module.exports in test files.
-- Never use focused tests.
-- Always ensure the assertion function is placed inside an it() function call.
-- Never use disabled tests.
-
-### Code Style
-
-- Never assign values in expressions.
-- Never use async functions as Promise executors.
-- Never reassign exceptions in catch clauses.
-- Never reassign class members.
-- Never compare against -0.
-- Never use labeled statements that aren't loops.
-- Never use console.
-- Never use control characters and escape sequences in regular expression literals.
-- Never use debugger.
-- Never assign directly to document.cookie.
-- Always use `===` and `!==`.
-- Never use duplicate case labels.
-- Never use duplicate class members.
-- Never use duplicate conditions in if-else-if chains.
-- Never use two keys with the same name inside objects.
-- Never use duplicate function parameter names.
-- Never have duplicate hooks in describe blocks.
-- Never use empty block statements and static blocks.
-- Never declare empty interfaces.
-- Never misuse the non-null assertion operator (!) in TypeScript files.
-- Never let switch clauses fall through.
-- Never reassign function declarations.
-- Never allow assignments to native objects and read-only global variables.
-- Always use Number.isFinite instead of global isFinite.
-- Always use Number.isNaN instead of global isNaN.
-- Never assign to imported bindings.
-- Never use irregular whitespace characters.
-- Never use labels that share a name with a variable.
-- Never use characters made with multiple code points in character class syntax.
-- Always use new and constructor properly.
-- Never use octal escape sequences in string literals.
-- Never use Object.prototype builtins directly.
-- Never redeclare variables, functions, classes, and types in the same scope.
-- Never have redundant "use strict".
-- Never compare things where both sides are exactly the same.
-- Never let identifiers shadow restricted names.
-- Never use sparse arrays (arrays with holes).
-- Never use template literal placeholder syntax in regular strings.
-- Never use the then property.
-- Never use unsafe negation.
-- Never use var.
-- Never use with statements in non-strict contexts.
-- Always ensure async functions actually use await.
-- Always ensure default clauses in switch statements come last.
-- Always pass a message value when creating a built-in error.
-- Always ensure get methods always return a value.
-- Always use a recommended display strategy with Google Fonts.
-- Always ensure for-in loops include an if statement.
-- Always use Array.isArray() instead of instanceof Array.
-- Always use the digits argument with Number#toFixed().
-- Always use the "use strict" directive in script files.
-- Never use negation in `if` statements that have `else` clauses.
-- Never use nested ternary expressions.
-
-## Implementation Notes
-
-These rules are designed to work with:
-
-- Next.js with App Router
-- React
-- TypeScript with strict mode
-- ESLint with comprehensive plugins
+### Best Practices
 
-Many of these rules are already enforced by the project's ESLint configuration. This document serves as a comprehensive reference for all frontend best practices that should be followed in this codebase.
+- Always include proper error handling and logging.
+- Never have unused function parameters.
+- Never have unused imports.
+- Never have unused labels.
+- Never have unused private class members.
+- Never have unused variables.
+- Never return a value from a function that has a 'void' return type.
+- Always use isNaN() when checking for NaN.
+- Always include key props in iterators and collection literals.
+- Always ensure "for" loop update clauses move the counter in the right direction.
+- Always ensure typeof expressions are compared to valid values.
+- Always ensure generator functions contain yield.
+- Never use await inside loops.
+- Never use bitwise operators.
+- Never use expressions where the operation doesn't change the value.
+- Always ensure Promise-like statements are handled appropriately.
+- Never create import cycles.
+- Never hardcode sensitive data like API keys and tokens.
+- Never let variable declarations shadow variables from outer scopes.
diff --git a/.claude/rules/sentry.md b/.claude/rules/sentry.md
new file mode 100644
index 00000000..1e5107ae
--- /dev/null
+++ b/.claude/rules/sentry.md
@@ -0,0 +1,114 @@
+# Sentry Monitoring Guidelines
+
+Patterns for error tracking and debugging with Sentry in this project.
+
+## Configuration
+
+Sentry initialization files:
+
+- `instrumentation-client.ts` - Client-side init
+- `sentry.server.config.ts` - Server init
+- `sentry.edge.config.ts` - Edge init
+
+Import Sentry in other files: `import * as Sentry from "@sentry/nextjs"`
+
+## Exception Capture (Primary Pattern)
+
+**Always include tags and context:**
+
+```typescript
+Sentry.captureException(error, {
+	tags: {
+		operation: "operation_name", // Required - makes errors searchable
+		userId, // Include when available
+	},
+	extra: {
+		contextualData, // Debug data (not indexed)
+	},
+});
+```
+
+**Anti-pattern to avoid:**
+
+```typescript
+// BAD - No tags, not searchable
+Sentry.captureException(error);
+Sentry.captureException(`Error: ${message}`);
+
+// GOOD - Tagged and searchable
+Sentry.captureException(error, {
+	tags: { operation: "fetch_bookmark", userId },
+	extra: { bookmarkId },
+});
+```
+
+## Breadcrumbs for Cache Debugging
+
+Use `Sentry.addBreadcrumb` to track state before errors occur:
+
+```typescript
+// From /src/utils/cache-debug-helpers.ts
+Sentry.addBreadcrumb({
+	category: "optimistic-update", // Lowercase, hyphenated
+	message: "Cache miss for category",
+	level: "warning",
+	data: {
+		bookmarkId: variables.bookmark_id,
+		categoryId: variables.category_id,
+	},
+});
+```
+
+Use `logCacheMiss` helper in optimistic mutation hooks:
+
+```typescript
+import { logCacheMiss } from "@/utils/cache-debug-helpers";
+
+if (!foundItem) {
+	logCacheMiss("Optimistic Update", "Item not found in cache", {
+		itemId: variables.id,
+	});
+	return currentData;
+}
+```
+
+## API Handler Integration
+
+Response helpers in `/src/lib/api-helpers/response.ts` auto-capture exceptions:
+
+| Helper       | Sentry                  | Use For                       |
+| ------------ | ----------------------- | ----------------------------- |
+| `apiError`   | Auto-captures with tags | System/database errors        |
+| `apiWarn`    | No capture              | User errors (404, validation) |
+| `apiSuccess` | No capture              | Success responses             |
+
+```typescript
+// apiError automatically calls Sentry.captureException
+return apiError({
+	route: ROUTE,
+	message: "Failed to fetch data",
+	error,
+	operation: "fetch_bookmarks", // Becomes Sentry tag
+	userId,
+	extra: { queryParams },
+});
+```
+
+## Error Boundaries
+
+Root error boundaries capture with context:
+
+```typescript
+// /src/app/error.tsx
+Sentry.captureException(error, {
+	extra: { errorMessage: "Root error" },
+});
+```
+
+## Best Practices
+
+1. **Always tag operations** - Makes errors filterable in Sentry dashboard
+2. **Include userId when available** - Helps identify affected users
+3. **Use breadcrumbs before risky operations** - Provides context for debugging
+4. **Let response helpers handle API errors** - Consistent capture pattern
+5. **Don't capture strings** - Always pass actual Error objects
diff --git a/.claude/rules/supabase-edge-functions.md b/.claude/rules/supabase-edge-functions.md
new file mode 100644
index 00000000..490aa43f
--- /dev/null
+++ b/.claude/rules/supabase-edge-functions.md
@@ -0,0 +1,87 @@
+---
+paths: supabase/functions/**
+---
+
+# Supabase Edge Functions
+
+## Guidelines
+
+1. **Prefer Web APIs and Deno core APIs** over external dependencies
+   - Use `fetch` instead of Axios
+   - Use WebSockets API instead of node-ws
+
+2. **Shared utilities** go in `supabase/functions/_shared`
+   - Import using relative paths
+   - NO cross-dependencies between Edge Functions
+
+3. **Import specifiers** - NO bare specifiers
+   - ❌ `@supabase/supabase-js`
+   - ✅ `npm:@supabase/supabase-js`
+
+4. **Version all external imports**
+   - ❌ `npm:express`
+   - ✅ `npm:express@4.18.2`
+
+5. **Prefer `npm:` and `jsr:`** over `deno.land/x`, `esm.sh`, `unpkg.com`
+
+6. **Node built-in APIs** - use `node:` specifier
+   - `import process from "node:process"`
+
+7. **Use `Deno.serve`** - NOT deprecated `serve` from std
+   - ❌ `import { serve } from "https://deno.land/std@0.168.0/http/server.ts"`
+   - ✅ `Deno.serve(async (req) => { ... })`
+
+8. **Pre-populated environment variables** (don't set manually):
+   - `SUPABASE_URL`
+   - `SUPABASE_PUBLISHABLE_OR_ANON_KEY`
+   - `SUPABASE_SERVICE_ROLE_KEY`
+   - `SUPABASE_DB_URL`
+
+9. **File writes** - ONLY `/tmp` directory allowed
+
+10. **Background tasks** - use `EdgeRuntime.waitUntil(promise)`
+
+## Example Function
+
+```typescript
+interface ReqPayload {
+	name: string;
+}
+
+console.info("server started");
+
+Deno.serve(async (req: Request) => {
+	const { name }: ReqPayload = await req.json();
+	const data = {
+		message: `Hello ${name}!`,
+	};
+
+	return new Response(JSON.stringify(data), {
+		headers: { "Content-Type": "application/json" },
+	});
+});
+```
+
+## Using npm Packages
+
+```typescript
+import express from "npm:express@4.18.2";
+
+const app = express();
+
+app.get(/(.*)/, (req, res) => {
+	res.send("Welcome to Supabase");
+});
+
+app.listen(8000);
+```
+
+## Using Node APIs
+
+```typescript
+import { randomBytes } from "node:crypto";
+import process from "node:process";
+
+const randomString = randomBytes(10).toString("hex");
+console.log(randomString);
+```
diff --git a/.claude/rules/supabase-functions.md b/.claude/rules/supabase-functions.md
new file mode 100644
index 00000000..7b797394
--- /dev/null
+++ b/.claude/rules/supabase-functions.md
@@ -0,0 +1,99 @@
+---
+paths: supabase/**/*.sql
+---
+
+# Supabase Database Functions
+
+Generate high-quality PostgreSQL functions following these best practices.
+
+## General Guidelines
+
+1. **Default to `SECURITY INVOKER`:**
+   - Functions run with permissions of the invoking user
+   - Use `SECURITY DEFINER` only when explicitly required
+
+2. **Set `search_path` to empty:**
+   - Always: `set search_path = ''`
+   - Use fully qualified names: `schema_name.table_name`
+
+3. **Use Explicit Typing:**
+   - Clearly specify input and output types
+   - Avoid ambiguous or loosely typed parameters
+
+4. **Default to Immutable or Stable:**
+   - Use `IMMUTABLE` or `STABLE` when possible
+   - Use `VOLATILE` only if modifying data
+
+## Example Templates
+
+### Simple Function
+
+```sql
+create or replace function my_schema.hello_world()
+returns text
+language plpgsql
+security invoker
+set search_path = ''
+as $$
+begin
+  return 'hello world';
+end;
+$$;
+```
+
+### Function with Parameters
+
+```sql
+create or replace function public.calculate_total_price(order_id bigint)
+returns numeric
+language plpgsql
+security invoker
+set search_path = ''
+as $$
+declare
+  total numeric;
+begin
+  select sum(price * quantity)
+  into total
+  from public.order_items
+  where order_id = calculate_total_price.order_id;
+
+  return total;
+end;
+$$;
+```
+
+### Trigger Function
+
+```sql
+create or replace function my_schema.update_updated_at()
+returns trigger
+language plpgsql
+security invoker
+set search_path = ''
+as $$
+begin
+  new.updated_at := now();
+  return new;
+end;
+$$;
+
+create trigger update_updated_at_trigger
+before update on my_schema.my_table
+for each row
+execute function my_schema.update_updated_at();
+```
+
+### Immutable Function
+
+```sql
+create or replace function my_schema.full_name(first_name text, last_name text)
+returns text
+language sql
+security invoker
+set search_path = ''
+immutable
+as $$
+  select first_name || ' ' || last_name;
+$$;
+```
diff --git a/.claude/rules/supabase-migrations.md b/.claude/rules/supabase-migrations.md
new file mode 100644
index 00000000..95ebcf8d
--- /dev/null
+++ b/.claude/rules/supabase-migrations.md
@@ -0,0 +1,54 @@
+---
+paths: supabase/migrations/**
+---
+
+# Supabase Migrations
+
+## File Naming Convention
+
+Migration files MUST follow: `YYYYMMDDHHmmss_short_description.sql`
+
+- `YYYY` - Four digits for year (e.g., `2024`)
+- `MM` - Two digits for month (01-12)
+- `DD` - Two digits for day (01-31)
+- `HH` - Two digits for hour in 24h format (00-23)
+- `mm` - Two digits for minute (00-59)
+- `ss` - Two digits for second (00-59)
+
+Example: `20240906123045_create_profiles.sql`
+
+## SQL Guidelines
+
+- Include header comment with migration purpose and affected tables
+- Add comments explaining each migration step
+- Write SQL in lowercase (or uppercase consistently within file)
+- Add copious comments for destructive commands (truncate, drop, alter)
+
+## Row Level Security
+
+**MUST enable RLS on every new table**, even for public access:
+
+```sql
+alter table my_table enable row level security;
+```
+
+### RLS Policy Rules
+
+- Create separate policies for each operation (select, insert, update, delete)
+- Create separate policies for each role (`anon`, `authenticated`)
+- DO NOT combine policies even if functionality is the same
+- Include comments explaining policy rationale
+
+```sql
+-- Allow authenticated users to read their own records
+create policy "Users can view own records"
+on my_table for select
+to authenticated
+using (user_id = auth.uid());
+
+-- Allow authenticated users to insert their own records
+create policy "Users can insert own records"
+on my_table for insert
+to authenticated
+with check (user_id = auth.uid());
+```
diff --git a/.claude/rules/supabase-nextjs.md b/.claude/rules/supabase-nextjs.md
new file mode 100644
index 00000000..9a58a6c7
--- /dev/null
+++ b/.claude/rules/supabase-nextjs.md
@@ -0,0 +1,128 @@
+# Supabase Auth SSR with Next.js
+
+## CRITICAL: Deprecated Patterns
+
+**NEVER use these patterns - they will break the application:**
+
+```typescript
+// ❌ NEVER USE - Individual cookie methods
+{
+  cookies: {
+    get(name: string) { ... },    // ❌ BREAKS APPLICATION
+    set(name: string, value) { ... }, // ❌ BREAKS APPLICATION
+    remove(name: string) { ... }  // ❌ BREAKS APPLICATION
+  }
+}
+
+// ❌ NEVER USE - Deprecated package
+import { createMiddlewareClient } from '@supabase/auth-helpers-nextjs'
+import { createClientComponentClient } from '@supabase/auth-helpers-nextjs'
+```
+
+## REQUIRED: Correct Patterns
+
+**ALWAYS use `@supabase/ssr` with `getAll`/`setAll`:**
+
+### Browser Client
+
+```typescript
+import { createBrowserClient } from "@supabase/ssr";
+
+export function createClient() {
+	return createBrowserClient(
+		process.env.NEXT_PUBLIC_SUPABASE_URL!,
+		process.env.NEXT_PUBLIC_SUPABASE_PUBLISHABLE_KEY!,
+	);
+}
+```
+
+### Server Client
+
+```typescript
+import { cookies } from "next/headers";
+import { createServerClient } from "@supabase/ssr";
+
+export async function createClient() {
+	const cookieStore = await cookies();
+
+	return createServerClient(
+		process.env.NEXT_PUBLIC_SUPABASE_URL!,
+		process.env.NEXT_PUBLIC_SUPABASE_PUBLISHABLE_KEY!,
+		{
+			cookies: {
+				getAll() {
+					return cookieStore.getAll();
+				},
+				setAll(cookiesToSet) {
+					try {
+						cookiesToSet.forEach(({ name, value, options }) =>
+							cookieStore.set(name, value, options),
+						);
+					} catch {
+						// Ignore - called from Server Component
+					}
+				},
+			},
+		},
+	);
+}
+```
+
+### Middleware
+
+```typescript
+import { NextResponse, type NextRequest } from "next/server";
+import { createServerClient } from "@supabase/ssr";
+
+export async function middleware(request: NextRequest) {
+	let supabaseResponse = NextResponse.next({ request });
+
+	const supabase = createServerClient(
+		process.env.NEXT_PUBLIC_SUPABASE_URL!,
+		process.env.NEXT_PUBLIC_SUPABASE_PUBLISHABLE_KEY!,
+		{
+			cookies: {
+				getAll() {
+					return request.cookies.getAll();
+				},
+				setAll(cookiesToSet) {
+					cookiesToSet.forEach(({ name, value }) =>
+						request.cookies.set(name, value),
+					);
+					supabaseResponse = NextResponse.next({ request });
+					cookiesToSet.forEach(({ name, value, options }) =>
+						supabaseResponse.cookies.set(name, value, options),
+					);
+				},
+			},
+		},
+	);
+
+	// IMPORTANT: DO NOT REMOVE auth.getUser()
+	const {
+		data: { user },
+	} = await supabase.auth.getUser();
+
+	// Handle unauthenticated users...
+
+	return supabaseResponse;
+}
+```
+
+## Verification Checklist
+
+Before generating any Supabase auth code:
+
+1. Using ONLY `getAll` and `setAll`? ✓
+2. Importing from `@supabase/ssr`? ✓
+3. NO `get`, `set`, or `remove` methods? ✓
+4. NO imports from `auth-helpers-nextjs`? ✓
+
+## Consequences of Wrong Implementation
+
+Using deprecated patterns will:
+
+1. Break in production
+2. Fail to maintain session state
+3. Cause authentication loops
+4. Result in security vulnerabilities
diff --git a/.claude/rules/supabase-realtime.md b/.claude/rules/supabase-realtime.md
new file mode 100644
index 00000000..fad8fc60
--- /dev/null
+++ b/.claude/rules/supabase-realtime.md
@@ -0,0 +1,114 @@
+---
+paths: src/**/*.{ts,tsx}
+---
+
+# Supabase Realtime
+
+## Core Rules
+
+### Do
+
+- Use `broadcast` for all realtime events (database changes, messaging, notifications)
+- Use `presence` sparingly for user state tracking only
+- Create indexes for columns used in RLS policies
+- Use topic names: `scope:entity` (e.g., `room:123:messages`)
+- Use snake_case event names: `entity_action` (e.g., `message_created`)
+- Include unsubscribe/cleanup logic in all implementations
+- Set `private: true` for channels using database triggers or RLS
+
+### Don't
+
+- Use `postgres_changes` for new applications (doesn't scale)
+- Create multiple subscriptions without cleanup
+- Use generic event names like "update" or "change"
+- Subscribe directly in render functions
+
+## Function Selection
+
+| Use Case                       | Recommended                       |
+| ------------------------------ | --------------------------------- |
+| Custom payloads                | `broadcast`                       |
+| Database change notifications  | `broadcast` via database triggers |
+| High-frequency updates         | `broadcast` with minimal payload  |
+| User presence/status           | `presence` (sparingly)            |
+| Client to client communication | `broadcast` without triggers      |
+
+## React Pattern
+
+```javascript
+const channelRef = useRef(null);
+
+useEffect(() => {
+  if (channelRef.current?.state === 'subscribed') return;
+
+  const channel = supabase.channel('room:123:messages', {
+    config: { private: true }
+  });
+  channelRef.current = channel;
+
+  await supabase.realtime.setAuth();
+
+  channel
+    .on('broadcast', { event: 'message_created' }, handleMessage)
+    .subscribe();
+
+  return () => {
+    if (channelRef.current) {
+      supabase.removeChannel(channelRef.current);
+      channelRef.current = null;
+    }
+  };
+}, [roomId]);
+```
+
+## Database Trigger Pattern
+
+```sql
+CREATE OR REPLACE FUNCTION room_messages_broadcast_trigger()
+RETURNS TRIGGER AS $$
+SECURITY DEFINER
+LANGUAGE plpgsql
+AS $$
+BEGIN
+  PERFORM realtime.broadcast_changes(
+    'room:' || COALESCE(NEW.room_id, OLD.room_id)::text,
+    TG_OP,
+    TG_OP,
+    TG_TABLE_NAME,
+    TG_TABLE_SCHEMA,
+    NEW,
+    OLD
+  );
+  RETURN COALESCE(NEW, OLD);
+END;
+$$;
+```
+
+## Authorization
+
+```sql
+-- RLS policy for private channels
+CREATE POLICY "room_members_can_read" ON realtime.messages
+FOR SELECT TO authenticated
+USING (
+  topic LIKE 'room:%' AND
+  EXISTS (
+    SELECT 1 FROM room_members
+    WHERE user_id = auth.uid()
+    AND room_id = SPLIT_PART(topic, ':', 2)::uuid
+  )
+);
+
+-- Required index
+CREATE INDEX idx_room_members_user_room
+ON room_members(user_id, room_id);
+```
+
+## Checklist
+
+- ✅ Favor `broadcast` over `postgres_changes`
+- ✅ Check channel state before subscribing
+- ✅ Include cleanup/unsubscribe logic
+- ✅ Use consistent naming conventions
+- ✅ Set `private: true` for database triggers
+- ✅ Add indexes for RLS policies
diff --git a/.claude/rules/supabase-rls.md b/.claude/rules/supabase-rls.md
new file mode 100644
index 00000000..da84871d
--- /dev/null
+++ b/.claude/rules/supabase-rls.md
@@ -0,0 +1,96 @@
+---
+paths: supabase/**/*.sql
+---
+
+# Supabase RLS Policies
+
+## Policy Structure
+
+- SELECT policies: USING only (not WITH CHECK)
+- INSERT policies: WITH CHECK only (not USING)
+- UPDATE policies: Both USING and WITH CHECK
+- DELETE policies: USING only (not WITH CHECK)
+
+## Required Patterns
+
+- Always use `auth.uid()` instead of `current_user`
+- Don't use `FOR ALL` - create separate policies per operation
+- Always specify role with `TO` clause (`anon`, `authenticated`)
+- Use descriptive policy names in double quotes
+- Prefer `PERMISSIVE` over `RESTRICTIVE` policies
+
+## Correct Syntax Order
+
+```sql
+create policy "Policy name"
+on table_name
+for select           -- operation comes first
+to authenticated     -- role comes after operation
+using ( ... );
+```
+
+## Performance Recommendations
+
+### Add Indexes
+
+```sql
+create index idx_table_user_id
+on my_table
+using btree (user_id);
+```
+
+### Use Select Wrapper for Functions
+
+```sql
+-- ❌ Slow - function called per row
+using ( auth.uid() = user_id );
+
+-- ✅ Fast - function cached per statement
+using ( (select auth.uid()) = user_id );
+```
+
+### Minimize Joins
+
+```sql
+-- ✅ Use IN with subquery instead of joins
+using (
+  team_id in (
+    select team_id
+    from team_members
+    where user_id = (select auth.uid())
+  )
+);
+```
+
+## Example Policies
+
+```sql
+-- Select policy for authenticated users
+create policy "Users can view own records"
+on my_table
+for select
+to authenticated
+using ( (select auth.uid()) = user_id );
+
+-- Insert policy with validation
+create policy "Users can insert own records"
+on my_table
+for insert
+to authenticated
+with check ( (select auth.uid()) = user_id );
+
+-- Update policy with both clauses
+create policy "Users can update own records"
+on my_table
+for update
+to authenticated
+using ( (select auth.uid()) = user_id )
+with check ( (select auth.uid()) = user_id );
+
+-- Delete policy
+create policy "Users can delete own records"
+on my_table
+for delete
+to authenticated
+using ( (select auth.uid()) = user_id );
+```
diff --git a/.claude/rules/supabase-schema.md b/.claude/rules/supabase-schema.md
new file mode 100644
index 00000000..9de47c3b
--- /dev/null
+++ b/.claude/rules/supabase-schema.md
@@ -0,0 +1,50 @@
+---
+paths: supabase/**
+---
+
+# Supabase Declarative Schema Management
+
+## Core Rules
+
+1. **Schema files in `supabase/schemas/`**
+   - All schema modifications go in `.sql` files here
+   - DO NOT modify `supabase/migrations/` directly (auto-generated)
+
+2. **Migration Generation Workflow**
+
+   ```bash
+   # Stop local dev environment first
+   supabase stop
+
+   # Generate migration from schema diff
+   supabase db diff -f <migration_name>
+   ```
+
+3. **File Organization**
+   - Files execute in lexicographic order
+   - Name files to manage dependencies (foreign keys)
+   - Append new columns to end of table definitions
+
+## Rollback Procedure
+
+1. Update `.sql` files in `supabase/schemas/` to desired state
+2. Generate rollback migration: `supabase db diff -f <rollback_name>`
+3. Review migration carefully for data loss
+
+## Known Caveats (Use Versioned Migrations Instead)
+
+These are NOT tracked by schema diff:
+
+- DML statements (insert, update, delete)
+- View ownership and grants
+- Security invoker on views
+- Materialized views
+- ALTER POLICY statements
+- Column privileges
+- Schema privileges
+- Comments
+- Partitions
+- ALTER PUBLICATION statements
+- CREATE DOMAIN statements
+
+**Non-compliance may lead to inconsistent database states.**
diff --git a/.claude/rules/supabase-sql.md b/.claude/rules/supabase-sql.md
new file mode 100644
index 00000000..0f3e0b27
--- /dev/null
+++ b/.claude/rules/supabase-sql.md
@@ -0,0 +1,131 @@
+---
+paths: "*.sql, supabase/**"
+---
+
+# Postgres SQL Style Guide
+
+## General
+
+- Use lowercase for SQL reserved words to maintain consistency and readability. Exception: Migration files may use uppercase keywords for better readability of function definitions.
+- Employ consistent, descriptive identifiers for tables, columns, and other database objects.
+- Use white space and indentation to enhance the readability of your code.
+- Store dates in ISO 8601 format (`yyyy-mm-ddThh:mm:ss.sssss`).
+- Include comments for complex logic, using '/\*...\*/' for block comments and '--' for line comments.
+
+## Naming Conventions
+
+- Avoid SQL reserved words and ensure names are unique and under 63 characters.
+- Use snake_case for tables and columns.
+- Prefer plurals for table names
+- Prefer singular names for columns.
+
+## Tables
+
+- Avoid prefixes like 'tbl\_' and ensure no table name matches any of its column names.
+- Always add an `id` column of type `identity generated always` unless otherwise specified.
+- Create all tables in the `public` schema unless otherwise specified.
+- Always add the schema to SQL queries for clarity.
+- Always add a comment to describe what the table does. The comment can be up to 1024 characters.
+
+## Columns
+
+- Use singular names and avoid generic names like 'id'.
+- For references to foreign tables, use the singular of the table name with the `_id` suffix. For example `user_id` to reference the `users` table
+- Always use lowercase except in cases involving acronyms or when readability would be enhanced by an exception.
+
+#### Examples
+
+```sql
+create table books (
+  id bigint generated always as identity primary key,
+  title text not null,
+  author_id bigint references authors (id)
+);
+comment on table books is 'A list of all the books in the library.';
+```
+
+## Queries
+
+- When the query is shorter keep it on just a few lines. As it gets larger start adding newlines for readability
+- Add spaces for readability.
+
+Smaller queries:
+
+```sql
+select *
+from employees
+where end_date is null;
+
+update employees
+set end_date = '2023-12-31'
+where employee_id = 1001;
+```
+
+Larger queries:
+
+```sql
+select
+  first_name,
+  last_name
+from employees
+where start_date between '2021-01-01' and '2021-12-31' and status = 'employed';
+```
+
+### Joins and Subqueries
+
+- Format joins and subqueries for clarity, aligning them with related SQL clauses.
+- Prefer full table names when referencing tables. This helps for readability.
+
+```sql
+select
+  employees.employee_name,
+  departments.department_name
+from
+  employees
+  join departments on employees.department_id = departments.department_id
+where employees.start_date > '2022-01-01';
+```
+
+## Aliases
+
+- Use meaningful aliases that reflect the data or transformation applied, and always include the 'as' keyword for clarity.
+
+```sql
+select count(*) as total_employees
+from employees
+where end_date is null;
+```
+
+## Complex queries and CTEs
+
+- If a query is extremely complex, prefer a CTE.
+- Make sure the CTE is clear and linear. Prefer readability over performance.
+- Add comments to each block.
+
+```sql
+with
+  department_employees as (
+    -- Get all employees and their departments
+    select
+      employees.department_id,
+      employees.first_name,
+      employees.last_name,
+      departments.department_name
+    from
+      employees
+      join departments on employees.department_id = departments.department_id
+  ),
+  employee_counts as (
+    -- Count how many employees in each department
+    select
+      department_name,
+      count(*) as num_employees
+    from department_employees
+    group by department_name
+  )
+select
+  department_name,
+  num_employees
+from employee_counts
+order by department_name;
+```
diff --git a/docs/task_completion_checklist.md b/.claude/rules/task-completion.md
similarity index 93%
rename from docs/task_completion_checklist.md
rename to .claude/rules/task-completion.md
index 629391fd..8a729ee9 100644
--- a/docs/task_completion_checklist.md
+++ b/.claude/rules/task-completion.md
@@ -1,6 +1,6 @@
 # Task Completion Checklist
 
-## 1. Code Quality ✓
+## 1. Code Quality
 
 - [ ] All TypeScript strict mode checks pass (`pnpm lint:types`)
 - [ ] ESLint shows no errors or warnings (`pnpm fix:eslint`)
@@ -35,13 +35,13 @@ pnpm fix
 
 This single command validates:
 
-- ✅ **TypeScript**: Type checking and compilation
-- ✅ **ESLint**: Code quality and React patterns
-- ✅ **Prettier**: Code formatting consistency
-- ✅ **Knip**: Unused dependencies, exports, and types
-- ✅ **CSS**: Stylelint validation
-- ✅ **Markdown**: Documentation formatting
-- ✅ **Spelling**: CSpell dictionary validation
+- TypeScript: Type checking and compilation
+- ESLint: Code quality and React patterns
+- Prettier: Code formatting consistency
+- Knip: Unused dependencies, exports, and types
+- CSS: Stylelint validation
+- Markdown: Documentation formatting
+- Spelling: CSpell dictionary validation
 
 ### 3. Build Verification (Recommended)
 
diff --git a/.cursor/commands/reviewtodev.md b/.cursor/commands/reviewtodev.md
new file mode 100644
index 00000000..4f6b38ab
--- /dev/null
+++ b/.cursor/commands/reviewtodev.md
@@ -0,0 +1,752 @@
+# Review Current Branch Against Dev Branch
+
+This command reviews your current branch changes against the `dev` branch using the PR Standards Checklist.
+
+## Usage
+
+Run this command to get a comprehensive review of your changes:
+
+```bash
+# Ensure you're on your feature branch
+git status
+
+# Fetch latest dev branch
+git fetch origin dev
+
+# Review changes against dev
+# This will analyze all changes and check against PR standards
+```
+
+## Automated Review Process
+
+This review checks:
+
+1. **Database Migrations** - File naming, structure, RLS policies, indexes, documentation
+2. **API Routes** - Authentication, validation, error handling, documentation
+3. **TypeScript Standards** - Types, exports, strict mode compliance
+4. **React/React Query** - Hook patterns, optimistic mutations, query invalidation
+5. **Code Quality** - File size, linting, naming conventions
+
+---
+
+## Step-by-Step Review Checklist
+
+### 1. Get Changed Files
+
+```bash
+# Get list of changed files compared to dev
+git diff --name-status origin/dev...HEAD
+
+# Get detailed diff
+git diff origin/dev...HEAD
+
+# Get only SQL migration files
+git diff --name-only origin/dev...HEAD | grep '\.sql$'
+
+# Get only TypeScript/TSX files
+git diff --name-only origin/dev...HEAD | grep -E '\.(ts|tsx)$'
+```
+
+### 2. Review Database Migrations
+
+For each migration file (`supabase/migrations/*.sql`):
+
+#### ✅ Check File Naming
+
+```bash
+# Verify migration file naming convention
+git diff --name-only origin/dev...HEAD | grep 'supabase/migrations/.*\.sql$' | while read file; do
+	filename=$(basename "$file")
+	if [[ ! "$filename" =~ ^[0-9]{14}_[a-z0-9_]+\.sql$ ]]; then
+		echo "❌ INVALID: $filename - Must match YYYYMMDDHHmmss_description.sql"
+	else
+		echo "✅ VALID: $filename"
+	fi
+done
+```
+
+#### ✅ Check Migration Structure
+
+```bash
+# Check for BEGIN/COMMIT transaction blocks
+git diff origin/dev...HEAD -- 'supabase/migrations/*.sql' | grep -E '^(BEGIN|COMMIT)' || echo "❌ Missing BEGIN/COMMIT transaction blocks"
+
+# Check for header comments
+git diff origin/dev...HEAD -- 'supabase/migrations/*.sql' | grep -E '^\+-- ============================================================================' || echo "❌ Missing migration header comments"
+
+# Check for SET search_path
+git diff origin/dev...HEAD -- 'supabase/migrations/*.sql' | grep -E 'SET search_path' || echo "⚠️  Consider adding SET search_path = public, pg_temp"
+```
+
+#### ✅ Check RLS Policies
+
+```bash
+# Check if RLS is enabled for new tables
+git diff origin/dev...HEAD -- 'supabase/migrations/*.sql' | grep -E 'CREATE TABLE' | while read line; do
+	table=$(echo "$line" | grep -oP 'CREATE TABLE[^(]*\K[^(]+')
+	if ! git diff origin/dev...HEAD -- 'supabase/migrations/*.sql' | grep -q "ALTER TABLE.*$table.*ENABLE ROW LEVEL SECURITY"; then
+		echo "❌ Missing RLS for table: $table"
+	fi
+done
+
+# Check for granular RLS policies (not combined)
+git diff origin/dev...HEAD -- 'supabase/migrations/*.sql' | grep -E 'CREATE POLICY.*FOR ALL' && echo "❌ Found FOR ALL policy - should be separate policies per operation"
+
+# Check for role-specific policies
+git diff origin/dev...HEAD -- 'supabase/migrations/*.sql' | grep -E 'CREATE POLICY' | grep -v 'TO (authenticated|anon)' && echo "⚠️  Policy missing TO clause for role specification"
+```
+
+#### ✅ Check Indexes
+
+```bash
+# Check if indexes exist for RLS policy columns
+git diff origin/dev...HEAD -- 'supabase/migrations/*.sql' | grep -E 'CREATE POLICY.*USING.*auth\.uid\(\)' \
+	&& echo "⚠️  Ensure indexes exist on user_id columns used in RLS policies"
+
+# Check for foreign key indexes
+git diff origin/dev...HEAD -- 'supabase/migrations/*.sql' | grep -E 'FOREIGN KEY' | while read line; do
+	column=$(echo "$line" | grep -oP 'FOREIGN KEY\s*\(\K[^)]+')
+	if ! git diff origin/dev...HEAD -- 'supabase/migrations/*.sql' | grep -q "CREATE INDEX.*$column"; then
+		echo "⚠️  Consider adding index for foreign key column: $column"
+	fi
+done
+```
+
+#### ✅ Check Documentation
+
+```bash
+# Check for COMMENT ON statements
+git diff origin/dev...HEAD -- 'supabase/migrations/*.sql' | grep -E 'CREATE TABLE' | while read line; do
+	table=$(echo "$line" | grep -oP 'CREATE TABLE[^(]*\K[^(]+')
+	if ! git diff origin/dev...HEAD -- 'supabase/migrations/*.sql' | grep -q "COMMENT ON TABLE.*$table"; then
+		echo "⚠️  Missing COMMENT ON TABLE for: $table"
+	fi
+done
+
+# Check for function comments
+git diff origin/dev...HEAD -- 'supabase/migrations/*.sql' | grep -E 'CREATE.*FUNCTION' | while read line; do
+	if ! git diff origin/dev...HEAD -- 'supabase/migrations/*.sql' | grep -q "COMMENT ON FUNCTION"; then
+		echo "⚠️  Missing COMMENT ON FUNCTION for created functions"
+	fi
+done
+```
+
+### 3. Review API Routes
+
+For each API route file (`src/app/api/**/*.ts` or `src/pages/api/**/*.ts`):
+
+#### ✅ Check Authentication
+
+```bash
+# Check for proper handler usage (public vs authenticated)
+git diff origin/dev...HEAD -- 'src/app/api/**/*.ts' 'src/pages/api/**/*.ts' | grep -E 'export (const|async function) (GET|POST|PUT|DELETE|PATCH)' | while read line; do
+	file=$(echo "$line" | grep -oP '^diff --git.*\K[^\s]+' || echo "$line" | awk '{print $3}')
+	if [ -n "$file" ] && [ -f "$file" ]; then
+		# Check if using handler helpers
+		if git diff origin/dev...HEAD -- "$file" | grep -qE '(createGetApiHandler|createPostApiHandler|createPutApiHandler|createDeleteApiHandler)'; then
+			# Public handler - should NOT have requireAuth
+			if git diff origin/dev...HEAD -- "$file" | grep -q "requireAuth"; then
+				echo "⚠️  Public handler should not use requireAuth in: $file"
+			fi
+			echo "✅ Using public handler helper in: $file"
+		elif git diff origin/dev...HEAD -- "$file" | grep -qE '(createGetApiHandlerWithAuth|createPostApiHandlerWithAuth|createPutApiHandlerWithAuth|createDeleteApiHandlerWithAuth)'; then
+			# Authenticated handler - should have requireAuth (handled by helper)
+			echo "✅ Using authenticated handler helper in: $file"
+		elif git diff origin/dev...HEAD -- "$file" | grep -qE 'export async function (GET|POST|PUT|DELETE|PATCH)'; then
+			# Manual handler - must check for requireAuth
+			if ! git diff origin/dev...HEAD -- "$file" | grep -q "requireAuth"; then
+				echo "❌ Missing requireAuth in manual handler: $file"
+			else
+				echo "✅ Has requireAuth in: $file"
+			fi
+		fi
+	fi
+done
+```
+
+#### ✅ Check Input Validation
+
+```bash
+# Check for parseBody usage
+git diff origin/dev...HEAD -- 'src/app/api/**/*.ts' 'src/pages/api/**/*.ts' | grep -E 'export async function POST' | while read line; do
+	file=$(echo "$line" | grep -oP '^diff --git.*\K[^\s]+')
+	if ! git diff origin/dev...HEAD -- "$file" | grep -q "parseBody"; then
+		echo "❌ Missing parseBody validation in: $file"
+	fi
+done
+
+# Check for Zod schemas
+git diff origin/dev...HEAD -- 'src/app/api/**/*.ts' 'src/pages/api/**/*.ts' | grep -E 'export async function (POST|PUT|PATCH)' | while read line; do
+	file=$(echo "$line" | grep -oP '^diff --git.*\K[^\s]+')
+	if ! git diff origin/dev...HEAD -- "$file" | grep -q "Schema.*=.*z\."; then
+		echo "⚠️  Consider adding Zod schema for input validation in: $file"
+	fi
+done
+```
+
+#### ✅ Check Error Handling
+
+```bash
+# Check for apiError/apiWarn usage
+git diff origin/dev...HEAD -- 'src/app/api/**/*.ts' 'src/pages/api/**/*.ts' | grep -E 'export async function' | while read line; do
+	file=$(echo "$line" | grep -oP '^diff --git.*\K[^\s]+')
+	if ! git diff origin/dev...HEAD -- "$file" | grep -qE '(apiError|apiWarn|apiSuccess)'; then
+		echo "⚠️  Missing proper error handling helpers in: $file"
+	fi
+done
+
+# Check for try/catch blocks
+git diff origin/dev...HEAD -- 'src/app/api/**/*.ts' 'src/pages/api/**/*.ts' | grep -E 'export async function' | while read line; do
+	file=$(echo "$line" | grep -oP '^diff --git.*\K[^\s]+')
+	if ! git diff origin/dev...HEAD -- "$file" | grep -q "try {"; then
+		echo "⚠️  Missing try/catch block in: $file"
+	fi
+done
+```
+
+#### ✅ Check for Console.log Statements
+
+```bash
+# Check for console.log statements in frontend code only (allowed in API routes)
+git diff origin/dev...HEAD -- 'src/**/*.{ts,tsx}' | grep -E '^\+.*console\.log' | grep -v 'src/app/api/' | grep -v 'src/pages/api/' && echo "❌ Found console.log statements in frontend code - remove from production code"
+```
+
+### 4. Review TypeScript Standards
+
+#### ✅ Check for Default Exports
+
+```bash
+# Check for default exports (should be named exports only)
+git diff origin/dev...HEAD -- 'src/**/*.{ts,tsx}' | grep -E '^\+export default' && echo "❌ Found default exports - use named exports only"
+```
+
+#### ✅ Check for `any` Types
+
+```bash
+# Check for 'any' types
+git diff origin/dev...HEAD -- 'src/**/*.{ts,tsx}' | grep -E ':\s*any\b' && echo "❌ Found 'any' types - use proper types"
+```
+
+#### ✅ Check for TypeScript Ignores
+
+```bash
+# Check for @ts-ignore or @ts-expect-error
+git diff origin/dev...HEAD -- 'src/**/*.{ts,tsx}' | grep -E '@ts-(ignore|expect-error)' && echo "❌ Found @ts-ignore/@ts-expect-error - fix types properly"
+```
+
+### 5. Review React/React Query Patterns
+
+#### ✅ Check Hook File Naming
+
+```bash
+# Check hook file naming (should be kebab-case)
+git diff --name-only origin/dev...HEAD | grep -E 'src/(hooks|async)/.*\.ts$' | while read file; do
+	filename=$(basename "$file")
+	if [[ "$filename" =~ [A-Z] ]]; then
+		echo "⚠️  Hook file should be kebab-case: $file"
+	fi
+done
+```
+
+#### ✅ Check Hook Exports
+
+```bash
+# Check for default exports in hooks
+git diff origin/dev...HEAD -- 'src/hooks/**/*.ts' 'src/async/**/*.ts' | grep -E '^\+export default' && echo "❌ Found default exports in hooks - use named exports"
+```
+
+#### ✅ Check Optimistic Mutations
+
+```bash
+# Check for optimistic mutation patterns
+git diff origin/dev...HEAD -- 'src/async/mutationHooks/**/*.ts' | grep -E 'useMutation' | while read line; do
+	file=$(echo "$line" | grep -oP '^diff --git.*\K[^\s]+')
+	if git diff origin/dev...HEAD -- "$file" | grep -q "onMutate"; then
+		if ! git diff origin/dev...HEAD -- "$file" | grep -qE '(cancelQueries|previousData|onError.*previousData)'; then
+			echo "⚠️  Optimistic mutation may be missing rollback logic in: $file"
+		fi
+	fi
+done
+```
+
+### 6. Review Code Quality
+
+#### ✅ Check File Sizes
+
+```bash
+# Check for files over 250 lines
+git diff --name-only origin/dev...HEAD | grep -E '\.(ts|tsx)$' | while read file; do
+	if [ -f "$file" ]; then
+		lines=$(wc -l < "$file")
+		if [ "$lines" -gt 250 ]; then
+			echo "⚠️  File exceeds 250 lines: $file ($lines lines)"
+		fi
+	fi
+done
+```
+
+#### ✅ Check for Classes
+
+```bash
+# Check for class definitions (should be functional only)
+git diff origin/dev...HEAD -- 'src/**/*.{ts,tsx}' | grep -E '^\+.*class\s+\w+' && echo "❌ Found class definitions - use functional programming only"
+```
+
+#### ✅ Check for Code Duplication
+
+```bash
+# Check for potential duplicate hooks/functions
+# This is a manual check - review new hooks/functions against existing ones
+echo "🔍 Checking for potential code duplication..."
+echo ""
+echo "New hooks created:"
+git diff --name-only origin/dev...HEAD | grep -E 'src/(hooks|async)/.*\.ts$' | while read file; do
+	hook_name=$(basename "$file" .ts)
+	echo "  - $hook_name"
+	echo "    Check if similar functionality exists:"
+	echo "    rg '$hook_name|${hook_name//-/_}' src/hooks/ src/async/ | head -5"
+done
+
+echo ""
+echo "New components created:"
+git diff --name-only origin/dev...HEAD | grep -E 'src/components/.*\.tsx$' | while read file; do
+	component_name=$(basename "$file" .tsx)
+	echo "  - $component_name"
+	echo "    Check if similar component exists:"
+	echo "    rg '$component_name' src/components/ | head -5"
+done
+
+echo ""
+echo "New utilities created:"
+git diff --name-only origin/dev...HEAD | grep -E 'src/utils/.*\.ts$' | while read file; do
+	util_name=$(basename "$file" .ts)
+	echo "  - $util_name"
+	echo "    Check if similar utility exists:"
+	echo "    rg '$util_name' src/utils/ | head -5"
+done
+```
+
+### 7. Run Linting Checks
+
+```bash
+# Get list of changed TypeScript/TSX files
+changed_files=$(git diff --name-only origin/dev...HEAD | grep -E '\.(ts|tsx)$' | tr '\n' ' ')
+
+if [ -n "$changed_files" ]; then
+	echo "Running ESLint fixes..."
+	pnpm fix:eslint $changed_files
+
+	echo "Running TypeScript type checks..."
+	pnpm lint:types
+
+	echo "Running Prettier..."
+	pnpm fix:prettier
+
+	echo "Checking for unused code..."
+	pnpm lint:knip
+else
+	echo "No TypeScript files changed"
+fi
+```
+
+---
+
+## Comprehensive Review Script
+
+Save this as a script and run it:
+
+```bash
+#!/bin/bash
+# review-pr-standards.sh
+# Comprehensive review of current branch against dev branch
+
+set -e
+
+echo "🔍 PR Standards Review"
+echo "======================"
+echo ""
+
+# Colors
+RED='\033[0;31m'
+GREEN='\033[0;32m'
+YELLOW='\033[1;33m'
+NC='\033[0m' # No Color
+
+# Check if we're in a git repo
+if ! git rev-parse --git-dir > /dev/null 2>&1; then
+	echo -e "${RED}❌ Not in a git repository${NC}"
+	exit 1
+fi
+
+# Fetch latest dev
+echo "📥 Fetching latest dev branch..."
+git fetch origin dev 2> /dev/null || echo "⚠️  Could not fetch origin/dev"
+
+# Check if dev branch exists
+if ! git rev-parse --verify origin/dev > /dev/null 2>&1; then
+	echo -e "${RED}❌ origin/dev branch not found${NC}"
+	exit 1
+fi
+
+# Get current branch
+current_branch=$(git rev-parse --abbrev-ref HEAD)
+echo "📍 Current branch: $current_branch"
+echo "📊 Comparing against: origin/dev"
+echo ""
+
+# Get changed files
+changed_files=$(git diff --name-only origin/dev...HEAD)
+if [ -z "$changed_files" ]; then
+	echo -e "${GREEN}✅ No changes detected${NC}"
+	exit 0
+fi
+
+echo "📝 Changed files:"
+echo "$changed_files" | nl
+echo ""
+
+# Track issues
+issues=0
+warnings=0
+
+# 1. Check Migration Files
+echo "🗄️  Checking Database Migrations..."
+migration_files=$(echo "$changed_files" | grep 'supabase/migrations/.*\.sql$' || true)
+if [ -n "$migration_files" ]; then
+	echo "$migration_files" | while read file; do
+		filename=$(basename "$file")
+
+		# Check naming convention
+		if [[ ! "$filename" =~ ^[0-9]{14}_[a-z0-9_]+\.sql$ ]]; then
+			echo -e "${RED}❌ Invalid migration filename: $filename${NC}"
+			echo "   Should match: YYYYMMDDHHmmss_description.sql"
+			((issues++))
+		else
+			echo -e "${GREEN}✅ Valid migration filename: $filename${NC}"
+		fi
+
+		# Check for BEGIN/COMMIT
+		if ! git diff origin/dev...HEAD -- "$file" | grep -qE '^\+BEGIN'; then
+			echo -e "${RED}❌ Missing BEGIN transaction in: $file${NC}"
+			((issues++))
+		fi
+		if ! git diff origin/dev...HEAD -- "$file" | grep -qE '^\+COMMIT'; then
+			echo -e "${RED}❌ Missing COMMIT transaction in: $file${NC}"
+			((issues++))
+		fi
+
+		# Check for header comments
+		if ! git diff origin/dev...HEAD -- "$file" | grep -qE '^\+-- ============================================================================'; then
+			echo -e "${YELLOW}⚠️  Missing migration header comments in: $file${NC}"
+			((warnings++))
+		fi
+
+		# Check for RLS
+		if git diff origin/dev...HEAD -- "$file" | grep -qE '^\+CREATE TABLE'; then
+			if ! git diff origin/dev...HEAD -- "$file" | grep -qE 'ENABLE ROW LEVEL SECURITY'; then
+				echo -e "${RED}❌ Missing RLS enablement for new table in: $file${NC}"
+				((issues++))
+			fi
+		fi
+
+		# Check for COMMENT ON
+		if git diff origin/dev...HEAD -- "$file" | grep -qE '^\+CREATE TABLE'; then
+			if ! git diff origin/dev...HEAD -- "$file" | grep -qE 'COMMENT ON TABLE'; then
+				echo -e "${YELLOW}⚠️  Missing COMMENT ON TABLE in: $file${NC}"
+				((warnings++))
+			fi
+		fi
+	done
+else
+	echo -e "${GREEN}✅ No migration files changed${NC}"
+fi
+echo ""
+
+# 2. Check API Routes
+echo "🌐 Checking API Routes..."
+api_files=$(echo "$changed_files" | grep -E '(src/app/api|src/pages/api)/.*\.ts$' || true)
+if [ -n "$api_files" ]; then
+	echo "$api_files" | while read file; do
+		# Check if using handler helpers (preferred pattern)
+		if git diff origin/dev...HEAD -- "$file" | grep -qE '(createGetApiHandler|createPostApiHandler|createPutApiHandler|createDeleteApiHandler|createGetApiHandlerWithAuth|createPostApiHandlerWithAuth)'; then
+			# Using handler helper - check if correct type
+			if git diff origin/dev...HEAD -- "$file" | grep -qE '(createGetApiHandler|createPostApiHandler)' && git diff origin/dev...HEAD -- "$file" | grep -q "requireAuth"; then
+				echo -e "${YELLOW}⚠️  Public handler should not use requireAuth in: $file${NC}"
+				((warnings++))
+			fi
+			if git diff origin/dev...HEAD -- "$file" | grep -qE '(createGetApiHandlerWithAuth|createPostApiHandlerWithAuth)'; then
+				echo -e "${GREEN}✅ Using authenticated handler helper in: $file${NC}"
+			else
+				echo -e "${GREEN}✅ Using public handler helper in: $file${NC}"
+			fi
+		# Check manual handlers
+		elif git diff origin/dev...HEAD -- "$file" | grep -qE 'export async function (GET|POST|PUT|DELETE|PATCH)'; then
+			# Manual handler - must have requireAuth
+			if ! git diff origin/dev...HEAD -- "$file" | grep -q "requireAuth"; then
+				echo -e "${RED}❌ Missing requireAuth in manual handler: $file${NC}"
+				echo "   Consider using createGetApiHandlerWithAuth or createPostApiHandlerWithAuth instead"
+				((issues++))
+			else
+				echo -e "${GREEN}✅ Has requireAuth in: $file${NC}"
+			fi
+		fi
+
+		# Check for parseBody/parseQuery (POST/PUT/PATCH for body, GET for query)
+		if git diff origin/dev...HEAD -- "$file" | grep -qE 'export (const GET|async function GET)'; then
+			if ! git diff origin/dev...HEAD -- "$file" | grep -qE '(parseQuery|createGetApiHandler)'; then
+				echo -e "${YELLOW}⚠️  GET handler should use parseQuery or createGetApiHandler in: $file${NC}"
+				((warnings++))
+			fi
+		fi
+		if git diff origin/dev...HEAD -- "$file" | grep -qE 'export (const POST|async function POST|const PUT|async function PUT|const PATCH|async function PATCH)'; then
+			if ! git diff origin/dev...HEAD -- "$file" | grep -qE '(parseBody|createPostApiHandler|createPutApiHandler|createPatchApiHandler)'; then
+				echo -e "${RED}❌ Missing parseBody validation in: $file${NC}"
+				((issues++))
+			fi
+		fi
+
+		# Check for try/catch (only for manual handlers, helpers handle it)
+		if git diff origin/dev...HEAD -- "$file" | grep -qE 'export async function' && ! git diff origin/dev...HEAD -- "$file" | grep -qE '(createGetApiHandler|createPostApiHandler|createPutApiHandler|createDeleteApiHandler|createGetApiHandlerWithAuth|createPostApiHandlerWithAuth)'; then
+			if ! git diff origin/dev...HEAD -- "$file" | grep -q "try {"; then
+				echo -e "${YELLOW}⚠️  Missing try/catch block in manual handler: $file${NC}"
+				((warnings++))
+			fi
+		fi
+	done
+else
+	echo -e "${GREEN}✅ No API route files changed${NC}"
+fi
+echo ""
+
+# 3. Check TypeScript Standards
+echo "📘 Checking TypeScript Standards..."
+ts_files=$(echo "$changed_files" | grep -E '\.(ts|tsx)$' || true)
+if [ -n "$ts_files" ]; then
+	# Check for default exports
+	if git diff origin/dev...HEAD -- $ts_files | grep -qE '^\+export default'; then
+		echo -e "${RED}❌ Found default exports - use named exports only${NC}"
+		git diff origin/dev...HEAD -- $ts_files | grep -E '^\+export default'
+		((issues++))
+	fi
+
+	# Check for 'any' types
+	if git diff origin/dev...HEAD -- $ts_files | grep -qE ':\s*any\b'; then
+		echo -e "${RED}❌ Found 'any' types${NC}"
+		git diff origin/dev...HEAD -- $ts_files | grep -E ':\s*any\b' | head -5
+		((issues++))
+	fi
+
+	# Check for @ts-ignore
+	if git diff origin/dev...HEAD -- $ts_files | grep -qE '@ts-(ignore|expect-error)'; then
+		echo -e "${RED}❌ Found @ts-ignore/@ts-expect-error${NC}"
+		git diff origin/dev...HEAD -- $ts_files | grep -E '@ts-(ignore|expect-error)'
+		((issues++))
+	fi
+
+	# Check for console.log statements in frontend code only
+	if git diff origin/dev...HEAD -- $ts_files | grep -E '^\+.*console\.log' | grep -v 'src/app/api/' | grep -v 'src/pages/api/'; then
+		echo -e "${RED}❌ Found console.log statements in frontend code - remove from production code${NC}"
+		git diff origin/dev...HEAD -- $ts_files | grep -E '^\+.*console\.log' | grep -v 'src/app/api/' | grep -v 'src/pages/api/' | head -5
+		((issues++))
+	fi
+
+	# Check for classes
+	if git diff origin/dev...HEAD -- $ts_files | grep -qE '^\+.*class\s+\w+'; then
+		echo -e "${RED}❌ Found class definitions - use functional programming only${NC}"
+		((issues++))
+	fi
+else
+	echo -e "${GREEN}✅ No TypeScript files changed${NC}"
+fi
+echo ""
+
+# 4. Check File Sizes
+echo "📏 Checking File Sizes..."
+echo "$changed_files" | grep -E '\.(ts|tsx)$' | while read file; do
+	if [ -f "$file" ]; then
+		lines=$(wc -l < "$file" 2> /dev/null || echo "0")
+		if [ "$lines" -gt 250 ]; then
+			echo -e "${YELLOW}⚠️  File exceeds 250 lines: $file ($lines lines)${NC}"
+			((warnings++))
+		fi
+	fi
+done
+echo ""
+
+# 5. Check for Code Duplication
+echo "🔄 Checking for Code Reuse Opportunities..."
+new_hooks=$(echo "$changed_files" | grep -E 'src/(hooks|async)/.*\.ts$' || true)
+new_components=$(echo "$changed_files" | grep -E 'src/components/.*\.tsx$' || true)
+new_utils=$(echo "$changed_files" | grep -E 'src/utils/.*\.ts$' || true)
+
+if [ -n "$new_hooks" ] || [ -n "$new_components" ] || [ -n "$new_utils" ]; then
+	echo -e "${YELLOW}⚠️  New code created - please verify no duplicates exist:${NC}"
+	if [ -n "$new_hooks" ]; then
+		echo "  New hooks:"
+		echo "$new_hooks" | while read file; do
+			hook_name=$(basename "$file" .ts)
+			echo "    - $hook_name"
+		done
+	fi
+	if [ -n "$new_components" ]; then
+		echo "  New components:"
+		echo "$new_components" | while read file; do
+			component_name=$(basename "$file" .tsx)
+			echo "    - $component_name"
+		done
+	fi
+	if [ -n "$new_utils" ]; then
+		echo "  New utilities:"
+		echo "$new_utils" | while read file; do
+			util_name=$(basename "$file" .ts)
+			echo "    - $util_name"
+		done
+	fi
+	echo ""
+	echo "  💡 Tip: Search for similar functionality before creating new code:"
+	echo "    rg '<function-name>' src/hooks/ src/async/ src/components/ src/utils/"
+	((warnings++))
+else
+	echo -e "${GREEN}✅ No new hooks/components/utils created${NC}"
+fi
+echo ""
+
+# Summary
+echo "📊 Review Summary"
+echo "================="
+if [ $issues -eq 0 ] && [ $warnings -eq 0 ]; then
+	echo -e "${GREEN}✅ No issues found!${NC}"
+elif [ $issues -eq 0 ]; then
+	echo -e "${GREEN}✅ No critical issues${NC}"
+	echo -e "${YELLOW}⚠️  $warnings warning(s)${NC}"
+else
+	echo -e "${RED}❌ $issues critical issue(s) found${NC}"
+	echo -e "${YELLOW}⚠️  $warnings warning(s)${NC}"
+	echo ""
+	echo "Please review the issues above and fix them before submitting your PR."
+	echo "Refer to docs/pr_standards_checklist.md for detailed guidelines."
+	exit 1
+fi
+
+echo ""
+echo "✅ Review complete!"
+echo ""
+echo "Next steps:"
+echo "1. Run: pnpm fix:eslint <changed-files>"
+echo "2. Run: pnpm lint:types"
+echo "3. Run: pnpm fix:prettier"
+echo "4. Review docs/pr_standards_checklist.md for any missed items"
+```
+
+---
+
+## Manual Review Checklist
+
+Use this checklist to manually review your changes:
+
+### Database Migrations
+
+- [ ] Migration file named correctly (`YYYYMMDDHHmmss_description.sql`)
+- [ ] Comprehensive header comment with purpose
+- [ ] Wrapped in `BEGIN;` / `COMMIT;` transaction
+- [ ] Pre-flight validation (DO blocks)
+- [ ] Post-migration verification (DO blocks)
+- [ ] RLS policies (one per operation, one per role)
+- [ ] Indexes for RLS policy columns
+- [ ] Indexes for foreign keys
+- [ ] `COMMENT ON` statements for tables/columns/functions
+- [ ] Security functions use `SECURITY DEFINER` properly
+
+### API Routes
+
+- [ ] **Handler pattern**:
+  - [ ] Uses handler helpers (`createGetApiHandler`, `createPostApiHandler`, etc.) when possible
+  - [ ] Uses `createGetApiHandlerWithAuth`/`createPostApiHandlerWithAuth` for authenticated endpoints
+  - [ ] Uses `createGetApiHandler`/`createPostApiHandler` for public endpoints (no auth)
+  - [ ] If manual handler, uses `requireAuth` for authenticated endpoints
+- [ ] Uses `parseBody` with Zod schema (POST/PUT/PATCH) or `parseQuery` (GET)
+- [ ] Uses `apiSuccess` with Zod schema for output
+- [ ] Uses `apiWarn` for user errors (4xx)
+- [ ] Uses `apiError` for system errors (5xx)
+- [ ] Error handling in try/catch (if manual handler, helpers handle it automatically)
+- [ ] Route constant defined (`const ROUTE = "..."`)
+- [ ] Public endpoints properly marked (no requireAuth if using public handler)
+- [ ] **No console.log statements in frontend code** (allowed in API routes for backend logging)
+
+### TypeScript
+
+- [ ] No `any` types
+- [ ] No `@ts-ignore` directives
+- [ ] Named exports only (no default exports)
+- [ ] Types exported only if used elsewhere
+- [ ] Strict mode passes
+
+### React/React Query
+
+- [ ] Hook files named in kebab-case
+- [ ] Named exports (not default)
+- [ ] Optimistic mutations include rollback
+- [ ] Query invalidation includes related queries
+
+### Code Quality
+
+- [ ] File size ≤ 250 lines
+- [ ] Functional programming only (no classes)
+- [ ] ESLint passes
+- [ ] Prettier formatting applied
+- [ ] TypeScript strict mode passes
+- [ ] No unused code
+- [ ] **Code reuse verified**:
+  - [ ] Searched for existing hooks before creating new (`rg` or `grep` in `src/hooks/`, `src/async/`)
+  - [ ] Searched for existing components before creating new (`rg` or `grep` in `src/components/`)
+  - [ ] Searched for existing utilities before creating new (`rg` or `grep` in `src/utils/`)
+  - [ ] Used existing patterns rather than creating duplicates
+
+---
+
+## Reference
+
+- **PR Standards Checklist**: `docs/pr_standards_checklist.md`
+- **Migration Guidelines**: `.cursor/rules/supabase-create-migration.mdc`
+- **RLS Guidelines**: `.cursor/rules/supabase-create-rls-policies.mdc`
+- **Code Style**: `CLAUDE.md`
+
+---
+
+## Quick Commands
+
+```bash
+# Get diff summary
+git diff --stat origin/dev...HEAD
+
+# Get only added lines
+git diff origin/dev...HEAD | grep '^+'
+
+# Get only removed lines
+git diff origin/dev...HEAD | grep '^-'
+
+# Review specific file
+git diff origin/dev...HEAD -- path/to/file.ts
+
+# Check if branch is up to date with dev
+git log origin/dev..HEAD --oneline
+
+# See what commits are in your branch but not in dev
+git log origin/dev..HEAD
+
+# See what commits are in dev but not in your branch
+git log HEAD..origin/dev
+
+# Search for existing code before creating new
+# Search for hooks
+rg "useFetch.*Categories" src/hooks/ src/async/
+
+# Search for components
+rg "Category.*Select|Category.*Dropdown" src/components/
+
+# Search for utilities
+rg "formatDate|format.*date" src/utils/
+
+# Search for functions by name pattern
+rg "function.*category" src/
+```
diff --git a/.cursor/rules/api-logging.mdc b/.cursor/rules/api-logging.mdc
new file mode 100644
index 00000000..a95021d8
--- /dev/null
+++ b/.cursor/rules/api-logging.mdc
@@ -0,0 +1,392 @@
+---
+# Specify the following for Cursor rules
+description: API Logging Rules
+alwaysApply: false
+paths: src/app/api/**/*.ts, src/pages/api/**/*.ts
+---
+
+# API Logging Rules
+
+Guidelines for logging, error handling, and Sentry integration in API routes.
+
+## App Router Handler Factories (Recommended)
+
+Four handler factories in `/src/lib/api-helpers/create-handler.ts`:
+
+| Function                       | Auth     | Method | Use Case               |
+| ------------------------------ | -------- | ------ | ---------------------- |
+| `createGetApiHandler`          | Public   | GET    | Public read endpoints  |
+| `createPostApiHandler`         | Public   | POST   | Public write endpoints |
+| `createGetApiHandlerWithAuth`  | Required | GET    | Authenticated reads    |
+| `createPostApiHandlerWithAuth` | Required | POST   | Authenticated writes   |
+
+### Authenticated POST Example
+
+```typescript
+import { z } from "zod";
+import { createPostApiHandlerWithAuth } from "@/lib/api-helpers/create-handler";
+import { apiError, apiWarn } from "@/lib/api-helpers/response";
+
+const ROUTE = "endpoint-name";
+
+const InputSchema = z.object({
+	param1: z.string(),
+});
+
+const OutputSchema = z.object({
+	id: z.number(),
+	name: z.string(),
+});
+
+export const POST = createPostApiHandlerWithAuth({
+	route: ROUTE,
+	inputSchema: InputSchema,
+	outputSchema: OutputSchema,
+	handler: async ({ data, supabase, user, route }) => {
+		const { param1 } = data;
+		const userId = user.id;
+
+		console.log(`[${route}] API called:`, { userId, param1 });
+
+		// Business logic...
+		const { data: result, error } = await supabase.from("table").select();
+		if (error) {
+			return apiError({
+				route,
+				message: "Failed to fetch data",
+				error,
+				operation: "operation_name",
+				userId,
+				extra: { param1 },
+			});
+		}
+
+		// Return raw data (automatically wrapped in apiSuccess)
+		return result;
+	},
+});
+```
+
+**Handler factory config:**
+
+| Prop           | Type        | Description                            |
+| -------------- | ----------- | -------------------------------------- |
+| `route`        | `string`    | Route name for logging prefix          |
+| `inputSchema`  | `z.ZodType` | Zod schema for request body validation |
+| `outputSchema` | `z.ZodType` | Zod schema for response validation     |
+| `handler`      | `function`  | Async handler receiving context        |
+
+**Handler context:**
+
+| Prop       | Type             | Description            |
+| ---------- | ---------------- | ---------------------- |
+| `data`     | `TInput`         | Validated request body |
+| `supabase` | `SupabaseClient` | Authenticated client   |
+| `user`     | `User`           | Authenticated user     |
+| `route`    | `string`         | Route name             |
+
+**Handler return behavior:**
+
+- Return raw data → wrapped in `apiSuccess` automatically
+- Return `NextResponse` (via `apiWarn`/`apiError`) → passed through directly
+
+### Manual Pattern (For Custom Control)
+
+Use manual helpers when you need custom authentication flow or special handling:
+
+```typescript
+import { type NextRequest } from "next/server";
+import { z } from "zod";
+import {
+	apiError,
+	apiSuccess,
+	apiWarn,
+	parseBody,
+} from "@/lib/api-helpers/response";
+import { requireAuth } from "@/lib/supabase/api";
+
+const ROUTE = "endpoint-name";
+
+const InputSchema = z.object({
+	param1: z.string(),
+});
+
+const OutputSchema = z.object({
+	id: z.number(),
+	name: z.string(),
+});
+
+export async function POST(request: NextRequest) {
+	try {
+		const auth = await requireAuth(ROUTE);
+		if (auth.errorResponse) {
+			return auth.errorResponse;
+		}
+		const { supabase, user } = auth;
+
+		// Validate request body
+		const body = await parseBody({
+			request,
+			schema: InputSchema,
+			route: ROUTE,
+		});
+		if (body.errorResponse) {
+			return body.errorResponse;
+		}
+
+		const { param1 } = body.data;
+		const userId = user.id;
+
+		console.log(`[${ROUTE}] API called:`, { userId, param1 });
+
+		// Business logic...
+		const { data, error } = await supabase.from("table").select();
+		if (error) {
+			return apiError({
+				route: ROUTE,
+				message: "Failed to fetch data",
+				error,
+				operation: "operation_name",
+				userId,
+				extra: { param1 },
+			});
+		}
+
+		return apiSuccess({ route: ROUTE, data, schema: OutputSchema });
+	} catch (error) {
+		return apiError({
+			route: ROUTE,
+			message: "An unexpected error occurred",
+			error,
+			operation: "endpoint_name_unexpected",
+		});
+	}
+}
+```
+
+### Response Helpers
+
+| Helper       | Use For                                              | Sentry | Status Codes |
+| ------------ | ---------------------------------------------------- | ------ | ------------ |
+| `parseBody`  | Request body validation                              | No     | 400          |
+| `apiWarn`    | User errors (not found, permission denied)           | No     | 4xx          |
+| `apiError`   | System errors (database failures, unexpected issues) | Yes    | 500          |
+| `apiSuccess` | Success with output validation                       | No     | 200          |
+
+**`parseBody` props:**
+
+- `request`: The incoming request object
+- `schema`: Zod schema for validation
+- `route`: Route name for logging prefix
+
+**`apiWarn` props:**
+
+- `route`: Route name for logging prefix
+- `message`: User-friendly error message (sent to client)
+- `status`: HTTP status code (400, 403, 404, etc.)
+- `context?`: Optional debug data for server logs
+
+**`apiError` props:**
+
+- `route`: Route name for logging prefix
+- `message`: User-friendly error message (sent to client)
+- `error`: The error object to log and send to Sentry
+- `operation`: Sentry tag for filtering (e.g., "fetch_bookmark")
+- `userId?`: Optional user ID for Sentry tags
+- `extra?`: Optional additional context for Sentry
+
+**`apiSuccess` props:**
+
+- `route`: Route name for logging prefix
+- `data`: The response data
+- `schema`: Zod schema for output validation
+- `status?`: HTTP status code (default: 200)
+
+### Response Types
+
+All helpers return typed `NextResponse` for proper type inference:
+
+```typescript
+type ApiSuccessResponse<T> = { data: T; error: null };
+type ApiErrorResponse = { data: null; error: string };
+export type ApiResponse<T> = ApiErrorResponse | ApiSuccessResponse<T>;
+```
+
+**Response Examples:**
+
+```json
+// 200 Success
+{ "data": { "id": 1, "name": "Example" }, "error": null }
+
+// 401 Unauthorized
+{ "data": null, "error": "Not authenticated" }
+
+// 400 Bad Request (validation)
+{ "data": null, "error": "Bookmark ID is required" }
+
+// 403 Forbidden
+{ "data": null, "error": "No access to this category" }
+
+// 404 Not Found
+{ "data": null, "error": "Bookmark not found or not owned by user" }
+
+// 500 Internal Server Error
+{ "data": null, "error": "Failed to fetch data" }
+```
+
+Note: Error responses use simple strings, not structured objects.
+
+### `requireAuth` Details
+
+Returns discriminated union for type narrowing:
+
+```typescript
+type AuthResult =
+	| { supabase: SupabaseClient<Database>; user: User; errorResponse: null }
+	| {
+			supabase: null;
+			user: null;
+			errorResponse: NextResponse<ApiErrorResponse>;
+	  };
+```
+
+**Auth error responses:**
+
+- `userError` → 400: `{ data: null, error: userError.message }`
+- `!user` → 401: `{ data: null, error: "Not authenticated" }`
+
+## Pages Router Authentication (Legacy)
+
+For Pages API routes, use manual auth check:
+
+```typescript
+const supabase = apiSupabaseClient(request, response);
+const { data: userData, error: userError } = await supabase.auth.getUser();
+
+if (userError) {
+	console.warn("[endpoint] Auth error:", userError);
+	response.status(400).json({ data: null, error: userError.message });
+	return;
+}
+
+if (!userData?.user) {
+	console.warn("[endpoint] No user found");
+	response.status(401).json({ data: null, error: "Not authenticated" });
+	return;
+}
+```
+
+## Critical Rules
+
+### 1. Root-Level Try-Catch (Required)
+
+Every handler MUST wrap all logic in try-catch:
+
+```typescript
+try {
+	// ALL logic here including auth
+} catch (error) {
+	console.error("[endpoint] Unexpected:", error);
+	Sentry.captureException(error, {
+		tags: { operation: "endpoint_unexpected" },
+	});
+	// Return generic error
+}
+```
+
+### 2. Never Expose Error Details
+
+| Context          | Log (Server)            | Response (Client)       |
+| ---------------- | ----------------------- | ----------------------- |
+| Validation error | `parsed.error.issues`   | "Invalid request"       |
+| Database error   | Full error object       | "Failed to [operation]" |
+| Auth error       | Full `userError` object | `userError.message`     |
+| Unexpected error | Full error object       | "An unexpected error"   |
+
+### 3. Fail-Fast Pattern
+
+Check errors immediately, return early:
+
+```typescript
+const { data, error } = await operation();
+if (error) {
+	console.error("[endpoint] Error:", error);
+	Sentry.captureException(error, { tags: { operation: "name", userId } });
+	return NextResponse.json(
+		{ data: null, error: "User message" },
+		{ status: 500 },
+	);
+}
+// Continue with success path
+```
+
+### 4. Always Send Response Before Return
+
+Never `return` without sending a response first (causes hanging requests).
+
+## Log Levels
+
+| Level           | Use For                                           | Example                        |
+| --------------- | ------------------------------------------------- | ------------------------------ |
+| `console.log`   | Entry points, success, flow decisions             | `"API called:", { userId }`    |
+| `console.warn`  | User-caused issues (auth, validation, duplicates) | `"Duplicate entry:", { name }` |
+| `console.error` | System/database errors                            | `"DB error:", error`           |
+
+## Sentry Integration
+
+```typescript
+Sentry.captureException(error, {
+	tags: {
+		operation: "operation_name", // Always include
+		userId, // Always include
+	},
+	extra: {
+		contextualData, // Only non-indexed debug data
+	},
+});
+```
+
+- `tags`: Indexed, searchable (operation, userId, key identifiers)
+- `extra`: Context only (paths, IDs), never `errorMessage`
+
+## Using `vet` for Throwing Operations
+
+Use `vet` for external APIs (axios, fetch) that throw on error. Returns `[error, result]` tuple.
+Don't use for Supabase (already returns `{ data, error }` tuples).
+
+```typescript
+const [apiError, apiResponse] = await vet(() => axios.get(url));
+if (apiError) {
+	Sentry.captureException(apiError, {
+		tags: { operation: "external_api", userId },
+	});
+	return NextResponse.json(
+		{ data: null, error: "External API failed" },
+		{ status: 500 },
+	);
+}
+```
+
+## Response Format
+
+```typescript
+// Success
+return NextResponse.json({ data, error: null }, { status: 200 });
+
+// Error - always user-friendly message
+return NextResponse.json(
+	{ data: null, error: "User-friendly message" },
+	{ status: 500 },
+);
+```
+
+Match the format to your API's response type.
+
+## Key Principles
+
+1. **Fail Fast** - Check errors immediately after operations
+2. **Early Return** - Use `return` after errors, not else blocks
+3. **No Raw Errors** - Send only user-friendly messages
+4. **Consistent Format** - `"[endpoint] Message:", { data }`
+5. **Appropriate Levels** - log (info), warn (user issues), error (system)
+6. **Always Tag Operations** - Makes errors searchable in Sentry
diff --git a/.cursor/rules/code-style.mdc b/.cursor/rules/code-style.mdc
new file mode 100644
index 00000000..18fba29c
--- /dev/null
+++ b/.cursor/rules/code-style.mdc
@@ -0,0 +1,205 @@
+---
+# Specify the following for Cursor rules
+description: Code Style Conventions
+alwaysApply: false
+---
+
+# Code Style Conventions
+
+## Code Quality Checks
+
+**ALWAYS run the following commands before completing any task:**
+
+1. Automatically use the IDE's built-in diagnostics tool to check for linting and type errors:
+   - Fix any linting or type errors before considering the task complete
+   - Do this for any file you create or modify
+
+This is a CRITICAL step that must NEVER be skipped when working on any code-related task
+
+## File Size Limits
+
+- **Maximum 250 lines per file** - If a file exceeds this limit:
+  - Extract large sections into separate component files
+  - Move related functionality into dedicated modules
+  - Split complex components into smaller, focused components
+- This ensures maintainability and better code organization
+
+## Naming Conventions
+
+- **Components**: PascalCase (e.g., `HeaderNavigation.tsx`)
+- **Functions/Hooks**: camelCase (e.g., `useMediaQuery`, `getFadeInProps`)
+- **Constants**: UPPER_SNAKE_CASE for true constants (e.g., `SITE_NAME`)
+- **Files**: kebab-case for non-component files
+- **CSS Classes**: Use Tailwind utilities, custom classes in kebab-case
+
+## React/Next.js Patterns
+
+- **Exports**: Named exports preferred
+
+  ```typescript
+  export function ComponentName () { ... }
+  ```
+
+  **Exceptions** (default exports allowed):
+  - Next.js pages (`page.tsx`, `layout.tsx`, `error.tsx`)
+  - Legacy query/mutation hooks (migrating to named exports)
+
+- **Component Structure**:
+  - Server components by default
+  - Client components explicitly marked with `"use client"`
+  - Separate files for server/client versions (e.g., `Component.tsx` and `ComponentClient.tsx`)
+- **Props**: Always define TypeScript interfaces
+
+  ```typescript
+  interface ComponentProps {
+  	title: string;
+  	isActive?: boolean;
+  }
+  ```
+
+## Styling Guidelines
+
+- **Tailwind CSS v4**: Primary styling method
+- **className Utility**: Use `cn()` helper for conditional classes
+
+  ```typescript
+  cn("base-class", isActive && "active-class");
+  ```
+
+- **No CSS-in-JS**: Avoid runtime styling solutions
+- **Custom CSS**: Only in global.css when absolutely necessary
+
+## File Organization
+
+- `/src/components` - Reusable UI components
+- `/src/pageComponents` - Page-specific components
+- `/src/pages` - Next.js pages (routes)
+- `/src/hooks` - Custom React hooks
+- `/src/store` - Zustand state stores
+- `/src/utils` - Utility functions
+- `/src/types` - Shared TypeScript types
+- `/src/async` - Async utilities and API calls
+- `/src/icons` - Icon components
+
+## Function Parameter Pattern
+
+**For functions with 2 or more parameters, use the props object pattern:**
+
+### Required Elements
+
+1. **Props Type**: Name it `FunctionNameProps`
+2. **Function Signature**: Use regular functions with single `props` parameter
+3. **Destructuring**: First line must destructure props alphabetically
+4. **Return Type**: Export complex return types as `FunctionNameReturnType`
+
+### Simple Example
+
+```typescript
+// Define props interface
+export interface ProcessDataProps {
+	connection: DatabaseConnection;
+	logger: Logger;
+	timeout?: number;
+}
+
+// Regular function with props parameter
+export async function processData(
+	props: ProcessDataProps,
+): Promise<ProcessResult> {
+	const { connection, logger, timeout = 5000 } = props; // Alphabetical destructuring
+	// ... implementation
+}
+
+// Export return type if needed elsewhere
+export type ProcessDataReturnType = Awaited<ReturnType<typeof processData>>;
+```
+
+### Benefits
+
+- Clear parameter grouping
+- Easy to add/remove parameters without changing call sites
+- Consistent pattern across codebase
+
+## Best Practices
+
+- **Images**: Use NextImage component with blurhash placeholders
+- **Links**: Use StyledLink component for consistent styling
+- **Icons**: Add to `/src/icons/svg/` and build sprite
+- **Config**: Centralize all business data in `siteConfig.ts`
+- **Environment Variables**: Validate with Zod schemas
+- **Metadata**: Use metadataUtils for consistent SEO
+
+## Code Quality Tools
+
+- **ESLint**: Extensive rule set for React, TypeScript, accessibility
+- **Prettier**: Auto-formatting with specific import order
+- **Stylelint**: CSS linting for consistency
+- **TypeScript**: Strict mode with all checks enabled
+- **Knip**: Detect unused code and dependencies
+- **cspell**: Spell checking across codebase
+
+## Accessibility Guidelines
+
+- **ARIA**: Use semantic HTML over ARIA roles when possible
+- **Keyboard**: All interactive elements must be keyboard accessible
+- **Alt Text**: Meaningful alt text for images (avoid "image", "picture", "photo")
+- **Focus**: Don't use positive tabIndex values
+- **Labels**: All form inputs must have associated labels
+- **Language**: Include `lang` attribute on html element
+
+### React useEffect Guidelines
+
+**Before using 'useEffect, read:** [You Might Not Need an Effect](https://react.dev/learn/you-might-not-need-an-effect)
+
+Common cases where 'useEffect is NOT needed:
+
+- Transforming data for rendering (use variables or useMemo instead)
+- Handling user events (use event handlers instead)
+- Resetting state when props change (use key prop or calculate during render)
+- Updating state based on props/state changes (calculate during render)
+  Only use 'useEffect for:
+- Synchronizing with external systems (APIs, DOM, third-party libraries)
+- Cleanup that must happen when component unmounts
+
+## Frontend Best Practices
+
+- **Next.js Images**: Use `next/image` instead of `<img>` tags
+- **Head Management**: Use Next.js head management, not `<head>` tags
+- **Security**: Always use `rel="noopener"` with `target="_blank"`
+- **Keys**: Don't use array indices as React keys
+- **Hooks**: Call hooks at top level, specify all dependencies
+- **Error Boundaries**: Handle errors gracefully with error boundaries
+
+## Git Conventions
+
+- **Commits**: Conventional commits format (enforced by commitlint)
+  - `feat:` for features
+  - `fix:` for bug fixes
+  - `chore:` for maintenance
+  - `docs:` for documentation
+- **Pre-commit**: Automatic linting via husky and lint-staged
+- **PR Titles**: Must follow conventional commits format
+
+## State Management
+
+### Zustand Stores
+
+- Store files in `/src/store`
+- Use TypeScript interfaces for store state
+- Separate actions from state
+
+### React Query
+
+- Query keys as constants
+- Custom hooks for queries
+- Proper error handling
+- Optimistic updates where appropriate
+
+## Environment Variables
+
+### Configuration
+
+- All env vars validated using Zod schemas
+- Separate client and server schemas
+- Type-safe access via validated schemas
+- Required prefix: `NEXT_PUBLIC_` for client-side vars
diff --git a/.cursor/rules/frontend.mdc b/.cursor/rules/frontend.mdc
new file mode 100644
index 00000000..8f0d507f
--- /dev/null
+++ b/.cursor/rules/frontend.mdc
@@ -0,0 +1,237 @@
+---
+# Specify the following for Cursor rules
+description: Frontend Rules
+alwaysApply: false
+paths: src/**/*.{ts,tsx}
+---
+
+# Frontend Rules
+
+Comprehensive accessibility and code quality rules for frontend development.
+
+## Accessibility Rules
+
+### ARIA and Semantic HTML
+
+- Never use `accessKey` attribute on any HTML element.
+- Never set `aria-hidden="true"` on focusable elements.
+- Never add ARIA roles, states, and properties to elements that don't support them.
+- Never use distracting elements like `<marquee>` or `<blink>`.
+- Always use the `scope` prop only on `<th>` elements.
+- Never assign non-interactive ARIA roles to interactive HTML elements.
+- Never assign interactive ARIA roles to non-interactive HTML elements.
+- Never use explicit role property that's the same as the implicit/default role.
+- Always ensure ARIA properties are valid for the element's supported roles.
+- Always include all required ARIA attributes for elements with ARIA roles.
+- Always ensure all ARIA properties (`aria-*`) are valid.
+- Always use valid, non-abstract ARIA roles for elements with ARIA roles.
+- Always use valid ARIA state and property values.
+- Always use semantic elements instead of role attributes in JSX.
+
+### Form and Input Accessibility
+
+- Always ensure label elements have text content and are associated with an input.
+- Always include a `type` attribute for button elements.
+- Always use valid values for the `autocomplete` attribute on input elements.
+
+### Keyboard Navigation
+
+- Never assign `tabIndex` to non-interactive HTML elements.
+- Never use positive integers for `tabIndex` property.
+- Always assign `tabIndex` to non-interactive HTML elements with `aria-activedescendant`.
+- Always make elements with interactive roles and handlers focusable.
+- Always accompany `onClick` with at least one of: `onKeyUp`, `onKeyDown`, or `onKeyPress`.
+- Always accompany `onMouseOver`/`onMouseOut` with `onFocus`/`onBlur`.
+
+### Content Accessibility
+
+- Never include "image", "picture", or "photo" in img `alt` prop.
+- Always include a `title` element for SVG elements.
+- Always give all elements requiring alt text meaningful information for screen readers.
+- Always ensure anchors have content that's accessible to screen readers.
+- Always give heading elements content that's accessible to screen readers (not hidden with `aria-hidden`).
+- Always include a `lang` attribute on the html element.
+- Always include a `title` attribute for iframe elements.
+- Always include caption tracks for audio and video elements.
+- Always ensure all anchors are valid and navigable.
+- Always use correct ISO language/country codes for the `lang` attribute.
+- Always use modern HTML features including `<dialog>` and the `popover` attribute.
+
+### Interactive Elements
+
+- Always make static elements with click handlers use a valid role attribute.
+- Never use event handlers on non-interactive elements.
+- Always use pointer events. Never use touch or mouse events directly.
+
+## Code Quality Rules
+
+### CSS and Styling
+
+- Always use CSS Grid for layout when it makes sense. Never use Flexbox if Grid can be used instead.
+- Never use `position: absolute` unless strictly necessary.
+- Always use modern CSS features including nesting, custom properties, container queries, subgrid, and color functions.
+- Always use Tailwind v4. Never use Tailwind v3.
+
+### TypeScript Best Practices
+
+- Always use TypeScript. Never use JavaScript.
+- Always add appropriate TypeScript types and interfaces.
+- Always import all methods, classes, and types used in the code.
+- Never use primitive type aliases or misleading types.
+- Never use empty type parameters in type aliases and interfaces.
+- Never use any or unknown as type constraints.
+- Never use the any type.
+- Never use the TypeScript directive @ts-ignore.
+- Never use TypeScript enums.
+- Never use TypeScript namespaces.
+- Never use TypeScript const enum.
+- Never add type annotations to variables that are initialized with literal expressions.
+- Always use `as const` instead of literal types and type annotations.
+- Always use either `T[]` or `Array<T>` consistently.
+- Always use `export type` for types.
+- Always use `import type` for types.
+- Always ensure all enum members are literal values.
+- Always use function types instead of object types with call signatures.
+- Never use void type outside of generic or return types.
+- Never let variables evolve into any type through reassignments.
+- Never use implicit any type on variable declarations.
+- Never merge interfaces and classes unsafely.
+- Never use overload signatures that aren't next to each other.
+- Always use the namespace keyword instead of the module keyword to declare TypeScript namespaces.
+
+### React/Next.js Specific Rules
+
+**Compound Component Pattern** (for complex UI like Combobox, Menu):
+
+```typescript
+// Export object with subcomponents for composition
+export const Combobox = {
+	Root, // Context provider + main wrapper
+	Input, // Text input
+	Listbox, // Dropdown options container
+	Option, // Individual option
+	Chips, // Selected items display
+	Chip, // Single chip
+};
+
+// Usage: <Combobox.Root><Combobox.Input /><Combobox.Listbox>...</Combobox.Listbox></Combobox.Root>
+```
+
+See `/src/components/ui/recollect/combobox/` for implementation.
+
+- Never use `<img>` elements in Next.js projects. Always use next/image.
+- Never use `<head>` elements in Next.js projects (except in \_document.js).
+- Never import next/document outside of pages/\_document.jsx in Next.js projects.
+- Never use the next/head module in pages/\_document.js on Next.js projects.
+- Never pass children as props.
+- Never let children and dangerouslySetInnerHTML props on the same element.
+- Never use Array index in keys.
+- Never use dangerous JSX props.
+- Never use `target="_blank"` without `rel="noopener"`.
+- Never define React components inside other components.
+- Never assign to React component props.
+- Never insert comments as text nodes.
+- Never assign JSX properties multiple times.
+- Never return the return value of React.render.
+- Never use shorthand assign when the variable appears on both sides.
+- Never place semicolons incorrectly inside JSX elements.
+- Always use `<>...</>` instead of `<Fragment>...</Fragment>`.
+- Never add extra closing tags for components without children.
+- Always ensure void (self-closing) elements don't have children.
+- Always ensure all dependencies are correctly specified in React hooks.
+- Always ensure all React hooks are called from the top level of component functions.
+
+### JavaScript/TypeScript Code Quality
+
+- Always use ES Modules. Never use CommonJS.
+- Always set `"type": "module"` in `package.json`.
+- Always use function declarations. Never use function expressions.
+- Never use consecutive spaces in regular expression literals.
+- Never use the `arguments` object.
+- Never use the comma operator.
+- Never write functions that exceed a given Cognitive Complexity score.
+- Never use unnecessary boolean casts.
+- Never use unnecessary callbacks with flatMap.
+- Always use for...of statements instead of Array.forEach.
+- Never create classes that only have static members.
+- Never use this and super in static contexts.
+- Never use unnecessary catch clauses.
+- Never use unnecessary constructors.
+- Never use unnecessary continue statements.
+- Never export empty modules that don't change anything.
+- Never use unnecessary escape sequences in regular expression literals.
+- Never use unnecessary fragments.
+- Never use unnecessary labels.
+- Never use unnecessary nested block statements.
+- Never rename imports, exports, and destructured assignments to the same name.
+- Never use unnecessary string or template literal concatenation.
+- Never use String.raw in template literals when there are no escape sequences.
+- Never use useless case statements in switch statements.
+- Never use ternary operators when simpler alternatives exist.
+- Never use useless `this` aliasing.
+- Never initialize variables to undefined.
+- Never use void operators.
+- Always use arrow functions instead of function expressions.
+- Always use Date.now() to get milliseconds since the Unix Epoch.
+- Always use .flatMap() instead of map().flat() when possible.
+- Always use literal property access instead of computed property access.
+- Never use parseInt() or Number.parseInt() when binary, octal, or hexadecimal literals work.
+- Always use concise optional chaining instead of chained logical expressions.
+- Always use regular expression literals instead of the RegExp constructor when possible.
+- Never use number literal object member names that aren't base 10 or use underscore separators.
+- Always remove redundant terms from logical expressions.
+- Always use while loops instead of for loops when you don't need initializer and update expressions.
+
+### Modern JavaScript
+
+- Always use `fetch`. Never use `axios`.
+- Always assume full modern browser support. Never include polyfills unless explicitly instructed.
+- Always use the latest version of all libraries.
+- Always use `String.slice()` instead of `String.substr()` and `String.substring()`.
+- Never use template literals if you don't need interpolation.
+- Never use `else` blocks when the `if` block breaks early.
+- Never use yoda expressions.
+- Never use Array constructors.
+- Always use `at()` instead of integer index access.
+- Always follow curly brace conventions.
+- Always use `else if` instead of nested `if` statements in `else` clauses.
+- Always use single `if` statements instead of nested `if` clauses.
+- Always use `new` for all builtins except `String`, `Number`, and `Boolean`.
+- Always use consistent accessibility modifiers on class properties and methods.
+- Always use `const` declarations for variables that are only assigned once.
+- Always put default function parameters and optional function parameters last.
+- Always include a `default` clause in switch statements.
+- Always initialize each enum member value explicitly.
+- Always use the `**` operator instead of `Math.pow`.
+- Always use `for-of` loops when you need the index to extract an item from the iterated array.
+- Always use `node:assert/strict` over `node:assert`.
+- Always use the `node:` protocol for Node.js builtin modules.
+- Always use Number properties instead of global ones.
+- Always use assignment operator shorthand where possible.
+- Always use template literals over string concatenation.
+- Always use `new` when throwing an error.
+- Never throw non-Error values.
+- Always use `String.trimStart()` and `String.trimEnd()` over `String.trimLeft()` and `String.trimRight()`.
+- Always use standard constants instead of approximated literals.
+
+### Best Practices
+
+- Always include proper error handling and logging.
+- Never have unused function parameters.
+- Never have unused imports.
+- Never have unused labels.
+- Never have unused private class members.
+- Never have unused variables.
+- Never return a value from a function that has a 'void' return type.
+- Always use isNaN() when checking for NaN.
+- Always include key props in iterators and collection literals.
+- Always ensure "for" loop update clauses move the counter in the right direction.
+- Always ensure typeof expressions are compared to valid values.
+- Always ensure generator functions contain yield.
+- Never use await inside loops.
+- Never use bitwise operators.
+- Never use expressions where the operation doesn't change the value.
+- Always ensure Promise-like statements are handled appropriately.
+- Never create import cycles.
+- Never hardcode sensitive data like API keys and tokens.
+- Never let variable declarations shadow variables from outer scopes.
diff --git a/.cursor/rules/sentry.mdc b/.cursor/rules/sentry.mdc
new file mode 100644
index 00000000..17e4e17a
--- /dev/null
+++ b/.cursor/rules/sentry.mdc
@@ -0,0 +1,120 @@
+---
+# Specify the following for Cursor rules
+description: Sentry Monitoring Guidelines
+alwaysApply: false
+---
+
+# Sentry Monitoring Guidelines
+
+Patterns for error tracking and debugging with Sentry in this project.
+
+## Configuration
+
+Sentry initialization files:
+
+- `instrumentation-client.ts` - Client-side init
+- `sentry.server.config.ts` - Server init
+- `sentry.edge.config.ts` - Edge init
+
+Import Sentry in other files: `import * as Sentry from "@sentry/nextjs"`
+
+## Exception Capture (Primary Pattern)
+
+**Always include tags and context:**
+
+```typescript
+Sentry.captureException(error, {
+	tags: {
+		operation: "operation_name", // Required - makes errors searchable
+		userId, // Include when available
+	},
+	extra: {
+		contextualData, // Debug data (not indexed)
+	},
+});
+```
+
+**Anti-pattern to avoid:**
+
+```typescript
+// BAD - No tags, not searchable
+Sentry.captureException(error);
+Sentry.captureException(`Error: ${message}`);
+
+// GOOD - Tagged and searchable
+Sentry.captureException(error, {
+	tags: { operation: "fetch_bookmark", userId },
+	extra: { bookmarkId },
+});
+```
+
+## Breadcrumbs for Cache Debugging
+
+Use `Sentry.addBreadcrumb` to track state before errors occur:
+
+```typescript
+// From /src/utils/cache-debug-helpers.ts
+Sentry.addBreadcrumb({
+	category: "optimistic-update", // Lowercase, hyphenated
+	message: "Cache miss for category",
+	level: "warning",
+	data: {
+		bookmarkId: variables.bookmark_id,
+		categoryId: variables.category_id,
+	},
+});
+```
+
+Use `logCacheMiss` helper in optimistic mutation hooks:
+
+```typescript
+import { logCacheMiss } from "@/utils/cache-debug-helpers";
+
+if (!foundItem) {
+	logCacheMiss("Optimistic Update", "Item not found in cache", {
+		itemId: variables.id,
+	});
+	return currentData;
+}
+```
+
+## API Handler Integration
+
+Response helpers in `/src/lib/api-helpers/response.ts` auto-capture exceptions:
+
+| Helper       | Sentry                  | Use For                       |
+| ------------ | ----------------------- | ----------------------------- |
+| `apiError`   | Auto-captures with tags | System/database errors        |
+| `apiWarn`    | No capture              | User errors (404, validation) |
+| `apiSuccess` | No capture              | Success responses             |
+
+```typescript
+// apiError automatically calls Sentry.captureException
+return apiError({
+	route: ROUTE,
+	message: "Failed to fetch data",
+	error,
+	operation: "fetch_bookmarks", // Becomes Sentry tag
+	userId,
+	extra: { queryParams },
+});
+```
+
+## Error Boundaries
+
+Root error boundaries capture with context:
+
+```typescript
+// /src/app/error.tsx
+Sentry.captureException(error, {
+	extra: { errorMessage: "Root error" },
+});
+```
+
+## Best Practices
+
+1. **Always tag operations** - Makes errors filterable in Sentry dashboard
+2. **Include userId when available** - Helps identify affected users
+3. **Use breadcrumbs before risky operations** - Provides context for debugging
+4. **Let response helpers handle API errors** - Consistent capture pattern
+5. **Don't capture strings** - Always pass actual Error objects
diff --git a/.cursor/rules/task-completion.mdc b/.cursor/rules/task-completion.mdc
new file mode 100644
index 00000000..0c20d64f
--- /dev/null
+++ b/.cursor/rules/task-completion.mdc
@@ -0,0 +1,200 @@
+---
+# Specify the following for Cursor rules
+description: Task completion checklist
+alwaysApply: false
+---
+
+# Task Completion Checklist
+
+## 1. Code Quality
+
+- [ ] All TypeScript strict mode checks pass (`pnpm lint:types`)
+- [ ] ESLint shows no errors or warnings (`pnpm fix:eslint`)
+- [ ] Code is properly formatted (`pnpm fix:prettier`)
+- [ ] CSS follows style guidelines (`pnpm fix:css`)
+- [ ] No spelling mistakes in code/comments (`pnpm fix:spelling`)
+- [ ] No unused code or dependencies (`pnpm fix:knip`)
+
+## Essential Commands to Run After Completing Any Development Task
+
+### 1. Code Formatting & Auto-fixing
+
+```bash
+# Format all code with Prettier
+pnpm fix:prettier
+
+# Auto-fix ESLint issues
+pnpm fix:eslint
+
+# Or run both via Turbo
+pnpm fix
+```
+
+### 2. Comprehensive Code Quality Check
+
+- [ ] All TypeScript strict mode checks pass (`pnpm lint:types`)
+- [ ] ESLint shows no errors or warnings (`pnpm fix:eslint`)
+- [ ] Code is properly formatted (`pnpm fix:prettier`)
+- [ ] CSS follows style guidelines (`pnpm fix:css`)
+- [ ] No spelling mistakes in code/comments (`pnpm fix:spelling`)
+- [ ] No unused code or dependencies (`pnpm fix:knip`)
+
+This single command validates:
+
+- TypeScript: Type checking and compilation
+- ESLint: Code quality and React patterns
+- Prettier: Code formatting consistency
+- Knip: Unused dependencies, exports, and types
+- CSS: Stylelint validation
+- Markdown: Documentation formatting
+- Spelling: CSpell dictionary validation
+
+### 3. Build Verification (Recommended)
+
+```bash
+# Ensure the application builds successfully
+pnpm build
+```
+
+## Quality Gates by Task Type
+
+### After Adding/Modifying Components
+
+1. **Format**: `pnpm fix:prettier`
+2. **Lint**: `pnpm lint:eslint`
+3. **Type Check**: `pnpm lint:types`
+4. **Accessibility**: Verify ARIA compliance in components
+5. **Build**: `pnpm build` (to catch any build-time issues)
+
+### After Styling Changes
+
+1. **CSS Lint**: `pnpm lint:css`
+2. **Format**: `pnpm fix:prettier`
+3. **TailwindCSS**: Verify class sorting is correct
+4. **Build**: `pnpm build` (to ensure CSS compilation)
+
+### After Utility/Helper Functions
+
+1. **Type Check**: `pnpm lint:types`
+2. **Unused Code**: `pnpm lint:knip`
+3. **Format**: `pnpm fix:prettier`
+4. **Test**: Verify function behavior (when tests exist)
+
+### After Documentation Changes
+
+1. **Markdown**: `pnpm fix:md`
+2. **Spelling**: `pnpm fix:spelling`
+3. **Format**: `pnpm fix:prettier`
+
+### After Dependency Changes
+
+1. **Package Check**: `pnpm check:packages`
+2. **Unused Detection**: `pnpm lint:knip`
+3. **Type Check**: `pnpm lint:types`
+4. **Build**: `pnpm build`
+
+## Pre-Commit Workflow
+
+### Automatic (via Husky + lint-staged)
+
+The following runs automatically on `git commit`:
+
+- **Prettier formatting** on all staged files
+- **Spell checking** dictionary updates
+- **Conventional commit** message validation
+
+### Manual Pre-commit Check
+
+```bash
+# Quick validation before committing
+pnpm fix && pnpm lint:types && pnpm lint:eslint
+```
+
+## Common Issues & Solutions
+
+### TypeScript Errors
+
+- Run `pnpm lint:types` to see detailed type errors
+- Ensure strict typing without `any` types
+- Use type guards instead of type assertions
+
+### ESLint Issues
+
+- Run `pnpm fix:eslint` for auto-fixable issues
+- Check accessibility rules for components
+- Verify React hooks usage patterns
+
+### Build Failures
+
+- Check Next.js configuration in `next.config.ts`
+- Verify environment variable validation
+- Review import paths and exports
+
+### Performance Issues
+
+- Run `pnpm build:analyze` to check bundle size
+- Use `pnpm build:sourcemap` for debugging
+
+## Best Practices Checklist
+
+### Code Quality
+
+- [ ] No TypeScript errors (`pnpm lint:types`)
+- [ ] No ESLint violations (`pnpm lint:eslint`)
+- [ ] Code properly formatted (`pnpm lint:prettier`)
+- [ ] No unused code (`pnpm lint:knip`)
+- [ ] Accessibility compliant (ARIA, semantic HTML)
+
+### Performance
+
+- [ ] Bundle size impact minimal (`pnpm build:analyze`)
+- [ ] Images optimized (use Next.js Image component)
+- [ ] No unnecessary re-renders
+- [ ] Proper code splitting (dynamic imports for large components)
+
+### Architecture
+
+- [ ] Follows established patterns
+- [ ] Uses path aliases (@/components/, @/utils/)
+- [ ] Proper component composition
+- [ ] Immutable data handling
+
+### Documentation
+
+- [ ] JSDoc comments for public APIs
+- [ ] README updates if needed
+- [ ] Spell check passes (`pnpm lint:spelling`)
+
+## Environment-Specific Considerations
+
+### Development
+
+- Use `pnpm dev` with hot reloading
+- Enable source maps for debugging: `SOURCEMAP=true pnpm dev`
+
+### Production Build
+
+- Always run `pnpm build` before deployment
+- Check bundle analysis: `ANALYZE=true pnpm build`
+- Verify environment variables are set
+
+### CI/CD
+
+- All linting runs in parallel via Turbo
+- Build verification on every commit
+- Conventional commit message enforcement
+
+## Quick Reference Commands
+
+```bash
+# The essentials (run after every task)
+pnpm fix && pnpm build
+
+# Fast feedback loop during development
+pnpm fix:prettier && pnpm lint:eslint && pnpm lint:types
+
+# Full quality assurance
+pnpm lint && pnpm build:analyze
+```
+
+Following this checklist ensures code quality, maintainability, and production readiness for every task completion.
diff --git a/.gitignore b/.gitignore
index 3bba9a3f..ee6af8d4 100644
--- a/.gitignore
+++ b/.gitignore
@@ -88,6 +88,8 @@ public/sitemap-0.xml
 .claude/settings.local.json
 .claude/docs
 .claude/auto-memory/dirty-files
+**/CLAUDE.md
+_plan
 .vercel
 .worktrees
 supabase/seed.sql
diff --git a/.markdownlint-cli2.jsonc b/.markdownlint-cli2.jsonc
index c563b227..d84d766a 100644
--- a/.markdownlint-cli2.jsonc
+++ b/.markdownlint-cli2.jsonc
@@ -14,5 +14,10 @@
 	"gitignore": true,
 
 	// Define glob expressions to ignore
-	"ignores": [".github/CODE_OF_CONDUCT.md", "CHANGELOG.md", ".claude/**/*.md"]
+	"ignores": [
+		".github/CODE_OF_CONDUCT.md",
+		"CHANGELOG.md",
+		".claude/**/*.md",
+		"**/CLAUDE.md"
+	]
 }
diff --git a/CLAUDE.md b/CLAUDE.md
index b75c7762..c1012f82 100644
--- a/CLAUDE.md
+++ b/CLAUDE.md
@@ -35,6 +35,26 @@ If ast-grep is available avoid tools `rg` or `grep` unless a plain‑text search
 
 ### Development Guidelines
 
+# Frontend Rules
+
+You are a Senior Front-End Developer and an Expert in ReactJS, NextJS, JavaScript, TypeScript, HTML, CSS and modern UI/UX frameworks (e.g., TailwindCSS, Shadcn, Radix). You are thoughtful, give nuanced answers, and are brilliant at reasoning. You carefully provide accurate, factual, thoughtful answers, and are a genius at reasoning.
+
+- Follow the user’s requirements carefully & to the letter.
+- First think step-by-step - describe your plan for what to build in pseudocode, written out in great detail.
+- Confirm, then write code!
+- Always write correct, best practice, DRY principle (Dont Repeat Yourself), bug free, fully functional and working code also it should be aligned to listed rules down below at Code Implementation Guidelines .
+- Focus on easy and readability code, over being performant.
+- Fully implement all requested functionality.
+- Leave NO todo’s, placeholders or missing pieces.
+- Ensure code is complete! Verify thoroughly finalised.
+- Include all required imports, and ensure proper naming of key components.
+- Be concise Minimize any other prose.
+- If you think there might not be a correct answer, you say so.
+- If you do not know the answer, say so, instead of guessing.
+- Always prefer using methods like useQuery, zustand rather than going for useEffect.
+
+Comprehensive accessibility and code quality rules for frontend development.
+
 **TypeScript:**
 
 - Only create abstractions when actually needed
@@ -220,6 +240,7 @@ Recollect is an open-source bookmark, images, and documents manager built with:
 | UI         | @ariakit/react        | 0.3.7   |
 | UI         | react-aria            | 3.45.0  |
 | Monitoring | @sentry/nextjs        | 10.32.0 |
+| State      | immer                 | 11.1.3  |
 
 <!-- END AUTO-MANAGED -->
 
diff --git a/cspell.json b/cspell.json
index cbc720c4..22ae7859 100644
--- a/cspell.json
+++ b/cspell.json
@@ -52,9 +52,9 @@
 		"dbname",
 		"dbsize",
 		"dels",
-		"DONT",
 		"dont",
 		"dotenvx",
+		"dups",
 		"eqwhx",
 		"fbca",
 		"fetchs",
@@ -134,7 +134,9 @@
 		"svgs",
 		"syncer",
 		"timelessco",
+		"timestamptz",
 		"Toastify",
+		"TOCTOU",
 		"totp",
 		"TOTP",
 		"treeify",
@@ -144,6 +146,7 @@
 		"tsvector",
 		"turborepo",
 		"Turborepo",
+		"twimg",
 		"UMAMI",
 		"umami",
 		"uncategorised",
diff --git a/docs/pr_standards_checklist.md b/docs/pr_standards_checklist.md
new file mode 100644
index 00000000..cc99d8af
--- /dev/null
+++ b/docs/pr_standards_checklist.md
@@ -0,0 +1,1423 @@
+# PR Standards Checklist
+
+This document outlines the standards expected for all pull requests in the Recollect codebase. Review this checklist before submitting any PR to ensure your code meets the project's quality standards.
+
+> **Reference PRs**:
+>
+> - ✅ **PR 694**: Excellent example of migration standards (`feat(bookmark-categories): ✨ implement many-to-many bookmark categories relationship`)
+> - ⚠️ **PR 690**: Review comments highlight common mistakes to avoid (`feat(bookmark): implement discoverable feature for bookmarks`)
+
+---
+
+## Table of Contents
+
+1. [Database Migrations](#database-migrations)
+2. [API Routes](#api-routes)
+3. [TypeScript Standards](#typescript-standards)
+4. [React & React Query Patterns](#react--react-query-patterns)
+5. [Code Quality Requirements](#code-quality-requirements)
+6. [Common Mistakes & Anti-Patterns](#common-mistakes--anti-patterns)
+7. [Pre-PR Checklist](#pre-pr-checklist)
+
+---
+
+## Database Migrations
+
+### File Naming Convention
+
+**✅ CORRECT:**
+
+```text
+20251208115323_bookmark_categories_many_to_many.sql
+```
+
+**❌ WRONG:**
+
+```text
+migration.sql
+bookmark_categories.sql
+2025-12-08_bookmark_categories.sql
+```
+
+**Rule**: Use format `YYYYMMDDHHmmss_short_description.sql` (UTC timestamp, lowercase with underscores)
+
+### Migration Structure
+
+Every migration MUST follow this structure:
+
+```sql
+-- ============================================================================
+-- MIGRATION: [Clear description of what this migration does]
+-- Created: YYYY-MM-DD
+-- Purpose: [Detailed explanation of the purpose and affected tables]
+-- ============================================================================
+--
+-- This migration:
+--   1. [Step 1 description]
+--   2. [Step 2 description]
+--   3. [Step 3 description]
+--
+-- [Any special considerations, security notes, or performance implications]
+--
+-- ============================================================================
+
+BEGIN;
+SET search_path = public, pg_temp;
+
+-- ============================================================================
+-- PART 1: [Section name]
+-- ============================================================================
+
+-- [Implementation with detailed comments]
+
+-- ============================================================================
+-- PART 2: [Next section]
+-- ============================================================================
+
+-- [More implementation]
+
+COMMIT;
+```
+
+### Required Elements
+
+#### 1. Transaction Blocks
+
+**✅ ALWAYS use BEGIN/COMMIT:**
+
+```sql
+BEGIN;
+-- All migration SQL here
+COMMIT;
+```
+
+**❌ NEVER skip transactions:**
+
+```sql
+-- Missing BEGIN/COMMIT - WRONG!
+ALTER TABLE everything ADD COLUMN make_discoverable timestamptz;
+```
+
+**Why**: Ensures atomicity - if any part fails, entire migration rolls back.
+
+#### 2. Pre-Flight Validation
+
+**✅ CORRECT - Validate prerequisites:**
+
+```sql
+-- Pre-flight validation: Ensure category_id=0 exists for uncategorized bookmarks
+DO $$
+BEGIN
+    IF NOT EXISTS (SELECT 1 FROM public.categories WHERE id = 0) THEN
+        RAISE EXCEPTION 'Migration blocked: category with id=0 does not exist. Run seed migration first.';
+    END IF;
+END $$;
+```
+
+**Why**: Prevents migrations from running in invalid states, catching issues early.
+
+#### 3. Post-Migration Verification
+
+**✅ CORRECT - Verify migration success:**
+
+```sql
+-- Post-migration verification for Part 1
+DO $$
+DECLARE
+    v_everything_count bigint;
+    v_junction_bookmark_count bigint;
+BEGIN
+    SELECT COUNT(*) INTO v_everything_count FROM public.everything;
+    SELECT COUNT(DISTINCT bookmark_id) INTO v_junction_bookmark_count FROM public.bookmark_categories;
+
+    IF v_everything_count != v_junction_bookmark_count THEN
+        RAISE EXCEPTION 'Data mismatch: % bookmarks but only % have junction entries. Rolling back.',
+            v_everything_count, v_junction_bookmark_count;
+    END IF;
+
+    RAISE NOTICE 'Junction table migration verified: all % bookmarks have junction entries', v_everything_count;
+END $$;
+```
+
+**Why**: Ensures data integrity after migration completes.
+
+#### 4. RLS Policies
+
+**✅ CORRECT - Granular policies per role and operation:**
+
+```sql
+-- SELECT: Authenticated users can view bookmark_categories if:
+-- 1. They own the entry (user_id = auth.uid())
+-- 2. They are a collaborator in the category (via shared_categories)
+-- 3. They own the category (category owner sees all)
+CREATE POLICY "bookmark_categories_select_authenticated"
+ON public.bookmark_categories FOR SELECT TO authenticated
+USING (
+    user_id = (SELECT auth.uid())
+    OR
+    category_id IN (
+        SELECT category_id
+        FROM public.shared_categories
+        WHERE email = (SELECT auth.jwt()->>'email')
+    )
+    OR
+    category_id IN (
+        SELECT id
+        FROM public.categories
+        WHERE user_id = (SELECT auth.uid())
+    )
+);
+
+-- SELECT: Anonymous users can view bookmark_categories for public categories
+CREATE POLICY "bookmark_categories_select_public"
+ON public.bookmark_categories FOR SELECT TO anon
+USING (
+    category_id IN (
+        SELECT id
+        FROM public.categories
+        WHERE is_public = true
+    )
+);
+
+-- INSERT: Users can only insert bookmark_categories for bookmarks they own
+CREATE POLICY "bookmark_categories_insert"
+ON public.bookmark_categories FOR INSERT TO authenticated
+WITH CHECK (
+    user_id = (SELECT auth.uid())
+    AND
+    public.user_owns_bookmark(bookmark_id, (SELECT auth.uid()))
+);
+```
+
+**❌ WRONG - Combined policies:**
+
+```sql
+-- WRONG: Don't combine operations or roles
+CREATE POLICY "all_access" ON public.bookmark_categories
+FOR ALL TO authenticated, anon
+USING (true);
+```
+
+**Rules**:
+
+- One policy per operation (SELECT, INSERT, UPDATE, DELETE)
+- One policy per role (authenticated, anon)
+- Always use `(SELECT auth.uid())` pattern for performance
+- Include detailed comments explaining access logic
+
+#### 5. Security Functions
+
+**✅ CORRECT - Use SECURITY DEFINER to prevent RLS recursion:**
+
+```sql
+-- Helper function to check bookmark ownership (bypasses RLS to prevent recursion)
+-- SECURITY: Function only checks ownership for the calling user (p_user_id must equal auth.uid())
+-- This prevents enumeration attacks where users could check arbitrary user_id values
+CREATE OR REPLACE FUNCTION public.user_owns_bookmark(p_bookmark_id bigint, p_user_id uuid)
+RETURNS boolean
+LANGUAGE plpgsql
+SECURITY DEFINER
+SET search_path = public, pg_temp
+STABLE
+AS $$
+BEGIN
+    -- SECURITY: Only allow checking ownership for the calling user
+    -- This prevents enumeration attacks (cannot check other users' bookmark ownership)
+    IF p_user_id IS DISTINCT FROM auth.uid() THEN
+        RETURN false;
+    END IF;
+
+    RETURN EXISTS (
+        SELECT 1 FROM public.everything
+        WHERE id = p_bookmark_id AND user_id = p_user_id
+    );
+END;
+$$;
+
+COMMENT ON FUNCTION public.user_owns_bookmark(bigint, uuid) IS
+'Helper function to check if a user owns a bookmark. Uses SECURITY DEFINER to bypass RLS and prevent infinite recursion in bookmark_categories policies. Function enforces that p_user_id must equal auth.uid() to prevent enumeration attacks.';
+```
+
+**Why**: Prevents RLS recursion when policies need to check other tables, while maintaining security.
+
+#### 6. Performance Indexes
+
+**✅ CORRECT - Index columns used in RLS policies:**
+
+```sql
+-- Create indexes for query performance
+CREATE INDEX IF NOT EXISTS idx_bookmark_categories_bookmark_id ON public.bookmark_categories(bookmark_id);
+CREATE INDEX IF NOT EXISTS idx_bookmark_categories_category_id ON public.bookmark_categories(category_id);
+CREATE INDEX IF NOT EXISTS idx_bookmark_categories_user_id ON public.bookmark_categories(user_id);
+
+-- Composite indexes for common query patterns
+CREATE INDEX IF NOT EXISTS idx_bookmark_categories_user_category ON public.bookmark_categories(user_id, category_id);
+CREATE INDEX IF NOT EXISTS idx_bookmark_categories_bookmark_user ON public.bookmark_categories(bookmark_id, user_id);
+
+-- Indexes for columns referenced in RLS policies (performance optimization)
+CREATE INDEX IF NOT EXISTS idx_categories_is_public ON public.categories(is_public);
+CREATE INDEX IF NOT EXISTS idx_shared_categories_edit_access ON public.shared_categories(edit_access);
+```
+
+**Why**: RLS policies are evaluated for every row - indexes dramatically improve performance.
+
+#### 7. Documentation Comments
+
+**✅ CORRECT - Document everything:**
+
+```sql
+COMMENT ON TABLE public.bookmark_categories IS
+'Junction table for many-to-many relationship between bookmarks (everything) and categories. Allows bookmarks to belong to multiple categories. category_id = 0 represents uncategorized bookmarks.';
+
+COMMENT ON COLUMN public.bookmark_categories.bookmark_id IS 'Foreign key to everything.id (bookmark)';
+COMMENT ON COLUMN public.bookmark_categories.category_id IS 'Foreign key to categories.id. 0 = uncategorized';
+COMMENT ON COLUMN public.bookmark_categories.user_id IS 'Owner of this bookmark-category association';
+
+COMMENT ON FUNCTION public.set_bookmark_categories IS
+'Atomically replaces all category associations for a bookmark. Uses FOR UPDATE locking to prevent race conditions. Deletes existing entries and inserts new ones in a single transaction.';
+
+COMMENT ON POLICY "bookmark_categories_select_authenticated" ON public.bookmark_categories IS
+'Allows authenticated users to view bookmark categories they own, collaborate on, or own the parent category.';
+```
+
+**Why**: Makes schema self-documenting and helps future developers understand intent.
+
+#### 8. Data Migration Patterns
+
+**✅ CORRECT - Migrate existing data carefully:**
+
+```sql
+-- Step 1: Migrate bookmarks with real categories (NOT 0)
+INSERT INTO public.bookmark_categories (bookmark_id, category_id, user_id, created_at)
+SELECT e.id, e.category_id, e.user_id, e.inserted_at
+FROM public.everything e
+WHERE e.category_id IS NOT NULL AND e.category_id != 0
+ON CONFLICT (bookmark_id, category_id) DO NOTHING;
+
+-- Step 2: Add category 0 ONLY for bookmarks that have NO entry yet (truly uncategorized)
+INSERT INTO public.bookmark_categories (bookmark_id, category_id, user_id, created_at)
+SELECT e.id, 0, e.user_id, e.inserted_at
+FROM public.everything e
+WHERE NOT EXISTS (
+    SELECT 1 FROM public.bookmark_categories bc WHERE bc.bookmark_id = e.id
+)
+ON CONFLICT (bookmark_id, category_id) DO NOTHING;
+```
+
+**Why**: Handles edge cases, prevents duplicates, and maintains data integrity.
+
+---
+
+## API Routes
+
+### Route Structure
+
+**✅ CORRECT - Use handler helpers (preferred pattern):**
+
+```typescript
+import { z } from "zod";
+import { createPostApiHandlerWithAuth } from "@/lib/api-helpers/create-handler";
+import { apiError, apiWarn } from "@/lib/api-helpers/response";
+import { HttpStatus } from "@/utils/error-utils/common";
+
+const ROUTE = "set-bookmark-categories";
+
+const SetBookmarkCategoriesPayloadSchema = z.object({
+	bookmarkId: z.number().int().positive(),
+	categoryIds: z.array(z.number().int().nonnegative()),
+});
+
+const SetBookmarkCategoriesResponseSchema = z.object({
+	bookmarkId: z.number(),
+	categoryIds: z.array(z.number()),
+});
+
+// Authenticated endpoint
+export const POST = createPostApiHandlerWithAuth({
+	route: ROUTE,
+	inputSchema: SetBookmarkCategoriesPayloadSchema,
+	outputSchema: SetBookmarkCategoriesResponseSchema,
+	handler: async ({ data, supabase, user, route }) => {
+		const { bookmarkId, categoryIds } = data;
+		const userId = user.id;
+
+		// Implementation here
+		const result = await setBookmarkCategories(
+			supabase,
+			userId,
+			bookmarkId,
+			categoryIds,
+		);
+
+		// Return data directly - handler wraps in apiSuccess automatically
+		return result;
+	},
+});
+```
+
+**✅ CORRECT - Public endpoint (no auth):**
+
+```typescript
+import { z } from "zod";
+import { createGetApiHandler } from "@/lib/api-helpers/create-handler";
+import { apiError, apiWarn } from "@/lib/api-helpers/response";
+import { createApiClient } from "@/lib/supabase/api";
+import { HttpStatus } from "@/utils/error-utils/common";
+
+const ROUTE = "fetch-discoverable-by-id";
+
+const FetchDiscoverableByIdQuerySchema = z.object({
+	id: z.coerce.number().int().positive(),
+});
+
+const ResponseSchema = z.object({
+	id: z.number(),
+	title: z.string().nullable(),
+	// ... other fields
+});
+
+// Public endpoint - no auth required
+export const GET = createGetApiHandler({
+	route: ROUTE,
+	inputSchema: FetchDiscoverableByIdQuerySchema,
+	outputSchema: ResponseSchema,
+	handler: async ({ input, route }) => {
+		const { id } = input;
+		const { supabase } = await createApiClient(); // No auth needed
+
+		const { data, error } = await supabase
+			.from("everything")
+			.select("*")
+			.eq("id", id)
+			.maybeSingle();
+
+		if (error) {
+			return apiError({
+				route,
+				message: "Failed to fetch bookmark",
+				error,
+				operation: "fetch_discoverable_bookmark",
+			});
+		}
+
+		if (!data) {
+			return apiWarn({
+				route,
+				message: "Bookmark not found",
+				status: HttpStatus.NOT_FOUND,
+				context: { id },
+			});
+		}
+
+		return data; // Handler wraps in apiSuccess automatically
+	},
+});
+```
+
+**✅ CORRECT - Manual handler (only if handler helpers don't fit):**
+
+```typescript
+import { type NextRequest } from "next/server";
+import { z } from "zod";
+import { apiError, apiSuccess, parseBody } from "@/lib/api-helpers/response";
+import { requireAuth } from "@/lib/supabase/api";
+
+const ROUTE = "set-bookmark-categories";
+
+const SetBookmarkCategoriesPayloadSchema = z.object({
+	bookmarkId: z.number().int().positive(),
+	categoryIds: z.array(z.number().int().nonnegative()),
+});
+
+const SetBookmarkCategoriesResponseSchema = z.object({
+	bookmarkId: z.number(),
+	categoryIds: z.array(z.number()),
+});
+
+export async function POST(request: NextRequest) {
+	try {
+		const auth = await requireAuth(ROUTE);
+		if (auth.errorResponse) {
+			return auth.errorResponse;
+		}
+
+		const body = await parseBody({
+			request,
+			schema: SetBookmarkCategoriesPayloadSchema,
+			route: ROUTE,
+		});
+		if (body.errorResponse) {
+			return body.errorResponse;
+		}
+
+		const { supabase, user } = auth;
+		const { bookmarkId, categoryIds } = body.data;
+
+		// Implementation here
+		const result = await setBookmarkCategories(
+			supabase,
+			user.id,
+			bookmarkId,
+			categoryIds,
+		);
+
+		return apiSuccess({
+			route: ROUTE,
+			data: result,
+			schema: SetBookmarkCategoriesResponseSchema,
+		});
+	} catch (error) {
+		return apiError({
+			route: ROUTE,
+			message: "Failed to set bookmark categories",
+			error,
+			operation: "set_bookmark_categories",
+			userId: auth?.user?.id,
+		});
+	}
+}
+```
+
+**When to use which pattern:**
+
+- **Handler helpers** (`createGetApiHandler`, `createPostApiHandlerWithAuth`, etc.): Use for standard CRUD operations - handles validation, error handling, and response formatting automatically
+- **Manual handlers**: Only use if you need custom logic that doesn't fit the handler helper pattern (e.g., streaming responses, custom middleware)
+
+### Required Patterns
+
+#### 1. Authentication & Handler Pattern
+
+**✅ CORRECT - Use handler helpers (preferred):**
+
+```typescript
+// For authenticated endpoints - use WithAuth helpers
+import {
+	createGetApiHandlerWithAuth,
+	createPostApiHandlerWithAuth,
+} from "@/lib/api-helpers/create-handler";
+
+export const GET = createGetApiHandlerWithAuth({
+	route: ROUTE,
+	inputSchema: QuerySchema,
+	outputSchema: ResponseSchema,
+	handler: async ({ data, supabase, user, route }) => {
+		// user and supabase are automatically available
+		// No need to call requireAuth manually
+	},
+});
+
+// For public endpoints - use public handlers
+import {
+	createGetApiHandler,
+	createPostApiHandler,
+} from "@/lib/api-helpers/create-handler";
+
+export const GET = createGetApiHandler({
+	route: ROUTE,
+	inputSchema: QuerySchema,
+	outputSchema: ResponseSchema,
+	handler: async ({ input, route }) => {
+		// No auth required - public endpoint
+		const { supabase } = await createApiClient();
+		// ...
+	},
+});
+```
+
+**✅ CORRECT - Manual handler (if handler helpers don't fit):**
+
+```typescript
+// For authenticated endpoints
+const auth = await requireAuth(ROUTE);
+if (auth.errorResponse) {
+	return auth.errorResponse;
+}
+const { supabase, user } = auth;
+```
+
+**❌ WRONG - Public handler with requireAuth:**
+
+```typescript
+// WRONG: Using requireAuth in public handler
+export const GET = createGetApiHandler({
+	handler: async ({ input, route }) => {
+		const auth = await requireAuth(ROUTE); // ❌ Don't do this!
+		// ...
+	},
+});
+```
+
+**❌ WRONG - No auth check in manual authenticated handler:**
+
+```typescript
+// WRONG: No auth check
+export async function POST(request: NextRequest) {
+	const body = await request.json();
+	// Direct database access without auth
+}
+```
+
+**Rules**:
+
+- **Prefer handler helpers**: Use `createGetApiHandler`, `createPostApiHandler`, `createGetApiHandlerWithAuth`, `createPostApiHandlerWithAuth`
+- **Public endpoints**: Use `createGetApiHandler`/`createPostApiHandler` (no auth)
+- **Authenticated endpoints**: Use `createGetApiHandlerWithAuth`/`createPostApiHandlerWithAuth` (auth handled automatically)
+- **Manual handlers**: Only if handler helpers don't fit your use case - must include `requireAuth` for authenticated endpoints
+
+#### 2. Input Validation
+
+**✅ CORRECT - Handler helpers handle validation automatically:**
+
+```typescript
+// Handler helpers automatically validate input/output
+export const GET = createGetApiHandler({
+	inputSchema: QuerySchema, // Automatically validates query params
+	outputSchema: ResponseSchema, // Automatically validates response
+	handler: async ({ input, route }) => {
+		// input is already validated
+		const { id } = input;
+	},
+});
+```
+
+**✅ CORRECT - Manual validation:**
+
+**✅ ALWAYS use `parseBody` (POST/PUT/PATCH) or `parseQuery` (GET) with Zod:**
+
+```typescript
+const body = await parseBody({
+	request,
+	schema: SetBookmarkCategoriesPayloadSchema,
+	route: ROUTE,
+});
+if (body.errorResponse) {
+	return body.errorResponse;
+}
+const { bookmarkId, categoryIds } = body.data;
+```
+
+**❌ NEVER trust user input:**
+
+```typescript
+// WRONG: No validation
+const body = await request.json();
+const bookmarkId = body.bookmarkId; // Could be anything!
+```
+
+#### 3. Error Handling
+
+**✅ CORRECT - Use appropriate error helpers:**
+
+```typescript
+// For user errors (4xx) - use apiWarn
+if (!bookmark) {
+	return apiWarn({
+		route: ROUTE,
+		message: "Bookmark not found",
+		status: HttpStatus.NOT_FOUND,
+		context: { bookmarkId },
+	});
+}
+
+// For system errors (5xx) - use apiError
+try {
+	// Database operation
+} catch (error) {
+	return apiError({
+		route: ROUTE,
+		message: "Failed to update bookmark",
+		error,
+		operation: "update_bookmark",
+		userId: user.id,
+	});
+}
+```
+
+**Rules**:
+
+- `apiWarn`: User errors (validation, not found, permission denied) - logs to console.warn, NO Sentry
+- `apiError`: System errors (database failures, unexpected errors) - logs to console.error AND sends to Sentry
+
+#### 4. Response Validation
+
+**✅ ALWAYS validate output with Zod:**
+
+```typescript
+return apiSuccess({
+	route: ROUTE,
+	data: result,
+	schema: SetBookmarkCategoriesResponseSchema,
+});
+```
+
+**Why**: Ensures API contracts are maintained and catches bugs early.
+
+---
+
+## TypeScript Standards
+
+### Export Rules
+
+**✅ CORRECT - Named exports only:**
+
+```typescript
+export type SetBookmarkCategoriesPayload = z.infer<
+	typeof SetBookmarkCategoriesPayloadSchema
+>;
+export type SetBookmarkCategoriesResponse = z.infer<
+	typeof SetBookmarkCategoriesResponseSchema
+>;
+export async function POST(request: NextRequest) {
+	/* ... */
+}
+```
+
+**❌ WRONG - No default exports:**
+
+```typescript
+// WRONG
+export default function POST(request: NextRequest) { /* ... */ }
+export default type MyType = { /* ... */ };
+```
+
+### Type Deduction
+
+**✅ CORRECT - Use type deduction from immediate parent:**
+
+```typescript
+// Child props = parent props, use type alias
+type ChildProps = ParentProps;
+
+// Use utility types
+type HandlerParams = Parameters<typeof myFunction>;
+type HandlerReturn = ReturnType<typeof myFunction>;
+type UserEmail = Pick<User, "email">;
+```
+
+**❌ WRONG - Don't skip to grandparents:**
+
+```typescript
+// WRONG: Skipping parent
+type ChildProps = GrandparentProps; // Should use ParentProps instead
+```
+
+### Type Safety
+
+**✅ CORRECT - Strict types, no `any`:**
+
+```typescript
+const result: SetBookmarkCategoriesResponse = {
+    bookmarkId: number,
+    categoryIds: number[],
+};
+```
+
+**❌ WRONG - Never use `any` or `@ts-ignore`:**
+
+```typescript
+// WRONG
+const result: any = {
+	/* ... */
+};
+// @ts-ignore
+const unsafe = someFunction();
+```
+
+### Type Exports
+
+**✅ CORRECT - Only export types used elsewhere:**
+
+```typescript
+// Check with grep first before exporting
+export type SetBookmarkCategoriesPayload = z.infer<typeof Schema>; // Used in other files
+type InternalHelperType = {
+	/* ... */
+}; // Not exported - only used locally
+```
+
+---
+
+## React & React Query Patterns
+
+### Hook Naming
+
+**✅ CORRECT - kebab-case file names, camelCase exports:**
+
+```text
+use-bookmark-categories.ts
+use-set-bookmark-categories.ts
+```
+
+```typescript
+export function useSetBookmarkCategories() {
+	/* ... */
+}
+```
+
+**❌ WRONG:**
+
+```text
+useBookmarkCategories.ts  // Wrong file name
+export default function useSetBookmarkCategories() { /* ... */ }  // Wrong export
+```
+
+### Optimistic Mutations
+
+**✅ CORRECT - Follow the pattern:**
+
+```typescript
+export function useSetBookmarkCategoriesOptimisticMutation() {
+	const queryClient = useQueryClient();
+	const session = useSupabaseSession((state) => state.session);
+
+	const mutation = useMutation({
+		mutationFn: setBookmarkCategories,
+		onMutate: async (data) => {
+			// Cancel any outgoing refetches
+			await queryClient.cancelQueries({
+				queryKey: [BOOKMARKS_KEY, session?.user?.id],
+			});
+
+			// Snapshot the previous value
+			const previousData = queryClient.getQueryData([
+				BOOKMARKS_KEY,
+				session?.user?.id,
+			]);
+
+			// Optimistically update to the new value
+			queryClient.setQueryData(
+				[BOOKMARKS_KEY, session?.user?.id],
+				(old: BookmarksData | undefined) => {
+					if (!old?.data) {
+						return old;
+					}
+					return {
+						...old,
+						data: old.data.map((bookmark) =>
+							bookmark.id === data.bookmarkId
+								? { ...bookmark, categoryIds: data.categoryIds }
+								: bookmark,
+						),
+					};
+				},
+			);
+
+			// Return context for rollback
+			return { previousData };
+		},
+		// Rollback on error
+		onError: (error, variables, context) => {
+			if (context?.previousData) {
+				queryClient.setQueryData(
+					[BOOKMARKS_KEY, session?.user?.id],
+					context.previousData,
+				);
+			}
+		},
+		// Always refetch after error or success
+		onSettled: () => {
+			void queryClient.invalidateQueries({
+				queryKey: [BOOKMARKS_KEY, session?.user?.id],
+			});
+		},
+	});
+
+	return { mutation };
+}
+```
+
+**Key Points**:
+
+- Cancel queries in `onMutate`
+- Snapshot previous data for rollback
+- Update optimistically
+- Rollback in `onError`
+- Invalidate in `onSettled`
+
+### Query Invalidation
+
+**✅ CORRECT - Invalidate related queries:**
+
+```typescript
+onSuccess: () => {
+    void queryClient.invalidateQueries({
+        queryKey: [BOOKMARKS_KEY, session?.user?.id],
+    });
+    void queryClient.invalidateQueries({
+        queryKey: [CATEGORIES_KEY, session?.user?.id],
+    });
+},
+```
+
+---
+
+## Code Quality Requirements
+
+### File Size
+
+**✅ CORRECT - Max 250 lines per file:**
+
+- Split larger files into modules
+- Extract reusable logic into utilities
+- Use composition over large monolithic files
+
+### Functional Programming
+
+**✅ CORRECT - Only functional code:**
+
+```typescript
+export function processBookmarks(bookmarks: Bookmark[]): ProcessedBookmark[] {
+	return bookmarks.map(transformBookmark);
+}
+```
+
+**❌ WRONG - No classes:**
+
+```typescript
+// WRONG
+class BookmarkProcessor {
+	process(bookmarks: Bookmark[]) {
+		/* ... */
+	}
+}
+```
+
+### Linting & Formatting
+
+**✅ ALWAYS run before PR:**
+
+```bash
+pnpm fix:eslint <changed-files>
+pnpm lint:types
+pnpm fix:prettier
+```
+
+**Required checks**:
+
+- ESLint passes
+- TypeScript strict mode passes
+- Prettier formatting applied
+- No unused code (knip)
+
+### Code Style
+
+**✅ Follow conventions:**
+
+- Components: `PascalCase`
+- Functions: `camelCase`
+- Constants: `UPPER_SNAKE_CASE`
+- Files: `kebab-case` for hooks/utils, `PascalCase` for components
+
+### Code Reuse
+
+**✅ ALWAYS check for existing implementations before creating new ones:**
+
+```typescript
+// ✅ CORRECT: Search for existing hooks/functions first
+// Before creating a new hook, check:
+// - src/hooks/ for custom hooks
+// - src/async/mutationHooks/ for mutation hooks
+// - src/async/queryHooks/ for query hooks
+// - src/utils/ for utility functions
+// - src/components/ for reusable components
+
+// Example: Need to fetch categories?
+// ✅ Use existing: useFetchCategories() from src/async/queryHooks/category/
+// ❌ Don't create: useGetCategories() or fetchCategories()
+
+// Example: Need to add category to bookmark?
+// ✅ Use existing: useAddCategoryToBookmarkOptimisticMutation() from src/async/mutationHooks/category/
+// ❌ Don't create: useSetBookmarkCategory() or addCategory()
+```
+
+**❌ WRONG - Creating duplicates:**
+
+```typescript
+// WRONG: Creating duplicate functionality
+export function useGetCategories() {
+	// Same functionality as existing useFetchCategories()
+}
+
+// WRONG: Creating duplicate component
+export function CategoryList() {
+	// Same functionality as existing CategoriesList component
+}
+
+// WRONG: Creating duplicate utility
+export function formatDate(date: Date) {
+	// Same functionality as existing formatDate() in utils/
+}
+```
+
+**Rules:**
+
+- **Search first**: Use `grep`, `rg`, or `ast-grep` to find existing implementations
+- **Check imports**: Look at how other files solve similar problems
+- **Reuse patterns**: Follow established patterns rather than inventing new ones
+- **Extend, don't duplicate**: If existing code is close but not perfect, extend it rather than duplicating
+- **Ask if unsure**: If you can't find existing code, ask in PR comments before creating new
+
+**Why**: Reduces code duplication, maintains consistency, and leverages tested, battle-hardened code.
+
+---
+
+## Common Mistakes & Anti-Patterns
+
+### Code Reuse Mistakes
+
+#### ❌ Creating Duplicate Functionality
+
+**Problem:**
+
+```typescript
+// WRONG: Creating duplicate hook when useFetchCategories already exists
+export function useGetCategories() {
+	const [categories, setCategories] = useState([]);
+	// ... same logic as existing useFetchCategories
+}
+
+// WRONG: Creating duplicate component
+export function CategoryDropdown() {
+	// ... same functionality as existing component
+}
+
+// WRONG: Creating duplicate utility
+export function formatDate(date: Date) {
+	// ... same logic as existing formatDate in utils/
+}
+```
+
+**Fix:**
+
+```typescript
+// CORRECT: Use existing hook
+import { useFetchCategories } from "@/async/queryHooks/category/useFetchCategories";
+
+// CORRECT: Use existing component
+import { CategorySelect } from "@/components/category-select";
+
+// CORRECT: Use existing utility
+import { formatDate } from "@/utils/date-utils";
+```
+
+**How to check:**
+
+```bash
+# Search for existing hooks
+rg "useFetch.*Categories" src/hooks/ src/async/
+
+# Search for existing components
+rg "Category.*Select|Category.*Dropdown" src/components/
+
+# Search for existing utilities
+rg "formatDate|format.*date" src/utils/
+```
+
+### Migration Mistakes
+
+#### ❌ Missing Transaction Blocks
+
+**Problem:**
+
+```sql
+-- WRONG: No BEGIN/COMMIT
+ALTER TABLE everything ADD COLUMN make_discoverable timestamptz;
+CREATE POLICY "anon_discover_access" ON everything FOR SELECT TO anon USING (make_discoverable IS NOT NULL);
+```
+
+**Fix:**
+
+```sql
+BEGIN;
+ALTER TABLE everything ADD COLUMN make_discoverable timestamptz;
+CREATE POLICY "anon_discover_access" ON everything FOR SELECT TO anon USING (make_discoverable IS NOT NULL);
+COMMIT;
+```
+
+#### ❌ Incomplete RLS Policies
+
+**Problem:**
+
+```sql
+-- WRONG: Only one policy for all operations
+CREATE POLICY "all_access" ON everything FOR ALL TO authenticated USING (true);
+```
+
+**Fix:**
+
+```sql
+-- Separate policies per operation and role
+CREATE POLICY "everything_select_authenticated" ON everything FOR SELECT TO authenticated USING (user_id = (SELECT auth.uid()));
+CREATE POLICY "everything_select_anon" ON everything FOR SELECT TO anon USING (is_public = true);
+CREATE POLICY "everything_insert" ON everything FOR INSERT TO authenticated WITH CHECK (user_id = (SELECT auth.uid()));
+CREATE POLICY "everything_update" ON everything FOR UPDATE TO authenticated USING (user_id = (SELECT auth.uid())) WITH CHECK (user_id = (SELECT auth.uid()));
+CREATE POLICY "everything_delete" ON everything FOR DELETE TO authenticated USING (user_id = (SELECT auth.uid()));
+```
+
+#### ❌ Missing Indexes
+
+**Problem:**
+
+```sql
+-- WRONG: RLS policy uses column without index
+CREATE POLICY "user_access" ON everything FOR SELECT TO authenticated
+USING (category_id IN (SELECT category_id FROM shared_categories WHERE email = (SELECT auth.jwt()->>'email')));
+-- No index on shared_categories.category_id or shared_categories.email
+```
+
+**Fix:**
+
+```sql
+-- Add indexes for RLS performance
+CREATE INDEX IF NOT EXISTS idx_shared_categories_category_id ON public.shared_categories (category_id);
+CREATE INDEX IF NOT EXISTS idx_shared_categories_email ON public.shared_categories (email);
+CREATE INDEX IF NOT EXISTS idx_shared_categories_category_id_email ON public.shared_categories (category_id, email);
+```
+
+#### ❌ Missing Documentation
+
+**Problem:**
+
+```sql
+-- WRONG: No comments explaining purpose
+CREATE TABLE bookmark_categories (
+    bookmark_id bigint,
+    category_id bigint
+);
+```
+
+**Fix:**
+
+```sql
+CREATE TABLE bookmark_categories (
+    bookmark_id bigint,
+    category_id bigint
+);
+
+COMMENT ON TABLE public.bookmark_categories IS
+'Junction table for many-to-many relationship between bookmarks and categories.';
+COMMENT ON COLUMN public.bookmark_categories.bookmark_id IS 'Foreign key to everything.id';
+COMMENT ON COLUMN public.bookmark_categories.category_id IS 'Foreign key to categories.id';
+```
+
+### API Route Mistakes
+
+#### ❌ Missing Authentication or Wrong Handler Type
+
+**Problem:**
+
+```typescript
+// WRONG: No auth check in manual handler
+export async function POST(request: NextRequest) {
+	const body = await request.json();
+	// Direct database access without auth
+}
+
+// WRONG: Using requireAuth in public handler
+export const GET = createGetApiHandler({
+	handler: async ({ input, route }) => {
+		const auth = await requireAuth(ROUTE); // ❌ Public handler shouldn't require auth
+		// ...
+	},
+});
+```
+
+**Fix:**
+
+```typescript
+// CORRECT: Use authenticated handler helper
+export const POST = createPostApiHandlerWithAuth({
+	route: ROUTE,
+	inputSchema: PayloadSchema,
+	outputSchema: ResponseSchema,
+	handler: async ({ data, supabase, user, route }) => {
+		// Auth handled automatically
+		// Now safe to proceed
+	},
+});
+
+// OR: Manual handler with requireAuth
+export async function POST(request: NextRequest) {
+	const auth = await requireAuth(ROUTE);
+	if (auth.errorResponse) {
+		return auth.errorResponse;
+	}
+	const { supabase, user } = auth;
+	// Now safe to proceed
+}
+
+// CORRECT: Public handler (no auth)
+export const GET = createGetApiHandler({
+	route: ROUTE,
+	inputSchema: QuerySchema,
+	outputSchema: ResponseSchema,
+	handler: async ({ input, route }) => {
+		// Public endpoint - no auth required
+		const { supabase } = await createApiClient();
+		// ...
+	},
+});
+```
+
+#### ❌ Missing Input Validation
+
+**Problem:**
+
+```typescript
+// WRONG: No validation
+const body = await request.json();
+const bookmarkId = body.bookmarkId; // Could be string, null, undefined, etc.
+```
+
+**Fix:**
+
+```typescript
+const body = await parseBody({
+	request,
+	schema: z.object({
+		bookmarkId: z.number().int().positive(),
+	}),
+	route: ROUTE,
+});
+if (body.errorResponse) {
+	return body.errorResponse;
+}
+const { bookmarkId } = body.data; // Type-safe!
+```
+
+#### ❌ Wrong Error Type
+
+**Problem:**
+
+```typescript
+// WRONG: Using apiError for user validation error
+if (!bookmark) {
+	return apiError({
+		route: ROUTE,
+		message: "Bookmark not found",
+		error: new Error("Not found"),
+		operation: "get_bookmark",
+	}); // This sends to Sentry unnecessarily
+}
+```
+
+**Fix:**
+
+```typescript
+// CORRECT: Use apiWarn for user errors
+if (!bookmark) {
+	return apiWarn({
+		route: ROUTE,
+		message: "Bookmark not found",
+		status: HttpStatus.NOT_FOUND,
+		context: { bookmarkId },
+	}); // No Sentry, just logs warning
+}
+```
+
+### TypeScript Mistakes
+
+#### ❌ Using `any`
+
+**Problem:**
+
+```typescript
+// WRONG
+function processData(data: any) {
+	return data.someProperty;
+}
+```
+
+**Fix:**
+
+```typescript
+// CORRECT
+type DataType = {
+	someProperty: string;
+};
+function processData(data: DataType) {
+	return data.someProperty;
+}
+```
+
+#### ❌ Default Exports
+
+**Problem:**
+
+```typescript
+// WRONG
+export default function useBookmarkCategories() {
+	/* ... */
+}
+```
+
+**Fix:**
+
+```typescript
+// CORRECT
+export function useBookmarkCategories() {
+	/* ... */
+}
+```
+
+### React Query Mistakes
+
+#### ❌ Missing Rollback
+
+**Problem:**
+
+```typescript
+// WRONG: No rollback on error
+onMutate: async (data) => {
+    queryClient.setQueryData([KEY], newData);
+    // No snapshot, no rollback
+},
+```
+
+**Fix:**
+
+```typescript
+// CORRECT: Snapshot and rollback
+onMutate: async (data) => {
+    await queryClient.cancelQueries({ queryKey: [KEY] });
+    const previousData = queryClient.getQueryData([KEY]);
+    queryClient.setQueryData([KEY], newData);
+    return { previousData };
+},
+onError: (error, variables, context) => {
+    if (context?.previousData) {
+        queryClient.setQueryData([KEY], context.previousData);
+    }
+},
+```
+
+---
+
+## Pre-PR Checklist
+
+Use this checklist before submitting any PR. Check each item to ensure your code meets standards.
+
+### Checklist: Database Migrations
+
+- [ ] Migration file named correctly (`YYYYMMDDHHmmss_description.sql`)
+- [ ] Comprehensive header comment with purpose and affected tables
+- [ ] Wrapped in `BEGIN;` / `COMMIT;` transaction block
+- [ ] Pre-flight validation (DO blocks) for prerequisites
+- [ ] Post-migration verification (DO blocks) for data integrity
+- [ ] RLS policies created (one per operation, one per role)
+- [ ] RLS policies use `(SELECT auth.uid())` pattern for performance
+- [ ] Indexes created for columns used in RLS policies
+- [ ] Indexes created for foreign keys and common query patterns
+- [ ] `COMMENT ON` statements for tables, columns, functions, policies
+- [ ] Data migration handles edge cases (NULLs, duplicates, conflicts)
+- [ ] Security functions use `SECURITY DEFINER` with proper checks
+- [ ] Functions include `SET search_path = public, pg_temp`
+- [ ] All SQL keywords in UPPERCASE (consistent within file)
+
+### Checklist: API Routes
+
+- [ ] **Handler pattern**:
+  - [ ] Uses handler helpers (`createGetApiHandler`, `createPostApiHandler`, etc.) when possible
+  - [ ] Uses `createGetApiHandlerWithAuth`/`createPostApiHandlerWithAuth` for authenticated endpoints
+  - [ ] Uses `createGetApiHandler`/`createPostApiHandler` for public endpoints (no auth)
+  - [ ] If manual handler, uses `requireAuth` for authenticated endpoints only
+  - [ ] Public handlers do NOT use `requireAuth`
+- [ ] Uses `parseBody` with Zod schema (POST/PUT/PATCH) or `parseQuery` (GET) - or handler helpers handle this
+- [ ] Uses `apiSuccess` with Zod schema for output validation - or handler helpers handle this
+- [ ] Uses `apiWarn` for user errors (4xx)
+- [ ] Uses `apiError` for system errors (5xx)
+- [ ] Error handling in try/catch block (if manual handler, helpers handle it automatically)
+- [ ] Sentry integration for system errors only
+- [ ] Route constant defined (`const ROUTE = "..."`)
+
+### TypeScript
+
+- [ ] No `any` types used
+- [ ] No `@ts-ignore` or `@ts-expect-error` directives
+- [ ] Named exports only (no default exports)
+- [ ] Types exported only if used in other files
+- [ ] Type deduction from immediate parent (not grandparent)
+- [ ] Uses utility types (`Parameters<>`, `ReturnType<>`, `Pick<>`, etc.) where appropriate
+- [ ] Strict mode passes (`pnpm lint:types`)
+
+### React & React Query
+
+- [ ] Hook file named in kebab-case (`use-bookmark-categories.ts`)
+- [ ] Hook function exported as named export (not default)
+- [ ] Optimistic mutations include:
+  - [ ] `cancelQueries` in `onMutate`
+  - [ ] Snapshot previous data
+  - [ ] Rollback in `onError`
+  - [ ] Invalidate in `onSettled`
+- [ ] Query invalidation includes all related queries
+- [ ] No array indices as React keys
+- [ ] Hooks at top level with all dependencies
+
+### Code Quality
+
+- [ ] File size ≤ 250 lines (split if larger)
+- [ ] Functional programming only (no classes)
+- [ ] ESLint passes (`pnpm fix:eslint <changed-files>`)
+- [ ] Prettier formatting applied (`pnpm fix:prettier`)
+- [ ] TypeScript strict mode passes (`pnpm lint:types`)
+- [ ] No unused code (check with `pnpm lint:knip`)
+- [ ] Naming conventions followed:
+  - [ ] Components: `PascalCase`
+  - [ ] Functions: `camelCase`
+  - [ ] Constants: `UPPER_SNAKE_CASE`
+  - [ ] Files: `kebab-case` for hooks/utils
+- [ ] **Code reuse checked**:
+  - [ ] Searched for existing hooks before creating new ones (`src/hooks/`, `src/async/`)
+  - [ ] Searched for existing components before creating new ones (`src/components/`)
+  - [ ] Searched for existing utilities before creating new ones (`src/utils/`)
+  - [ ] Used existing patterns rather than inventing new ones
+
+### Documentation
+
+- [ ] Migration includes header comments explaining purpose
+- [ ] Complex logic includes inline comments
+- [ ] Functions include JSDoc comments where helpful
+- [ ] Database objects have `COMMENT ON` statements
+
+### Testing & Verification
+
+- [ ] Migration tested locally (`supabase db reset` and verify)
+- [ ] API routes tested with valid/invalid inputs
+- [ ] Error cases tested (auth failures, validation errors)
+- [ ] RLS policies tested (different user roles)
+- [ ] **No console.log statements** left in frontend
+- [ ] No commented-out code
+
+### Security
+
+- [ ] RLS policies properly restrict access
+- [ ] No SQL injection vulnerabilities (use parameterized queries)
+- [ ] No authentication bypasses
+- [ ] Input validation on all user inputs
+- [ ] Sensitive data not logged
+
+---
+
+## Reference Documentation
+
+- [CLAUDE.md](../CLAUDE.md) - Core project guidelines
+- [Migration Guidelines](.cursor/rules/supabase-create-migration.mdc) - Migration standards
+- [RLS Policy Guidelines](.cursor/rules/supabase-create-rls-policies.mdc) - RLS best practices
+- [Code Style Conventions](../CLAUDE.md#code-style-conventions) - Code style rules
+- [Task Completion Checklist](../CLAUDE.md#task-completion-checklist) - Required checks before completing tasks
+
+---
+
+## Questions?
+
+If you're unsure about any standard, check:
+
+1. PR 694 (`feat(bookmark-categories): ✨ implement many-to-many bookmark categories relationship`) - Excellent reference
+2. Existing migrations in `supabase/migrations/` - Follow established patterns
+3. Existing API routes in `src/app/api/` or `src/pages/api/` - Follow established patterns
+4. Ask in PR comments before submitting - Better to clarify early!
+
+---
+
+**Last Updated**: 2026-01-05
+**Maintained By**: Development Team
diff --git a/docs/sentry_rules.md b/docs/sentry_rules.md
deleted file mode 100644
index 03b81587..00000000
--- a/docs/sentry_rules.md
+++ /dev/null
@@ -1,126 +0,0 @@
-These examples should be used as guidance when configuring Sentry functionality within a project.
-
-# Exception Catching
-
-Use `Sentry.captureException(error)` to capture an exception and log the error in Sentry.
-Use this in try catch blocks or areas where exceptions are expected
-
-# Tracing Examples
-
-Spans should be created for meaningful actions within an applications like button clicks, API calls, and function calls
-Use the `Sentry.startSpan` function to create a span
-Child spans can exist within a parent span
-
-## Custom Span instrumentation in component actions
-
-The `name` and `op` properties should be meaningful for the activities in the call.
-Attach attributes based on relevant information and metrics from the request
-
-```javascript
-function TestComponent() {
-	const handleTestButtonClick = () => {
-		// Create a transaction/span to measure performance
-		Sentry.startSpan(
-			{
-				op: "ui.click",
-				name: "Test Button Click",
-			},
-			(span) => {
-				const value = "some config";
-				const metric = "some metric";
-
-				// Metrics can be added to the span
-				span.setAttribute("config", value);
-				span.setAttribute("metric", metric);
-
-				doSomething();
-			},
-		);
-	};
-
-	return (
-		<button type="button" onClick={handleTestButtonClick}>
-			Test Sentry
-		</button>
-	);
-}
-```
-
-## Custom span instrumentation in API calls
-
-The `name` and `op` properties should be meaningful for the activities in the call.
-Attach attributes based on relevant information and metrics from the request
-
-```javascript
-async function fetchUserData(userId) {
-	return Sentry.startSpan(
-		{
-			op: "http.client",
-			name: `GET /api/users/${userId}`,
-		},
-		async () => {
-			const response = await fetch(`/api/users/${userId}`);
-			const data = await response.json();
-			return data;
-		},
-	);
-}
-```
-
-# Logs
-
-Where logs are used, ensure Sentry is imported using `import * as Sentry from "@sentry/nextjs"`
-Enable logging in Sentry using `Sentry.init({ _experiments: { enableLogs: true } })`
-Reference the logger using `const { logger } = Sentry`
-Sentry offers a consoleLoggingIntegration that can be used to log specific console error types automatically without instrumenting the individual logger calls
-
-## Configuration
-
-In NextJS the client side Sentry initialization is in `instrumentation-client.ts`, the server initialization is in `sentry.server.config.ts` and the edge initialization is in `sentry.edge.config.ts`
-Initialization does not need to be repeated in other files, it only needs to happen the files mentioned above. You should use `import * as Sentry from "@sentry/nextjs"` to reference Sentry functionality
-
-### Baseline
-
-```javascript
-import * as Sentry from "@sentry/nextjs";
-
-Sentry.init({
-	dsn: "https://examplePublicKey@o0.ingest.sentry.io/0",
-
-	enableLogs: true,
-});
-```
-
-### Logger Integration
-
-```javascript
-Sentry.init({
-	dsn: "https://examplePublicKey@o0.ingest.sentry.io/0",
-	integrations: [
-		// send console.log, console.warn, and console.error calls as logs to Sentry
-		Sentry.consoleLoggingIntegration({ levels: ["log", "warn", "error"] }),
-	],
-});
-```
-
-## Logger Examples
-
-`logger.fmt` is a template literal function that should be used to bring variables into the structured logs.
-
-```javascript
-logger.trace("Starting database connection", { database: "users" });
-logger.debug(logger.fmt`Cache miss for user: ${userId}`);
-logger.info("Updated profile", { profileId: 345 });
-logger.warn("Rate limit reached for endpoint", {
-	endpoint: "/api/results/",
-	isEnterprise: false,
-});
-logger.error("Failed to process payment", {
-	orderId: "order_123",
-	amount: 99.99,
-});
-logger.fatal("Database connection pool exhausted", {
-	database: "users",
-	activeConnections: 100,
-});
-```
diff --git a/package.json b/package.json
index 72c8f15f..d356295d 100644
--- a/package.json
+++ b/package.json
@@ -107,6 +107,7 @@
 		"date-fns": "2.29.3",
 		"formidable": "3.5.4",
 		"image-size": "2.0.2",
+		"immer": "11.1.3",
 		"input-otp": "1.4.2",
 		"jsonwebtoken": "9.0.3",
 		"jwt-decode": "4.0.0",
diff --git a/pnpm-lock.yaml b/pnpm-lock.yaml
index 352e6858..def3570b 100644
--- a/pnpm-lock.yaml
+++ b/pnpm-lock.yaml
@@ -96,6 +96,9 @@ importers:
       image-size:
         specifier: 2.0.2
         version: 2.0.2
+      immer:
+        specifier: 11.1.3
+        version: 11.1.3
       input-otp:
         specifier: 1.4.2
         version: 1.4.2(react-dom@19.2.3(react@19.2.3))(react@19.2.3)
@@ -188,7 +191,7 @@ importers:
         version: 4.2.1
       zustand:
         specifier: 5.0.9
-        version: 5.0.9(@types/react@19.2.7)(react@19.2.3)(use-sync-external-store@1.6.0(react@19.2.3))
+        version: 5.0.9(@types/react@19.2.7)(immer@11.1.3)(react@19.2.3)(use-sync-external-store@1.6.0(react@19.2.3))
     devDependencies:
       '@commitlint/cli':
         specifier: 20.2.0
@@ -6286,6 +6289,9 @@ packages:
   immediate@3.0.6:
     resolution: {integrity: sha512-XXOFtyqDjNDAQxVfYxuF7g9Il/IbWmmlQg2MYKOH8ExIT1qg6xc4zyS3HaEEATgs1btfzxq15ciUiY7gjSXRGQ==}
 
+  immer@11.1.3:
+    resolution: {integrity: sha512-6jQTc5z0KJFtr1UgFpIL3N9XSC3saRaI9PwWtzM2pSqkNGtiNkYY2OSwkOGDK2XcTRcLb1pi/aNkKZz0nxVH4Q==}
+
   import-fresh@3.3.1:
     resolution: {integrity: sha512-TR3KfrTZTYLPB6jUjfx6MF9WcWrHL9su5TObK4ZkYgBdWKPOFoSoQIdEuTuR82pmtxH2spWG9h6etwfr1pLBqQ==}
     engines: {node: '>=6'}
@@ -9094,6 +9100,7 @@ packages:
   whatwg-encoding@3.1.1:
     resolution: {integrity: sha512-6qN4hJdMwfYBtE3YBTTHhoeuUrDBPZmbQaxWAqSALV/MeEnR5z1xd8UKud2RAkFoPkmB+hli1TZSnyi84xz1vQ==}
     engines: {node: '>=18'}
+    deprecated: Use @exodus/bytes instead for a more spec-conformant and faster implementation
 
   whatwg-mimetype@4.0.0:
     resolution: {integrity: sha512-QaKxh0eNIi2mE9p2vEdzfagOKHCcj1pJ56EEHGQOVxp8r9/iszLUUV7v89x9O1p/T+NlTM5W7jW6+cz4Fq1YVg==}
@@ -16721,6 +16728,8 @@ snapshots:
 
   immediate@3.0.6: {}
 
+  immer@11.1.3: {}
+
   import-fresh@3.3.1:
     dependencies:
       parent-module: 1.0.1
@@ -19996,8 +20005,9 @@ snapshots:
 
   zod@4.2.1: {}
 
-  zustand@5.0.9(@types/react@19.2.7)(react@19.2.3)(use-sync-external-store@1.6.0(react@19.2.3)):
+  zustand@5.0.9(@types/react@19.2.7)(immer@11.1.3)(react@19.2.3)(use-sync-external-store@1.6.0(react@19.2.3)):
     optionalDependencies:
       '@types/react': 19.2.7
+      immer: 11.1.3
       react: 19.2.3
       use-sync-external-store: 1.6.0(react@19.2.3)
diff --git a/src/app/api/bookmark/fetch-bookmarks-discoverable/route.ts b/src/app/api/bookmark/fetch-bookmarks-discoverable/route.ts
new file mode 100644
index 00000000..642b2b76
--- /dev/null
+++ b/src/app/api/bookmark/fetch-bookmarks-discoverable/route.ts
@@ -0,0 +1,118 @@
+import { z } from "zod";
+
+import { createGetApiHandler } from "@/lib/api-helpers/create-handler";
+import { apiError } from "@/lib/api-helpers/response";
+import { createApiClient } from "@/lib/supabase/api";
+import { MAIN_TABLE_NAME, PAGINATION_LIMIT } from "@/utils/constants";
+
+const ROUTE = "fetch-bookmarks-discoverable";
+
+const FetchDiscoverBookmarksQuerySchema = z.object({
+	page: z.coerce.number().int().nonnegative(),
+});
+
+const MetadataSchema = z.object({
+	coverImage: z.string().nullable().optional(),
+	favIcon: z.string().nullable().optional(),
+	height: z.number().nullable().optional(),
+	iframeAllowed: z.boolean().nullable().optional(),
+	img_caption: z.string().nullable().optional(),
+	isOgImagePreferred: z.boolean().optional(),
+	isPageScreenshot: z.boolean().nullable().optional(),
+	mediaType: z.string().nullable().optional(),
+	ocr: z.string().nullable().optional(),
+	ogImgBlurUrl: z.string().nullable().optional(),
+	screenshot: z.string().nullable().optional(),
+	twitter_avatar_url: z.string().nullable().optional(),
+	video_url: z.string().nullable().optional(),
+	width: z.number().nullable().optional(),
+});
+
+const DiscoverableBookmarkRowSchema = z.object({
+	id: z.number(),
+	inserted_at: z.string(),
+	title: z.string().nullable(),
+	url: z.string().nullable(),
+	description: z.string().nullable(),
+	ogImage: z.string().nullable(),
+	screenshot: z.string().nullable(),
+	category_id: z.number(),
+	trash: z.boolean(),
+	type: z.string().nullable(),
+	meta_data: MetadataSchema.nullable(),
+	sort_index: z.string().nullable(),
+	make_discoverable: z.string().nullable(),
+});
+
+const FetchDiscoverBookmarksResponseSchema = z.array(
+	DiscoverableBookmarkRowSchema,
+);
+
+const getRange = (page: number) => {
+	const rangeStart = page * PAGINATION_LIMIT;
+	const rangeEnd = (page + 1) * PAGINATION_LIMIT - 1;
+
+	return { rangeEnd, rangeStart };
+};
+
+export const GET = createGetApiHandler({
+	inputSchema: FetchDiscoverBookmarksQuerySchema,
+	outputSchema: FetchDiscoverBookmarksResponseSchema,
+	route: ROUTE,
+	handler: async ({ input, route }) => {
+		const { page } = input;
+		const { rangeEnd, rangeStart } = getRange(page);
+
+		console.log(`[${route}] API called:`, {
+			page,
+			rangeStart,
+			rangeEnd,
+		});
+
+		const { supabase } = await createApiClient();
+
+		const { data, error } = await supabase
+			.from(MAIN_TABLE_NAME)
+			.select(
+				`
+				id,
+				inserted_at,
+				title,
+				url,
+				description,
+				ogImage,
+				screenshot,
+				category_id,
+				trash,
+				type,
+				meta_data,
+				sort_index,
+				make_discoverable
+			`,
+			)
+			.eq("trash", false)
+			.not("make_discoverable", "is", null)
+			.order("make_discoverable", { ascending: false })
+			.range(rangeStart, rangeEnd);
+
+		if (error) {
+			return apiError({
+				route,
+				message: "Failed to fetch discoverable bookmarks",
+				error,
+				operation: "fetch_discoverable_bookmarks",
+				extra: {
+					page,
+					rangeStart,
+					rangeEnd,
+				},
+			});
+		}
+
+		console.log(`[${route}] Discoverable bookmarks fetched successfully:`, {
+			count: data.length,
+		});
+
+		return data;
+	},
+});
diff --git a/src/app/api/bookmark/fetch-public-bookmark-by-id/route.ts b/src/app/api/bookmark/fetch-public-bookmark-by-id/route.ts
new file mode 100644
index 00000000..fe70b522
--- /dev/null
+++ b/src/app/api/bookmark/fetch-public-bookmark-by-id/route.ts
@@ -0,0 +1,217 @@
+import { z } from "zod";
+
+import { createGetApiHandler } from "@/lib/api-helpers/create-handler";
+import { apiError, apiWarn } from "@/lib/api-helpers/response";
+import {
+	BOOKMARK_CATEGORIES_TABLE_NAME,
+	CATEGORIES_TABLE_NAME,
+	MAIN_TABLE_NAME,
+} from "@/utils/constants";
+import { createServiceClient } from "@/utils/supabaseClient";
+
+const ROUTE = "fetch-public-bookmark-by-id";
+
+const FetchPublicBookmarkByIdQuerySchema = z.object({
+	bookmark_id: z
+		.string()
+		.regex(/^\d+$/u, "Bookmark ID must be numeric")
+		.transform(Number),
+	user_name: z
+		.string()
+		.regex(/^[\w-]{1,39}$/u, "Invalid username format")
+		.min(1)
+		.max(39),
+	category_slug: z
+		.string()
+		.regex(/^[\da-z-]+$/iu, "Invalid category slug format")
+		.min(1)
+		.max(100),
+});
+
+const MetadataSchema = z.object({
+	coverImage: z.string().nullable().optional(),
+	favIcon: z.string().nullable().optional(),
+	height: z.number().nullable().optional(),
+	iframeAllowed: z.boolean().nullable().optional(),
+	img_caption: z.string().nullable().optional(),
+	isOgImagePreferred: z.boolean().optional(),
+	isPageScreenshot: z.boolean().nullable().optional(),
+	mediaType: z.string().nullable().optional(),
+	ocr: z.string().nullable().optional(),
+	ogImgBlurUrl: z.string().nullable().optional(),
+	screenshot: z.string().nullable().optional(),
+	twitter_avatar_url: z.string().nullable().optional(),
+	video_url: z.string().nullable().optional(),
+	width: z.number().nullable().optional(),
+});
+
+const ProfileSchema = z.object({
+	user_name: z.string().nullable(),
+});
+
+const BookmarkSchema = z.object({
+	id: z.number(),
+	inserted_at: z.string(),
+	title: z.string().nullable(),
+	url: z.string().nullable(),
+	description: z.string().nullable(),
+	ogImage: z.string().nullable(),
+	screenshot: z.string().nullable(),
+	trash: z.boolean(),
+	type: z.string().nullable(),
+	meta_data: MetadataSchema.nullable(),
+	make_discoverable: z.string().nullable(),
+	user_id: ProfileSchema,
+});
+
+const FetchPublicBookmarkByIdResponseSchema = BookmarkSchema.nullable();
+
+export type FetchPublicBookmarkByIdResponse = z.infer<
+	typeof FetchPublicBookmarkByIdResponseSchema
+>;
+
+export const GET = createGetApiHandler({
+	inputSchema: FetchPublicBookmarkByIdQuerySchema,
+	outputSchema: FetchPublicBookmarkByIdResponseSchema,
+	route: ROUTE,
+	handler: async ({ input, route }) => {
+		const {
+			bookmark_id: bookmarkId,
+			user_name: userName,
+			category_slug: categorySlug,
+		} = input;
+
+		console.log(`[${route}] API called:`, {
+			bookmarkId,
+			userName,
+			categorySlug,
+		});
+
+		const supabase = createServiceClient();
+
+		const { data: categoryData, error: categoryError } = (await supabase
+			.from(CATEGORIES_TABLE_NAME)
+			.select(
+				`
+				id,
+				user_id (
+					user_name
+				),
+				is_public
+			`,
+			)
+			.eq("category_slug", categorySlug)
+			.maybeSingle()) as {
+			data: {
+				id: number;
+				is_public: boolean;
+				user_id: {
+					user_name: string | null;
+				};
+			} | null;
+			error: unknown;
+		};
+
+		if (categoryError) {
+			return apiError({
+				route,
+				message: "Failed to fetch category",
+				error: categoryError,
+				operation: "fetch_category",
+				extra: { categorySlug },
+			});
+		}
+
+		if (!categoryData) {
+			console.log(`[${route}] Category not found:`, { categorySlug });
+			return apiWarn({
+				route,
+				message: "Category not found",
+				status: 404,
+				context: { categorySlug },
+			});
+		}
+
+		// Verify username matches
+		if (categoryData.user_id?.user_name !== userName) {
+			console.log(`[${route}] Username mismatch:`, {
+				expected: categoryData.user_id?.user_name,
+				provided: userName,
+			});
+			return apiWarn({
+				route,
+				message: "Username mismatch",
+				status: 404,
+				context: { userName, categorySlug },
+			});
+		}
+
+		if (!categoryData.is_public) {
+			console.log(`[${route}] Category is not public:`, { categorySlug });
+			return apiWarn({
+				route,
+				message: "Category is not public",
+				status: 403,
+				context: { categorySlug },
+			});
+		}
+
+		const categoryId = categoryData.id;
+
+		console.log(`[${route}] Category verified:`, {
+			categoryId,
+			isPublic: categoryData.is_public,
+		});
+
+		const { data: bookmarkData, error: bookmarkError } = await supabase
+			.from(MAIN_TABLE_NAME)
+			.select(
+				`
+				*,
+				${BOOKMARK_CATEGORIES_TABLE_NAME}!inner (
+					category_id
+				),
+				user_id!inner (
+ 					user_name
+				)
+			`,
+			)
+			.eq("id", bookmarkId)
+			.eq(`${BOOKMARK_CATEGORIES_TABLE_NAME}.category_id`, categoryId)
+			.eq("trash", false)
+			.maybeSingle();
+
+		if (bookmarkError) {
+			return apiError({
+				route,
+				message: "Failed to fetch bookmark",
+				error: bookmarkError,
+				operation: "fetch_bookmark",
+				extra: { bookmarkId, categoryId },
+			});
+		}
+
+		if (!bookmarkData) {
+			console.log(`[${route}] Bookmark not found in category:`, {
+				bookmarkId,
+				categoryId,
+			});
+			return apiWarn({
+				route,
+				message: "Bookmark not found in category",
+				status: 404,
+				context: { bookmarkId, categoryId },
+			});
+		}
+
+		// eslint-disable-next-line @typescript-eslint/no-unused-vars
+		const { [BOOKMARK_CATEGORIES_TABLE_NAME]: _removed, ...cleanedBookmark } =
+			bookmarkData;
+
+		console.log(`[${route}] Bookmark fetched successfully:`, {
+			bookmarkId: cleanedBookmark.id,
+		});
+
+		return cleanedBookmark;
+	},
+});
diff --git a/src/app/api/bookmark/toggle-discoverable-on-bookmark/route.ts b/src/app/api/bookmark/toggle-discoverable-on-bookmark/route.ts
new file mode 100644
index 00000000..5b028404
--- /dev/null
+++ b/src/app/api/bookmark/toggle-discoverable-on-bookmark/route.ts
@@ -0,0 +1,113 @@
+import { z } from "zod";
+
+import { createPostApiHandlerWithAuth } from "@/lib/api-helpers/create-handler";
+import { apiError, apiWarn } from "@/lib/api-helpers/response";
+import { isNonEmptyArray, isNullable } from "@/utils/assertion-utils";
+import { MAIN_TABLE_NAME } from "@/utils/constants";
+import { HttpStatus } from "@/utils/error-utils/common";
+
+const ROUTE = "toggle-discoverable-on-bookmark";
+
+const ToggleBookmarkDiscoverablePayloadSchema = z.object({
+	bookmark_id: z
+		.number({
+			error: (issue) =>
+				isNullable(issue.input)
+					? "Bookmark ID is required"
+					: "Bookmark ID must be a number",
+		})
+		.int({ error: "Bookmark ID must be a whole number" })
+		.positive({ error: "Bookmark ID must be a positive number" }),
+	make_discoverable: z.boolean({
+		error: (issue) =>
+			isNullable(issue.input)
+				? "make_discoverable is required"
+				: "make_discoverable must be a boolean",
+	}),
+});
+
+export type ToggleBookmarkDiscoverablePayload = z.infer<
+	typeof ToggleBookmarkDiscoverablePayloadSchema
+>;
+
+const ToggleBookmarkDiscoverableResponseSchema = z.object({
+	id: z.number(),
+	make_discoverable: z.string().nullable(),
+});
+
+export type ToggleBookmarkDiscoverableResponse = z.infer<
+	typeof ToggleBookmarkDiscoverableResponseSchema
+>;
+
+export const POST = createPostApiHandlerWithAuth({
+	route: ROUTE,
+	inputSchema: ToggleBookmarkDiscoverablePayloadSchema,
+	outputSchema: ToggleBookmarkDiscoverableResponseSchema,
+	handler: async ({ data, supabase, user, route }) => {
+		const { bookmark_id: bookmarkId, make_discoverable: makeDiscoverable } =
+			data;
+		const userId = user.id;
+
+		console.log(`[${route}] API called:`, {
+			userId,
+			bookmarkId,
+			makeDiscoverable,
+		});
+
+		// Build match conditions - atomic update prevents TOCTOU race condition
+		// Only require trash: false when making discoverable (removing discoverability is always safe)
+		const matchConditions: Record<string, unknown> = {
+			id: bookmarkId,
+			user_id: userId,
+		};
+		if (makeDiscoverable) {
+			matchConditions.trash = false;
+		}
+
+		const { data: updatedData, error } = await supabase
+			.from(MAIN_TABLE_NAME)
+			.update({
+				make_discoverable: makeDiscoverable ? new Date().toISOString() : null,
+			})
+			.match(matchConditions)
+			.select();
+
+		if (error) {
+			return apiError({
+				route,
+				message: "Failed to toggle bookmark discoverable status",
+				error,
+				operation: "toggle_discoverable_on_bookmark",
+				userId,
+				extra: {
+					bookmarkId,
+					makeDiscoverable,
+				},
+			});
+		}
+
+		if (!isNonEmptyArray(updatedData)) {
+			return apiWarn({
+				route,
+				message: makeDiscoverable
+					? "Bookmark not found, you lack permission, or bookmark is trashed"
+					: "Bookmark not found or you lack permission",
+				status: HttpStatus.BAD_REQUEST,
+				context: {
+					bookmarkId,
+					userId,
+				},
+			});
+		}
+
+		console.log(
+			`[${route}] Bookmark discoverable status toggled successfully:`,
+			{
+				bookmarkId: updatedData[0].id,
+				makeDiscoverable,
+			},
+		);
+
+		return updatedData[0];
+	},
+});
diff --git a/src/app/api/category/add-category-to-bookmark/route.ts b/src/app/api/category/add-category-to-bookmark/route.ts
index 551e24cd..a948a21a 100644
--- a/src/app/api/category/add-category-to-bookmark/route.ts
+++ b/src/app/api/category/add-category-to-bookmark/route.ts
@@ -1,6 +1,6 @@
 import { z } from "zod";
 
-import { createSupabasePostApiHandler } from "@/lib/api-helpers/create-handler";
+import { createPostApiHandlerWithAuth } from "@/lib/api-helpers/create-handler";
 import { apiError, apiWarn } from "@/lib/api-helpers/response";
 import { isNullable } from "@/utils/assertion-utils";
 import {
@@ -48,7 +48,7 @@ export type AddCategoryToBookmarkResponse = z.infer<
 	typeof AddCategoryToBookmarkResponseSchema
 >;
 
-export const POST = createSupabasePostApiHandler({
+export const POST = createPostApiHandlerWithAuth({
 	route: ROUTE,
 	inputSchema: AddCategoryToBookmarkPayloadSchema,
 	outputSchema: AddCategoryToBookmarkResponseSchema,
diff --git a/src/app/api/category/add-category-to-bookmarks/route.ts b/src/app/api/category/add-category-to-bookmarks/route.ts
index 503534e9..4850dc91 100644
--- a/src/app/api/category/add-category-to-bookmarks/route.ts
+++ b/src/app/api/category/add-category-to-bookmarks/route.ts
@@ -1,6 +1,6 @@
 import { z } from "zod";
 
-import { createSupabasePostApiHandler } from "@/lib/api-helpers/create-handler";
+import { createPostApiHandlerWithAuth } from "@/lib/api-helpers/create-handler";
 import { apiError, apiWarn } from "@/lib/api-helpers/response";
 import { isNullable } from "@/utils/assertion-utils";
 import {
@@ -53,7 +53,7 @@ export type AddCategoryToBookmarksResponse = z.infer<
 	typeof AddCategoryToBookmarksResponseSchema
 >;
 
-export const POST = createSupabasePostApiHandler({
+export const POST = createPostApiHandlerWithAuth({
 	route: ROUTE,
 	inputSchema: AddCategoryToBookmarksPayloadSchema,
 	outputSchema: AddCategoryToBookmarksResponseSchema,
diff --git a/src/app/api/category/create-user-category/route.ts b/src/app/api/category/create-user-category/route.ts
new file mode 100644
index 00000000..e2fbd9a1
--- /dev/null
+++ b/src/app/api/category/create-user-category/route.ts
@@ -0,0 +1,132 @@
+import slugify from "slugify";
+import uniqid from "uniqid";
+import { z } from "zod";
+
+import { createPostApiHandlerWithAuth } from "@/lib/api-helpers/create-handler";
+import { apiError, apiWarn } from "@/lib/api-helpers/response";
+import { tagCategoryNameSchema } from "@/lib/validation/tag-category-schema";
+import { isNonEmptyArray, isNonNullable } from "@/utils/assertion-utils";
+import {
+	CATEGORIES_TABLE_NAME,
+	DUPLICATE_CATEGORY_NAME_ERROR,
+	PROFILES,
+} from "@/utils/constants";
+
+const ROUTE = "create-user-category";
+
+const CreateCategoryPayloadSchema = z.object({
+	name: tagCategoryNameSchema,
+	category_order: z.array(z.number()).nullish(),
+});
+
+export type CreateCategoryPayload = z.infer<typeof CreateCategoryPayloadSchema>;
+
+const CreateCategoryResponseSchema = z
+	.array(
+		z.object({
+			id: z.number(),
+			category_name: z.string().nullable(),
+			category_slug: z.string(),
+			category_views: z.unknown().nullable(),
+			created_at: z.string().nullable(),
+			icon: z.string().nullable(),
+			icon_color: z.string().nullable(),
+			is_public: z.boolean(),
+			order_index: z.number().nullable(),
+			user_id: z.string().nullable(),
+		}),
+	)
+	.nonempty();
+
+export type CreateCategoryResponse = [
+	z.infer<typeof CreateCategoryResponseSchema>[number],
+	...z.infer<typeof CreateCategoryResponseSchema>,
+];
+
+export const POST = createPostApiHandlerWithAuth({
+	route: ROUTE,
+	inputSchema: CreateCategoryPayloadSchema,
+	outputSchema: CreateCategoryResponseSchema,
+	handler: async ({ data, supabase, user, route }) => {
+		const { name, category_order: categoryOrder } = data;
+		const userId = user.id;
+
+		console.log(`[${route}] API called:`, { userId, name });
+
+		const { data: categoryData, error } = await supabase
+			.from(CATEGORIES_TABLE_NAME)
+			.insert([
+				{
+					category_name: name,
+					user_id: userId,
+					category_slug: `${slugify(name, { lower: true })}-${uniqid.time()}`,
+				},
+			])
+			.select();
+
+		if (error) {
+			// Handle unique constraint violation (case-insensitive duplicate)
+			// Postgres error code 23505 = unique_violation
+			if (
+				error.code === "23505" ||
+				error.message?.includes("unique_user_category_name_ci")
+			) {
+				return apiWarn({
+					route,
+					message: DUPLICATE_CATEGORY_NAME_ERROR,
+					status: 409,
+					context: { name, userId },
+				});
+			}
+
+			return apiError({
+				route,
+				message: "Error creating category",
+				error,
+				operation: "insert_category",
+				userId,
+				extra: { name },
+			});
+		}
+
+		if (!isNonEmptyArray(categoryData)) {
+			return apiError({
+				route,
+				message: "No data returned from database",
+				error: new Error("Empty insert result"),
+				operation: "insert_category_empty",
+				userId,
+			});
+		}
+
+		// Update category order if provided
+		if (isNonNullable(categoryOrder)) {
+			const newCategoryId = categoryData[0].id;
+
+			console.log(`[${route}] Updating category order:`, { newCategoryId });
+
+			const { error: orderError } = await supabase
+				.from(PROFILES)
+				.update({ category_order: [...categoryOrder, newCategoryId] })
+				.match({ id: userId })
+				.select("id, category_order");
+
+			if (orderError) {
+				return apiError({
+					route,
+					message: "Error updating category order",
+					error: orderError,
+					operation: "update_category_order",
+					userId,
+					extra: { categoryId: newCategoryId },
+				});
+			}
+		}
+
+		console.log(`[${route}] Category created:`, {
+			categoryId: categoryData[0].id,
+		});
+
+		return categoryData;
+	},
+});
diff --git a/src/app/api/category/remove-category-from-bookmark/route.ts b/src/app/api/category/remove-category-from-bookmark/route.ts
index f1b7be07..b857e71a 100644
--- a/src/app/api/category/remove-category-from-bookmark/route.ts
+++ b/src/app/api/category/remove-category-from-bookmark/route.ts
@@ -1,8 +1,8 @@
 import { z } from "zod";
 
-import { createSupabasePostApiHandler } from "@/lib/api-helpers/create-handler";
+import { createPostApiHandlerWithAuth } from "@/lib/api-helpers/create-handler";
 import { apiError, apiWarn } from "@/lib/api-helpers/response";
-import { isNullable } from "@/utils/assertion-utils";
+import { isNonEmptyArray, isNullable } from "@/utils/assertion-utils";
 import { MAIN_TABLE_NAME, UNCATEGORIZED_CATEGORY_ID } from "@/utils/constants";
 
 const ROUTE = "remove-category-from-bookmark";
@@ -43,7 +43,7 @@ export type RemoveCategoryFromBookmarkResponse = z.infer<
 	typeof RemoveCategoryFromBookmarkResponseSchema
 >;
 
-export const POST = createSupabasePostApiHandler({
+export const POST = createPostApiHandlerWithAuth({
 	route: ROUTE,
 	inputSchema: RemoveCategoryFromBookmarkPayloadSchema,
 	outputSchema: RemoveCategoryFromBookmarkResponseSchema,
@@ -121,7 +121,7 @@ export const POST = createSupabasePostApiHandler({
 		}
 
 		// RPC returns empty array if nothing was deleted (category wasn't associated)
-		if (!rpcData || rpcData.length === 0) {
+		if (!isNonEmptyArray(rpcData)) {
 			return apiWarn({
 				route,
 				message: "Category association not found",
@@ -130,15 +130,12 @@ export const POST = createSupabasePostApiHandler({
 			});
 		}
 
-		const addedUncategorized = rpcData[0]?.added_uncategorized ?? false;
-
 		console.log(`[${route}] Category removed successfully:`, {
 			bookmarkId,
 			categoryId,
-			addedUncategorized,
+			addedUncategorized: rpcData[0].added_uncategorized,
 		});
 
-		// Return in API schema format
 		return [{ bookmark_id: bookmarkId, category_id: categoryId }];
 	},
 });
diff --git a/src/app/api/category/set-bookmark-categories/route.ts b/src/app/api/category/set-bookmark-categories/route.ts
index 3ec8a268..e995df38 100644
--- a/src/app/api/category/set-bookmark-categories/route.ts
+++ b/src/app/api/category/set-bookmark-categories/route.ts
@@ -1,6 +1,6 @@
 import { z } from "zod";
 
-import { createSupabasePostApiHandler } from "@/lib/api-helpers/create-handler";
+import { createPostApiHandlerWithAuth } from "@/lib/api-helpers/create-handler";
 import { apiError, apiWarn } from "@/lib/api-helpers/response";
 import { isNullable } from "@/utils/assertion-utils";
 import {
@@ -55,7 +55,7 @@ export type SetBookmarkCategoriesResponse = z.infer<
 	typeof SetBookmarkCategoriesResponseSchema
 >;
 
-export const POST = createSupabasePostApiHandler({
+export const POST = createPostApiHandlerWithAuth({
 	route: ROUTE,
 	inputSchema: SetBookmarkCategoriesPayloadSchema,
 	outputSchema: SetBookmarkCategoriesResponseSchema,
diff --git a/src/app/api/category/update-user-category/route.ts b/src/app/api/category/update-user-category/route.ts
new file mode 100644
index 00000000..e19b06fe
--- /dev/null
+++ b/src/app/api/category/update-user-category/route.ts
@@ -0,0 +1,124 @@
+import { z } from "zod";
+
+import { createPostApiHandlerWithAuth } from "@/lib/api-helpers/create-handler";
+import { apiError, apiWarn } from "@/lib/api-helpers/response";
+import { tagCategoryNameSchema } from "@/lib/validation/tag-category-schema";
+import { type Database } from "@/types/database-generated.types";
+import { isNonEmptyArray } from "@/utils/assertion-utils";
+import {
+	CATEGORIES_TABLE_NAME,
+	DUPLICATE_CATEGORY_NAME_ERROR,
+} from "@/utils/constants";
+
+const ROUTE = "update-user-category";
+
+// Use looseObject for flexible JSONB column handling (allows extra keys)
+const categoryViewsSchema = z
+	.looseObject({
+		bookmarksView: z.string().optional(),
+		cardContentViewArray: z.array(z.string()).optional(),
+		moodboardColumns: z.array(z.number()).optional(),
+		sortBy: z.string().optional(),
+	})
+	.optional();
+
+const UpdateCategoryPayloadSchema = z.object({
+	category_id: z.union([z.number(), z.string()]),
+	updateData: z.object({
+		category_name: tagCategoryNameSchema.optional(),
+		category_views: categoryViewsSchema,
+		icon: z.string().nullable().optional(),
+		icon_color: z.string().optional(),
+		is_public: z.boolean().optional(),
+	}),
+});
+
+export type UpdateCategoryPayload = z.infer<typeof UpdateCategoryPayloadSchema>;
+
+const UpdateCategoryResponseSchema = z
+	.array(
+		z.object({
+			id: z.number(),
+			category_name: z.string().nullable(),
+			category_slug: z.string(),
+			category_views: z.unknown().nullable(),
+			created_at: z.string().nullable(),
+			icon: z.string().nullable(),
+			icon_color: z.string().nullable(),
+			is_public: z.boolean(),
+			order_index: z.number().nullable(),
+			user_id: z.string().nullable(),
+		}),
+	)
+	.nonempty();
+
+export type UpdateCategoryResponse = [
+	z.infer<typeof UpdateCategoryResponseSchema>[number],
+	...z.infer<typeof UpdateCategoryResponseSchema>,
+];
+
+export const POST = createPostApiHandlerWithAuth({
+	route: ROUTE,
+	inputSchema: UpdateCategoryPayloadSchema,
+	outputSchema: UpdateCategoryResponseSchema,
+	handler: async ({ data, supabase, user, route }) => {
+		const { category_id: categoryId, updateData } = data;
+		const userId = user.id;
+
+		console.log(`[${route}] API called:`, {
+			userId,
+			categoryId,
+			categoryName: updateData.category_name,
+		});
+
+		const { data: categoryData, error } = await supabase
+			.from(CATEGORIES_TABLE_NAME)
+			.update(
+				updateData as Database["public"]["Tables"]["categories"]["Update"],
+			)
+			.match({ id: categoryId, user_id: userId })
+			.select();
+
+		if (error) {
+			// Handle unique constraint violation (case-insensitive duplicate)
+			// Postgres error code 23505 = unique_violation
+			if (
+				error.code === "23505" ||
+				error.message?.includes("unique_user_category_name_ci")
+			) {
+				return apiWarn({
+					route,
+					message: DUPLICATE_CATEGORY_NAME_ERROR,
+					status: 409,
+					context: { name: updateData.category_name, userId },
+				});
+			}
+
+			return apiError({
+				route,
+				message: "Error updating category",
+				error,
+				operation: "update_category",
+				userId,
+				extra: { categoryId },
+			});
+		}
+
+		if (!isNonEmptyArray(categoryData)) {
+			return apiError({
+				route,
+				message: "No data returned from database",
+				error: new Error("Empty update result"),
+				operation: "update_category_empty",
+				userId,
+			});
+		}
+
+		console.log(`[${route}] Category updated:`, {
+			categoryId: categoryData[0].id,
+			categoryName: categoryData[0].category_name,
+		});
+
+		return categoryData;
+	},
+});
diff --git a/src/app/api/dev/session/route.ts b/src/app/api/dev/session/route.ts
new file mode 100644
index 00000000..6491028f
--- /dev/null
+++ b/src/app/api/dev/session/route.ts
@@ -0,0 +1,57 @@
+import { NextResponse } from "next/server";
+
+import { createApiClient, getApiUser } from "@/lib/supabase/api";
+
+/**
+ * Dev-only endpoint to retrieve current session token for API testing.
+ * Returns 404 in production for security.
+ *
+ * IMPORTANT: Must be accessed via BROWSER (not curl/CLI) because
+ * session cookies are browser-only.
+ *
+ * Usage:
+ * 1. Visit http://localhost:3000/api/dev/session in browser
+ * 2. Copy the `access_token` from the JSON response
+ * 3. Use in CLI: curl -H "Authorization: Bearer <token>" ...
+ * @returns {object} { access_token, expires_at, user_email }
+ */
+export async function GET() {
+	// Block in production - return 404 as if endpoint doesn't exist
+	// Defense in depth: check both NODE_ENV and VERCEL_ENV to protect against misconfiguration
+	if (
+		process.env.NODE_ENV !== "development" ||
+		process.env.VERCEL_ENV === "production"
+	) {
+		return NextResponse.json({ error: "Not found" }, { status: 404 });
+	}
+
+	const { supabase, token } = await createApiClient();
+	const {
+		data: { user },
+	} = await getApiUser(supabase, token);
+
+	if (!user) {
+		return NextResponse.json(
+			{ error: "Not authenticated - visit localhost:3000 and log in first" },
+			{ status: 401 },
+		);
+	}
+
+	// Get session for access token
+	const {
+		data: { session },
+	} = await supabase.auth.getSession();
+
+	if (!session) {
+		return NextResponse.json(
+			{ error: "No active session found" },
+			{ status: 401 },
+		);
+	}
+
+	return NextResponse.json({
+		access_token: session.access_token,
+		expires_at: session.expires_at,
+		user_email: user.email,
+	});
+}
diff --git a/src/app/api/tags/add-tag-to-bookmark/route.ts b/src/app/api/tags/add-tag-to-bookmark/route.ts
new file mode 100644
index 00000000..fefd0b42
--- /dev/null
+++ b/src/app/api/tags/add-tag-to-bookmark/route.ts
@@ -0,0 +1,152 @@
+import { z } from "zod";
+
+import { createPostApiHandlerWithAuth } from "@/lib/api-helpers/create-handler";
+import { apiError, apiWarn } from "@/lib/api-helpers/response";
+import { isNonEmptyArray } from "@/utils/assertion-utils";
+import {
+	BOOKMARK_TAGS_TABLE_NAME,
+	MAIN_TABLE_NAME,
+	TAG_TABLE_NAME,
+} from "@/utils/constants";
+
+const ROUTE = "add-tag-to-bookmark";
+
+const AddTagToBookmarkPayloadSchema = z.object({
+	bookmarkId: z.number(),
+	tagId: z.number(),
+});
+
+export type AddTagToBookmarkPayload = z.infer<
+	typeof AddTagToBookmarkPayloadSchema
+>;
+
+const AddTagToBookmarkResponseSchema = z
+	.array(
+		z.object({
+			id: z.number(),
+			bookmark_id: z.number(),
+			tag_id: z.number(),
+			user_id: z.string().nullable(),
+			created_at: z.string().nullable(),
+		}),
+	)
+	.nonempty();
+
+export type AddTagToBookmarkResponse = [
+	z.infer<typeof AddTagToBookmarkResponseSchema>[number],
+	...z.infer<typeof AddTagToBookmarkResponseSchema>,
+];
+
+export const POST = createPostApiHandlerWithAuth({
+	route: ROUTE,
+	inputSchema: AddTagToBookmarkPayloadSchema,
+	outputSchema: AddTagToBookmarkResponseSchema,
+	handler: async ({ data, supabase, user, route }) => {
+		const { bookmarkId, tagId } = data;
+		const userId = user.id;
+
+		console.log(`[${route}] API called:`, { userId, bookmarkId, tagId });
+
+		// Verify bookmark and tag ownership in parallel
+		const [bookmarkResult, tagResult] = await Promise.all([
+			supabase
+				.from(MAIN_TABLE_NAME)
+				.select("user_id")
+				.eq("id", bookmarkId)
+				.single(),
+			supabase.from(TAG_TABLE_NAME).select("user_id").eq("id", tagId).single(),
+		]);
+
+		const { data: bookmarkData, error: bookmarkError } = bookmarkResult;
+		const { data: tagData, error: tagError } = tagResult;
+
+		if (bookmarkError) {
+			return apiError({
+				route,
+				message: "Error verifying bookmark ownership",
+				error: bookmarkError,
+				operation: "verify_bookmark_owner",
+				userId,
+				extra: { bookmarkId },
+			});
+		}
+
+		if (bookmarkData.user_id !== userId) {
+			return apiWarn({
+				route,
+				message: "User is not the owner of the bookmark",
+				status: 403,
+				context: { bookmarkId, userId },
+			});
+		}
+
+		if (tagError) {
+			return apiError({
+				route,
+				message: "Error verifying tag ownership",
+				error: tagError,
+				operation: "verify_tag_owner",
+				userId,
+				extra: { tagId },
+			});
+		}
+
+		if (tagData?.user_id !== userId) {
+			return apiWarn({
+				route,
+				message: "User is not the owner of the tag",
+				status: 403,
+				context: { tagId, userId },
+			});
+		}
+
+		// Insert into bookmark_tags junction table
+		const { data: bookmarkTagData, error } = await supabase
+			.from(BOOKMARK_TAGS_TABLE_NAME)
+			.insert({
+				bookmark_id: bookmarkId,
+				tag_id: tagId,
+				user_id: userId,
+			})
+			.select();
+
+		if (error) {
+			// Handle duplicate entry (tag already assigned to bookmark)
+			if (error.code === "23505") {
+				return apiWarn({
+					route,
+					message: "Tag is already assigned to this bookmark",
+					status: 409,
+					context: { bookmarkId, tagId, userId },
+				});
+			}
+
+			return apiError({
+				route,
+				message: "Error adding tag to bookmark",
+				error,
+				operation: "insert_bookmark_tag",
+				userId,
+				extra: { bookmarkId, tagId },
+			});
+		}
+
+		if (!isNonEmptyArray(bookmarkTagData)) {
+			return apiError({
+				route,
+				message: "No data returned from database",
+				error: new Error("Empty insert result"),
+				operation: "insert_bookmark_tag_empty",
+				userId,
+			});
+		}
+
+		console.log(`[${route}] Tag added to bookmark:`, {
+			id: bookmarkTagData[0].id,
+			bookmarkId,
+			tagId,
+		});
+
+		return bookmarkTagData;
+	},
+});
diff --git a/src/app/api/tags/create-and-assign-tag/route.ts b/src/app/api/tags/create-and-assign-tag/route.ts
new file mode 100644
index 00000000..9baa86ab
--- /dev/null
+++ b/src/app/api/tags/create-and-assign-tag/route.ts
@@ -0,0 +1,134 @@
+import { z } from "zod";
+
+import { createPostApiHandlerWithAuth } from "@/lib/api-helpers/create-handler";
+import { apiError, apiWarn } from "@/lib/api-helpers/response";
+import { tagCategoryNameSchema } from "@/lib/validation/tag-category-schema";
+import { isNonEmptyArray } from "@/utils/assertion-utils";
+
+const ROUTE = "create-and-assign-tag";
+
+const CreateAndAssignTagPayloadSchema = z.object({
+	name: tagCategoryNameSchema,
+	bookmarkId: z.number(),
+});
+
+export type CreateAndAssignTagPayload = z.infer<
+	typeof CreateAndAssignTagPayloadSchema
+>;
+
+const TagSchema = z.object({
+	id: z.number(),
+	name: z.string().nullable(),
+	user_id: z.string().nullable(),
+	created_at: z.string().nullable(),
+});
+
+const BookmarkTagSchema = z.object({
+	id: z.number(),
+	bookmark_id: z.number(),
+	tag_id: z.number(),
+	user_id: z.string().nullable(),
+	created_at: z.string().nullable(),
+});
+
+const CreateAndAssignTagResponseSchema = z.object({
+	tag: TagSchema,
+	bookmarkTag: BookmarkTagSchema,
+});
+
+export type CreateAndAssignTagResponse = z.infer<
+	typeof CreateAndAssignTagResponseSchema
+>;
+
+export const POST = createPostApiHandlerWithAuth({
+	route: ROUTE,
+	inputSchema: CreateAndAssignTagPayloadSchema,
+	outputSchema: CreateAndAssignTagResponseSchema,
+	handler: async ({ data, supabase, user, route }) => {
+		const { name, bookmarkId } = data;
+		const userId = user.id;
+
+		console.log(`[${route}] API called:`, { userId, name, bookmarkId });
+
+		// Single atomic RPC call that:
+		// 1. Verifies bookmark ownership (with FOR UPDATE lock)
+		// 2. Creates the tag
+		// 3. Assigns tag to bookmark
+		// All operations succeed or all fail (PostgreSQL transaction)
+		const { data: rpcData, error: rpcError } = await supabase.rpc(
+			"create_and_assign_tag",
+			{
+				p_bookmark_id: bookmarkId,
+				p_tag_name: name,
+			},
+		);
+
+		if (rpcError) {
+			// Handle specific error codes
+			if (rpcError.code === "42501") {
+				// insufficient_privilege - bookmark not owned by user
+				return apiWarn({
+					route,
+					message: "Bookmark not found or not owned by user",
+					status: 403,
+					context: { bookmarkId, userId },
+				});
+			}
+
+			if (rpcError.code === "23505") {
+				// unique_violation (23505) - duplicate tag name
+				return apiWarn({
+					route,
+					message:
+						"You already have a tag with this name, please use a different name",
+					status: 409,
+					context: { name, userId },
+				});
+			}
+
+			return apiError({
+				route,
+				message: "Error creating and assigning tag",
+				error: rpcError,
+				operation: "create_and_assign_tag_rpc",
+				userId,
+				extra: { bookmarkId, name },
+			});
+		}
+
+		if (!isNonEmptyArray(rpcData)) {
+			return apiError({
+				route,
+				message: "No data returned from create_and_assign_tag RPC",
+				error: new Error("Empty RPC result"),
+				operation: "create_and_assign_tag_empty",
+				userId,
+			});
+		}
+
+		const rpcRow = rpcData[0];
+
+		console.log(`[${route}] Tag created and assigned:`, {
+			tagId: rpcRow.tag_id,
+			tagName: rpcRow.tag_name,
+			bookmarkTagId: rpcRow.bookmark_tag_id,
+			bookmarkId: rpcRow.bookmark_tag_bookmark_id,
+		});
+
+		return {
+			tag: {
+				id: rpcRow.tag_id,
+				name: rpcRow.tag_name,
+				user_id: rpcRow.tag_user_id,
+				created_at: rpcRow.tag_created_at,
+			},
+			bookmarkTag: {
+				id: rpcRow.bookmark_tag_id,
+				bookmark_id: rpcRow.bookmark_tag_bookmark_id,
+				tag_id: rpcRow.bookmark_tag_tag_id,
+				user_id: rpcRow.bookmark_tag_user_id,
+				created_at: rpcRow.bookmark_tag_created_at,
+			},
+		};
+	},
+});
diff --git a/src/app/api/tags/remove-tag-from-bookmark/route.ts b/src/app/api/tags/remove-tag-from-bookmark/route.ts
new file mode 100644
index 00000000..2dd9c0c0
--- /dev/null
+++ b/src/app/api/tags/remove-tag-from-bookmark/route.ts
@@ -0,0 +1,139 @@
+import { z } from "zod";
+
+import { createPostApiHandlerWithAuth } from "@/lib/api-helpers/create-handler";
+import { apiError, apiWarn } from "@/lib/api-helpers/response";
+import { isNonEmptyArray } from "@/utils/assertion-utils";
+import {
+	BOOKMARK_TAGS_TABLE_NAME,
+	MAIN_TABLE_NAME,
+	TAG_TABLE_NAME,
+} from "@/utils/constants";
+
+const ROUTE = "remove-tag-from-bookmark";
+
+const RemoveTagFromBookmarkPayloadSchema = z.object({
+	bookmarkId: z.number(),
+	tagId: z.number(),
+});
+
+export type RemoveTagFromBookmarkPayload = z.infer<
+	typeof RemoveTagFromBookmarkPayloadSchema
+>;
+
+const RemoveTagFromBookmarkResponseSchema = z
+	.array(
+		z.object({
+			id: z.number(),
+			bookmark_id: z.number(),
+			tag_id: z.number(),
+			user_id: z.string().nullable(),
+			created_at: z.string().nullable(),
+		}),
+	)
+	.nonempty();
+
+export type RemoveTagFromBookmarkResponse = [
+	z.infer<typeof RemoveTagFromBookmarkResponseSchema>[number],
+	...z.infer<typeof RemoveTagFromBookmarkResponseSchema>,
+];
+
+export const POST = createPostApiHandlerWithAuth({
+	route: ROUTE,
+	inputSchema: RemoveTagFromBookmarkPayloadSchema,
+	outputSchema: RemoveTagFromBookmarkResponseSchema,
+	handler: async ({ data, supabase, user, route }) => {
+		const { bookmarkId, tagId } = data;
+		const userId = user.id;
+
+		console.log(`[${route}] API called:`, { userId, bookmarkId, tagId });
+
+		// Verify bookmark and tag ownership in parallel
+		const [bookmarkResult, tagResult] = await Promise.all([
+			supabase
+				.from(MAIN_TABLE_NAME)
+				.select("user_id")
+				.eq("id", bookmarkId)
+				.single(),
+			supabase.from(TAG_TABLE_NAME).select("user_id").eq("id", tagId).single(),
+		]);
+
+		const { data: bookmarkData, error: bookmarkError } = bookmarkResult;
+		const { data: tagData, error: tagError } = tagResult;
+
+		if (bookmarkError) {
+			return apiError({
+				route,
+				message: "Error verifying bookmark ownership",
+				error: bookmarkError,
+				operation: "verify_bookmark_owner",
+				userId,
+				extra: { bookmarkId },
+			});
+		}
+
+		if (bookmarkData?.user_id !== userId) {
+			return apiWarn({
+				route,
+				message: "User is not the owner of the bookmark",
+				status: 403,
+				context: { bookmarkId, userId },
+			});
+		}
+
+		if (tagError) {
+			return apiError({
+				route,
+				message: "Error verifying tag ownership",
+				error: tagError,
+				operation: "verify_tag_owner",
+				userId,
+				extra: { tagId },
+			});
+		}
+
+		if (tagData?.user_id !== userId) {
+			return apiWarn({
+				route,
+				message: "User is not the owner of the tag",
+				status: 403,
+				context: { tagId, userId },
+			});
+		}
+
+		// Delete from bookmark_tags junction table
+		const { data: deletedData, error } = await supabase
+			.from(BOOKMARK_TAGS_TABLE_NAME)
+			.delete()
+			.eq("bookmark_id", bookmarkId)
+			.eq("tag_id", tagId)
+			.select();
+
+		if (error) {
+			return apiError({
+				route,
+				message: "Error removing tag from bookmark",
+				error,
+				operation: "delete_bookmark_tag",
+				userId,
+				extra: { bookmarkId, tagId },
+			});
+		}
+
+		if (!isNonEmptyArray(deletedData)) {
+			return apiWarn({
+				route,
+				message: "Tag was not assigned to this bookmark",
+				status: 404,
+				context: { bookmarkId, tagId, userId },
+			});
+		}
+
+		console.log(`[${route}] Tag removed from bookmark:`, {
+			id: deletedData[0].id,
+			bookmarkId,
+			tagId,
+		});
+
+		return deletedData;
+	},
+});
diff --git a/src/async/mutationHooks/bookmarks/use-toggle-discoverable-optimistic-mutation.ts b/src/async/mutationHooks/bookmarks/use-toggle-discoverable-optimistic-mutation.ts
new file mode 100644
index 00000000..b0d2c313
--- /dev/null
+++ b/src/async/mutationHooks/bookmarks/use-toggle-discoverable-optimistic-mutation.ts
@@ -0,0 +1,47 @@
+import {
+	type ToggleBookmarkDiscoverablePayload,
+	type ToggleBookmarkDiscoverableResponse,
+} from "@/app/api/bookmark/toggle-discoverable-on-bookmark/route";
+import { useBookmarkMutationContext } from "@/hooks/use-bookmark-mutation-context";
+import { useReactQueryOptimisticMutation } from "@/hooks/use-react-query-optimistic-mutation";
+import { postApi } from "@/lib/api-helpers/api";
+import { type BookmarksPaginatedDataTypes } from "@/types/apiTypes";
+import {
+	BOOKMARKS_KEY,
+	NEXT_API_URL,
+	TOGGLE_BOOKMARK_DISCOVERABLE_API,
+} from "@/utils/constants";
+import { updateBookmarkInPaginatedData } from "@/utils/query-cache-helpers";
+
+export function useToggleDiscoverableOptimisticMutation() {
+	const { queryKey, searchQueryKey } = useBookmarkMutationContext();
+
+	const toggleDiscoverableOptimisticMutation = useReactQueryOptimisticMutation<
+		ToggleBookmarkDiscoverableResponse,
+		Error,
+		ToggleBookmarkDiscoverablePayload,
+		typeof queryKey,
+		BookmarksPaginatedDataTypes
+	>({
+		mutationFn: (variables) =>
+			postApi<ToggleBookmarkDiscoverableResponse>(
+				`${NEXT_API_URL}${TOGGLE_BOOKMARK_DISCOVERABLE_API}`,
+				variables,
+			),
+		queryKey,
+		secondaryQueryKey: searchQueryKey,
+		updater: (currentData, variables) =>
+			updateBookmarkInPaginatedData(
+				currentData,
+				variables.bookmark_id,
+				(bookmark) => {
+					bookmark.make_discoverable = variables.make_discoverable
+						? "pending"
+						: null;
+				},
+			) as BookmarksPaginatedDataTypes,
+		invalidates: [[BOOKMARKS_KEY]],
+	});
+
+	return { toggleDiscoverableOptimisticMutation };
+}
diff --git a/src/async/mutationHooks/category/use-add-category-optimistic-mutation.ts b/src/async/mutationHooks/category/use-add-category-optimistic-mutation.ts
new file mode 100644
index 00000000..a15e8a4b
--- /dev/null
+++ b/src/async/mutationHooks/category/use-add-category-optimistic-mutation.ts
@@ -0,0 +1,76 @@
+import { useQueryClient } from "@tanstack/react-query";
+import { produce } from "immer";
+
+import {
+	type CreateCategoryPayload,
+	type CreateCategoryResponse,
+} from "@/app/api/category/create-user-category/route";
+import { useReactQueryOptimisticMutation } from "@/hooks/use-react-query-optimistic-mutation";
+import { postApi } from "@/lib/api-helpers/api";
+import { useSupabaseSession } from "@/store/componentStore";
+import { type CategoriesData } from "@/types/apiTypes";
+import {
+	BOOKMARKS_COUNT_KEY,
+	CATEGORIES_KEY,
+	CREATE_USER_CATEGORIES_API,
+	USER_PROFILE,
+} from "@/utils/constants";
+
+export function useAddCategoryOptimisticMutation() {
+	const session = useSupabaseSession((state) => state.session);
+	const queryClient = useQueryClient();
+
+	const queryKey = [CATEGORIES_KEY, session?.user?.id] as const;
+
+	const addCategoryOptimisticMutation = useReactQueryOptimisticMutation<
+		CreateCategoryResponse,
+		Error,
+		CreateCategoryPayload,
+		typeof queryKey,
+		{ data: CategoriesData[] } | undefined
+	>({
+		mutationFn: (payload) =>
+			postApi<CreateCategoryResponse>(
+				`/api${CREATE_USER_CATEGORIES_API}`,
+				payload,
+			),
+		queryKey,
+		updater: (currentData, variables) => {
+			if (!currentData?.data) {
+				return currentData;
+			}
+
+			// Optimistic placeholder - only includes fields needed for UI display.
+			// Full data comes from server response after invalidation.
+			const optimisticCategory = {
+				category_name: variables.name,
+				user_id: session?.user?.id,
+				icon: "star-04",
+				icon_color: "#000000",
+			} as unknown as CategoriesData;
+
+			return produce(currentData, (draft) => {
+				draft.data.push(optimisticCategory);
+			});
+		},
+		onSettled: (_data, error) => {
+			if (error) {
+				return;
+			}
+
+			void queryClient.invalidateQueries({
+				queryKey: [CATEGORIES_KEY, session?.user?.id],
+			});
+			void queryClient.invalidateQueries({
+				queryKey: [USER_PROFILE, session?.user?.id],
+			});
+			void queryClient.invalidateQueries({
+				queryKey: [BOOKMARKS_COUNT_KEY, session?.user?.id],
+			});
+		},
+		showSuccessToast: true,
+		successMessage: "Collection created",
+	});
+
+	return { addCategoryOptimisticMutation };
+}
diff --git a/src/async/mutationHooks/category/use-add-category-to-bookmark-mutation.ts b/src/async/mutationHooks/category/use-add-category-to-bookmark-mutation.ts
deleted file mode 100644
index a1a17b1d..00000000
--- a/src/async/mutationHooks/category/use-add-category-to-bookmark-mutation.ts
+++ /dev/null
@@ -1,250 +0,0 @@
-import * as Sentry from "@sentry/nextjs";
-
-import {
-	type AddCategoryToBookmarkPayload,
-	type AddCategoryToBookmarkResponse,
-} from "@/app/api/category/add-category-to-bookmark/route";
-import { useBookmarkMutationContext } from "@/hooks/use-bookmark-mutation-context";
-import { useReactQueryOptimisticMutation } from "@/hooks/use-react-query-optimistic-mutation";
-import { postApi } from "@/lib/api-helpers/api";
-import { type CategoriesData, type PaginatedBookmarks } from "@/types/apiTypes";
-import {
-	ADD_CATEGORY_TO_BOOKMARK_API,
-	BOOKMARKS_COUNT_KEY,
-	BOOKMARKS_KEY,
-	CATEGORIES_KEY,
-	UNCATEGORIZED_CATEGORY_ID,
-} from "@/utils/constants";
-
-type AddCategoryMutationOptions = {
-	skipInvalidation?: boolean;
-};
-
-/**
- * Mutation hook for adding a single category to a bookmark.
- * This is additive - it adds to existing categories without removing them.
- * Used for drag-and-drop operations.
- */
-export function useAddCategoryToBookmarkMutation({
-	skipInvalidation = false,
-}: AddCategoryMutationOptions = {}) {
-	const { queryClient, session, queryKey, searchQueryKey } =
-		useBookmarkMutationContext();
-
-	const addCategoryToBookmarkMutation = useReactQueryOptimisticMutation<
-		AddCategoryToBookmarkResponse,
-		Error,
-		AddCategoryToBookmarkPayload,
-		typeof queryKey,
-		PaginatedBookmarks
-	>({
-		mutationFn: (payload) =>
-			postApi<AddCategoryToBookmarkResponse>(
-				`/api${ADD_CATEGORY_TO_BOOKMARK_API}`,
-				payload,
-			),
-		queryKey,
-		secondaryQueryKey: searchQueryKey,
-		skipSecondaryInvalidation: skipInvalidation,
-
-		updater: (currentData, variables) => {
-			if (!currentData?.pages) {
-				return currentData as PaginatedBookmarks;
-			}
-
-			// Resolve category from cache - skip optimistic update if not found
-			const allCategories =
-				(
-					queryClient.getQueryData([CATEGORIES_KEY, session?.user?.id]) as
-						| { data: CategoriesData[] }
-						| undefined
-				)?.data ?? [];
-			const newCategoryEntry = allCategories.find(
-				(cat) => cat.id === variables.category_id,
-			);
-
-			// If category not in cache, skip optimistic update and wait for server response
-			if (!newCategoryEntry) {
-				if (process.env.NODE_ENV === "development") {
-					console.warn(
-						`[Optimistic Update] Category ${variables.category_id} not found in cache.`,
-						{
-							bookmarkId: variables.bookmark_id,
-							categoryId: variables.category_id,
-						},
-					);
-				}
-
-				Sentry.addBreadcrumb({
-					category: "optimistic-update",
-					message: "Category not found in cache",
-					level: "warning",
-					data: {
-						bookmarkId: variables.bookmark_id,
-						categoryId: variables.category_id,
-					},
-				});
-				return currentData;
-			}
-
-			// Find the page containing the bookmark, then update only that page
-			for (
-				let pageIndex = 0;
-				pageIndex < currentData.pages.length;
-				pageIndex++
-			) {
-				const bookmarkIndex = currentData.pages[pageIndex].data.findIndex(
-					(b) => b.id === variables.bookmark_id,
-				);
-
-				if (bookmarkIndex !== -1) {
-					const bookmark = currentData.pages[pageIndex].data[bookmarkIndex];
-
-					// Check for duplicates
-					const existingCategories = bookmark.addedCategories ?? [];
-					const alreadyHasCategory = existingCategories.some(
-						(cat) => cat.id === variables.category_id,
-					);
-
-					// If already has category, return unchanged
-					if (alreadyHasCategory) {
-						return currentData;
-					}
-
-					// EXCLUSIVE MODEL: When adding a real category, filter out category 0
-					const isAddingRealCategory =
-						variables.category_id !== UNCATEGORIZED_CATEGORY_ID;
-					const filteredCategories = isAddingRealCategory
-						? existingCategories.filter(
-								(cat) => cat.id !== UNCATEGORIZED_CATEGORY_ID,
-							)
-						: existingCategories;
-
-					// Found the bookmark - only clone this page
-					return {
-						...currentData,
-						pages: currentData.pages.map((page, pageIdx) =>
-							pageIdx === pageIndex
-								? {
-										...page,
-										data: page.data.map((b, idx) =>
-											idx === bookmarkIndex
-												? {
-														...b,
-														addedCategories: [
-															...filteredCategories,
-															newCategoryEntry,
-														],
-													}
-												: b,
-										),
-									}
-								: page,
-						),
-					};
-				}
-			}
-
-			// Bookmark not found in any page - return unchanged
-			return currentData;
-		},
-
-		// Additional optimistic update for single bookmark cache (preview route support)
-		additionalOptimisticUpdates: [
-			{
-				getQueryKey: (variables) => [
-					BOOKMARKS_KEY,
-					String(variables.bookmark_id),
-				],
-				updater: (currentData, variables) => {
-					const data = currentData as
-						| { data: Array<{ addedCategories?: CategoriesData[] }> }
-						| undefined;
-					if (!data?.data?.[0]) {
-						return currentData;
-					}
-
-					const allCategories =
-						(
-							queryClient.getQueryData([CATEGORIES_KEY, session?.user?.id]) as
-								| { data: CategoriesData[] }
-								| undefined
-						)?.data ?? [];
-					const newCategoryEntry = allCategories.find(
-						(cat) => cat.id === variables.category_id,
-					);
-
-					// If category not in cache, skip update
-					if (!newCategoryEntry) {
-						if (process.env.NODE_ENV === "development") {
-							console.warn(
-								`[Optimistic Update] Category ${variables.category_id} not found in cache (single bookmark).`,
-								{
-									bookmarkId: variables.bookmark_id,
-									categoryId: variables.category_id,
-								},
-							);
-						}
-
-						Sentry.addBreadcrumb({
-							category: "optimistic-update",
-							message: "Category not found in cache (single bookmark)",
-							level: "warning",
-							data: {
-								bookmarkId: variables.bookmark_id,
-								categoryId: variables.category_id,
-							},
-						});
-						return currentData;
-					}
-
-					const existingCategories = data.data[0].addedCategories ?? [];
-
-					// Check for duplicates
-					const alreadyHasCategory = existingCategories.some(
-						(cat) => cat.id === variables.category_id,
-					);
-					if (alreadyHasCategory) {
-						return currentData;
-					}
-
-					// EXCLUSIVE MODEL: Filter out uncategorized when adding real category
-					const filteredCategories =
-						variables.category_id !== UNCATEGORIZED_CATEGORY_ID
-							? existingCategories.filter(
-									(cat) => cat.id !== UNCATEGORIZED_CATEGORY_ID,
-								)
-							: existingCategories;
-
-					return {
-						...data,
-						data: data.data.map((bookmark) => ({
-							...bookmark,
-							addedCategories: [...filteredCategories, newCategoryEntry],
-						})),
-					};
-				},
-			},
-		],
-
-		onSettled: (_data, error) => {
-			if (error || skipInvalidation) {
-				return;
-			}
-
-			// Invalidate bookmark counts
-			void queryClient.invalidateQueries({
-				queryKey: [BOOKMARKS_COUNT_KEY, session?.user?.id],
-			});
-
-			// Invalidate ALL bookmark queries for user (covers all collections)
-			void queryClient.invalidateQueries({
-				queryKey: [BOOKMARKS_KEY, session?.user?.id],
-			});
-		},
-		showSuccessToast: true,
-		successMessage: "Collection added",
-	});
-
-	return { addCategoryToBookmarkMutation };
-}
diff --git a/src/async/mutationHooks/category/use-add-category-to-bookmark-optimistic-mutation.ts b/src/async/mutationHooks/category/use-add-category-to-bookmark-optimistic-mutation.ts
new file mode 100644
index 00000000..1f6adab8
--- /dev/null
+++ b/src/async/mutationHooks/category/use-add-category-to-bookmark-optimistic-mutation.ts
@@ -0,0 +1,199 @@
+import { produce } from "immer";
+
+import {
+	type AddCategoryToBookmarkPayload,
+	type AddCategoryToBookmarkResponse,
+} from "@/app/api/category/add-category-to-bookmark/route";
+import { useBookmarkMutationContext } from "@/hooks/use-bookmark-mutation-context";
+import { useReactQueryOptimisticMutation } from "@/hooks/use-react-query-optimistic-mutation";
+import { postApi } from "@/lib/api-helpers/api";
+import { type CategoriesData, type PaginatedBookmarks } from "@/types/apiTypes";
+import { logCacheMiss } from "@/utils/cache-debug-helpers";
+import {
+	ADD_CATEGORY_TO_BOOKMARK_API,
+	BOOKMARKS_COUNT_KEY,
+	BOOKMARKS_KEY,
+	CATEGORIES_KEY,
+	UNCATEGORIZED_CATEGORY_ID,
+} from "@/utils/constants";
+import { updateBookmarkInPaginatedData } from "@/utils/query-cache-helpers";
+
+type AddCategoryMutationOptions = {
+	skipInvalidation?: boolean;
+};
+
+/**
+ * Mutation hook for adding a single category to a bookmark.
+ * This is additive - it adds to existing categories without removing them.
+ * Used for drag-and-drop operations.
+ */
+export function useAddCategoryToBookmarkOptimisticMutation({
+	skipInvalidation = false,
+}: AddCategoryMutationOptions = {}) {
+	const { queryClient, session, queryKey, searchQueryKey } =
+		useBookmarkMutationContext();
+
+	const addCategoryToBookmarkOptimisticMutation =
+		useReactQueryOptimisticMutation<
+			AddCategoryToBookmarkResponse,
+			Error,
+			AddCategoryToBookmarkPayload,
+			typeof queryKey,
+			PaginatedBookmarks
+		>({
+			mutationFn: (payload) =>
+				postApi<AddCategoryToBookmarkResponse>(
+					`/api${ADD_CATEGORY_TO_BOOKMARK_API}`,
+					payload,
+				),
+			queryKey,
+			secondaryQueryKey: searchQueryKey,
+			skipSecondaryInvalidation: skipInvalidation,
+
+			updater: (currentData, variables) => {
+				if (!currentData?.pages) {
+					return currentData as PaginatedBookmarks;
+				}
+
+				// Resolve category from cache - skip optimistic update if not found
+				const allCategories =
+					(
+						queryClient.getQueryData([CATEGORIES_KEY, session?.user?.id]) as
+							| { data: CategoriesData[] }
+							| undefined
+					)?.data ?? [];
+				const newCategoryEntry = allCategories.find(
+					(cat) => cat.id === variables.category_id,
+				);
+
+				// If category not in cache, skip optimistic update and wait for server response
+				if (!newCategoryEntry) {
+					logCacheMiss("Optimistic Update", "Category not found in cache", {
+						bookmarkId: variables.bookmark_id,
+						categoryId: variables.category_id,
+					});
+					return currentData;
+				}
+
+				return (
+					updateBookmarkInPaginatedData(
+						currentData,
+						variables.bookmark_id,
+						(bookmark) => {
+							// Check for duplicates
+							const existingCategories = bookmark.addedCategories ?? [];
+							const alreadyHasCategory = existingCategories.some(
+								(cat) => cat.id === variables.category_id,
+							);
+							if (alreadyHasCategory) {
+								return;
+							}
+
+							// EXCLUSIVE MODEL: When adding a real category, filter out category 0
+							const isAddingRealCategory =
+								variables.category_id !== UNCATEGORIZED_CATEGORY_ID;
+							const filteredCategories = isAddingRealCategory
+								? existingCategories.filter(
+										(cat) => cat.id !== UNCATEGORIZED_CATEGORY_ID,
+									)
+								: existingCategories;
+
+							bookmark.addedCategories = [
+								...filteredCategories,
+								newCategoryEntry,
+							];
+						},
+					) ?? currentData
+				);
+			},
+
+			// Additional optimistic update for single bookmark cache (preview route support)
+			additionalOptimisticUpdates: [
+				{
+					getQueryKey: (variables) => [
+						BOOKMARKS_KEY,
+						String(variables.bookmark_id),
+					],
+					updater: (currentData, variables) => {
+						const data = currentData as
+							| { data: Array<{ addedCategories?: CategoriesData[] }> }
+							| undefined;
+						if (!data?.data?.[0]) {
+							return currentData;
+						}
+
+						const allCategories =
+							(
+								queryClient.getQueryData([
+									CATEGORIES_KEY,
+									session?.user?.id,
+								]) as { data: CategoriesData[] } | undefined
+							)?.data ?? [];
+						const newCategoryEntry = allCategories.find(
+							(cat) => cat.id === variables.category_id,
+						);
+
+						// If category not in cache, skip update
+						if (!newCategoryEntry) {
+							logCacheMiss(
+								"Optimistic Update",
+								"Category not found in cache (single bookmark)",
+								{
+									bookmarkId: variables.bookmark_id,
+									categoryId: variables.category_id,
+								},
+							);
+							return currentData;
+						}
+
+						const existingCategories = data.data[0].addedCategories ?? [];
+
+						// Check for duplicates
+						const alreadyHasCategory = existingCategories.some(
+							(cat) => cat.id === variables.category_id,
+						);
+						if (alreadyHasCategory) {
+							return currentData;
+						}
+
+						// EXCLUSIVE MODEL: Filter out uncategorized when adding real category
+						const filteredCategories =
+							variables.category_id !== UNCATEGORIZED_CATEGORY_ID
+								? existingCategories.filter(
+										(cat) => cat.id !== UNCATEGORIZED_CATEGORY_ID,
+									)
+								: existingCategories;
+
+						return produce(data, (draft) => {
+							for (const bookmark of draft.data) {
+								bookmark.addedCategories = [
+									...filteredCategories,
+									newCategoryEntry,
+								];
+							}
+						});
+					},
+				},
+			],
+
+			onSettled: (_data, error) => {
+				if (error || skipInvalidation) {
+					return;
+				}
+
+				// Invalidate bookmark counts
+				void queryClient.invalidateQueries({
+					queryKey: [BOOKMARKS_COUNT_KEY, session?.user?.id],
+				});
+
+				// Invalidate ALL bookmark queries for user (covers all collections)
+				void queryClient.invalidateQueries({
+					queryKey: [BOOKMARKS_KEY, session?.user?.id],
+				});
+			},
+			showSuccessToast: true,
+			successMessage: "Collection added",
+		});
+
+	return { addCategoryToBookmarkOptimisticMutation };
+}
diff --git a/src/async/mutationHooks/category/use-add-category-to-bookmarks-mutation.ts b/src/async/mutationHooks/category/use-add-category-to-bookmarks-mutation.ts
deleted file mode 100644
index 4bdbfd21..00000000
--- a/src/async/mutationHooks/category/use-add-category-to-bookmarks-mutation.ts
+++ /dev/null
@@ -1,145 +0,0 @@
-import * as Sentry from "@sentry/nextjs";
-
-import {
-	type AddCategoryToBookmarksPayload,
-	type AddCategoryToBookmarksResponse,
-} from "@/app/api/category/add-category-to-bookmarks/route";
-import { useBookmarkMutationContext } from "@/hooks/use-bookmark-mutation-context";
-import { useReactQueryOptimisticMutation } from "@/hooks/use-react-query-optimistic-mutation";
-import { postApi } from "@/lib/api-helpers/api";
-import { type CategoriesData, type PaginatedBookmarks } from "@/types/apiTypes";
-import {
-	ADD_CATEGORY_TO_BOOKMARKS_API,
-	BOOKMARKS_COUNT_KEY,
-	BOOKMARKS_KEY,
-	CATEGORIES_KEY,
-	UNCATEGORIZED_CATEGORY_ID,
-} from "@/utils/constants";
-
-/**
- * Mutation hook for adding a single category to multiple bookmarks in one operation.
- * Optimistically updates all affected bookmarks in cache.
- * Used for bulk selection operations.
- */
-export function useAddCategoryToBookmarksMutation() {
-	const { queryClient, session, queryKey, searchQueryKey } =
-		useBookmarkMutationContext();
-
-	const addCategoryToBookmarksMutation = useReactQueryOptimisticMutation<
-		AddCategoryToBookmarksResponse,
-		Error,
-		AddCategoryToBookmarksPayload,
-		typeof queryKey,
-		PaginatedBookmarks
-	>({
-		mutationFn: (payload) =>
-			postApi<AddCategoryToBookmarksResponse>(
-				`/api${ADD_CATEGORY_TO_BOOKMARKS_API}`,
-				payload,
-			),
-		queryKey,
-		secondaryQueryKey: searchQueryKey,
-		updater: (currentData, variables) => {
-			if (!currentData?.pages) {
-				return currentData as PaginatedBookmarks;
-			}
-
-			// Resolve category from cache - skip optimistic update if not found
-			const allCategories =
-				(
-					queryClient.getQueryData([CATEGORIES_KEY, session?.user?.id]) as
-						| { data: CategoriesData[] }
-						| undefined
-				)?.data ?? [];
-			const newCategoryEntry = allCategories.find(
-				(cat) => cat.id === variables.category_id,
-			);
-
-			// If category not in cache, skip optimistic update and wait for server response
-			if (!newCategoryEntry) {
-				if (process.env.NODE_ENV === "development") {
-					console.warn(
-						`[Optimistic Update] Category ${variables.category_id} not found in cache.`,
-						{
-							bookmarkIds: variables.bookmark_ids,
-							categoryId: variables.category_id,
-						},
-					);
-				}
-
-				Sentry.addBreadcrumb({
-					category: "optimistic-update",
-					message: "Category not found in cache (bulk operation)",
-					level: "warning",
-					data: {
-						bookmarkIds: variables.bookmark_ids,
-						categoryId: variables.category_id,
-					},
-				});
-				return currentData;
-			}
-
-			// Create Set for O(1) lookup
-			const bookmarkIdSet = new Set(variables.bookmark_ids);
-
-			// Update all matching bookmarks across all pages
-			return {
-				...currentData,
-				pages: currentData.pages.map((page) => ({
-					...page,
-					data: page.data.map((bookmark) => {
-						// Skip if not in selection
-						if (!bookmarkIdSet.has(bookmark.id)) {
-							return bookmark;
-						}
-
-						// Check if already has category
-						const existingCategories = bookmark.addedCategories ?? [];
-						const alreadyHasCategory = existingCategories.some(
-							(cat) => cat.id === variables.category_id,
-						);
-
-						// Skip if already has
-						if (alreadyHasCategory) {
-							return bookmark;
-						}
-
-						// EXCLUSIVE MODEL: When adding a real category, filter out category 0
-						const isAddingRealCategory =
-							variables.category_id !== UNCATEGORIZED_CATEGORY_ID;
-						const filteredCategories = isAddingRealCategory
-							? existingCategories.filter(
-									(cat) => cat.id !== UNCATEGORIZED_CATEGORY_ID,
-								)
-							: existingCategories;
-
-						// Add category
-						return {
-							...bookmark,
-							addedCategories: [...filteredCategories, newCategoryEntry],
-						};
-					}),
-				})),
-			};
-		},
-		onSettled: (_data, error) => {
-			if (error) {
-				return;
-			}
-
-			// Invalidate bookmark counts
-			void queryClient.invalidateQueries({
-				queryKey: [BOOKMARKS_COUNT_KEY, session?.user?.id],
-			});
-
-			// Invalidate ALL bookmark queries for user (covers all collections)
-			void queryClient.invalidateQueries({
-				queryKey: [BOOKMARKS_KEY, session?.user?.id],
-			});
-		},
-		showSuccessToast: true,
-		successMessage: "Collection added to selected bookmarks",
-	});
-
-	return { addCategoryToBookmarksMutation };
-}
diff --git a/src/async/mutationHooks/category/use-add-category-to-bookmarks-optimistic-mutation.ts b/src/async/mutationHooks/category/use-add-category-to-bookmarks-optimistic-mutation.ts
new file mode 100644
index 00000000..deaaabfe
--- /dev/null
+++ b/src/async/mutationHooks/category/use-add-category-to-bookmarks-optimistic-mutation.ts
@@ -0,0 +1,134 @@
+import { produce } from "immer";
+
+import {
+	type AddCategoryToBookmarksPayload,
+	type AddCategoryToBookmarksResponse,
+} from "@/app/api/category/add-category-to-bookmarks/route";
+import { useBookmarkMutationContext } from "@/hooks/use-bookmark-mutation-context";
+import { useReactQueryOptimisticMutation } from "@/hooks/use-react-query-optimistic-mutation";
+import { postApi } from "@/lib/api-helpers/api";
+import { type CategoriesData, type PaginatedBookmarks } from "@/types/apiTypes";
+import { logCacheMiss } from "@/utils/cache-debug-helpers";
+import {
+	ADD_CATEGORY_TO_BOOKMARKS_API,
+	BOOKMARKS_COUNT_KEY,
+	BOOKMARKS_KEY,
+	CATEGORIES_KEY,
+	UNCATEGORIZED_CATEGORY_ID,
+} from "@/utils/constants";
+
+/**
+ * Mutation hook for adding a single category to multiple bookmarks in one operation.
+ * Optimistically updates all affected bookmarks in cache.
+ * Used for bulk selection operations.
+ */
+export function useAddCategoryToBookmarksOptimisticMutation() {
+	const { queryClient, session, queryKey, searchQueryKey } =
+		useBookmarkMutationContext();
+
+	const addCategoryToBookmarksOptimisticMutation =
+		useReactQueryOptimisticMutation<
+			AddCategoryToBookmarksResponse,
+			Error,
+			AddCategoryToBookmarksPayload,
+			typeof queryKey,
+			PaginatedBookmarks
+		>({
+			mutationFn: (payload) =>
+				postApi<AddCategoryToBookmarksResponse>(
+					`/api${ADD_CATEGORY_TO_BOOKMARKS_API}`,
+					payload,
+				),
+			queryKey,
+			secondaryQueryKey: searchQueryKey,
+			updater: (currentData, variables) => {
+				if (!currentData?.pages) {
+					return currentData as PaginatedBookmarks;
+				}
+
+				// Resolve category from cache - skip optimistic update if not found
+				const allCategories =
+					(
+						queryClient.getQueryData([CATEGORIES_KEY, session?.user?.id]) as
+							| { data: CategoriesData[] }
+							| undefined
+					)?.data ?? [];
+				const newCategoryEntry = allCategories.find(
+					(cat) => cat.id === variables.category_id,
+				);
+
+				// If category not in cache, skip optimistic update and wait for server response
+				if (!newCategoryEntry) {
+					logCacheMiss(
+						"Optimistic Update",
+						"Category not found in cache (bulk operation)",
+						{
+							bookmarkIds: variables.bookmark_ids,
+							categoryId: variables.category_id,
+						},
+					);
+					return currentData;
+				}
+
+				// Create Set for O(1) lookup
+				const bookmarkIdSet = new Set(variables.bookmark_ids);
+				const isAddingRealCategory =
+					variables.category_id !== UNCATEGORIZED_CATEGORY_ID;
+
+				return produce(currentData, (draft) => {
+					for (const page of draft.pages) {
+						if (!page?.data) {
+							continue;
+						}
+
+						for (const bookmark of page.data) {
+							// Skip if not in selection
+							if (!bookmarkIdSet.has(bookmark.id)) {
+								continue;
+							}
+
+							// Check if already has category
+							const existingCategories = bookmark.addedCategories ?? [];
+							const alreadyHasCategory = existingCategories.some(
+								(cat) => cat.id === variables.category_id,
+							);
+							if (alreadyHasCategory) {
+								continue;
+							}
+
+							// EXCLUSIVE MODEL: When adding a real category, filter out category 0
+							const filteredCategories = isAddingRealCategory
+								? existingCategories.filter(
+										(cat) => cat.id !== UNCATEGORIZED_CATEGORY_ID,
+									)
+								: existingCategories;
+
+							bookmark.addedCategories = [
+								...filteredCategories,
+								newCategoryEntry,
+							];
+						}
+					}
+				});
+			},
+			onSettled: (_data, error) => {
+				if (error) {
+					return;
+				}
+
+				// Invalidate bookmark counts
+				void queryClient.invalidateQueries({
+					queryKey: [BOOKMARKS_COUNT_KEY, session?.user?.id],
+				});
+
+				// Invalidate ALL bookmark queries for user (covers all collections)
+				void queryClient.invalidateQueries({
+					queryKey: [BOOKMARKS_KEY, session?.user?.id],
+				});
+			},
+			showSuccessToast: true,
+			successMessage: "Collection added to selected bookmarks",
+		});
+
+	return { addCategoryToBookmarksOptimisticMutation };
+}
diff --git a/src/async/mutationHooks/category/use-remove-category-from-bookmark-mutation.ts b/src/async/mutationHooks/category/use-remove-category-from-bookmark-mutation.ts
deleted file mode 100644
index 79320390..00000000
--- a/src/async/mutationHooks/category/use-remove-category-from-bookmark-mutation.ts
+++ /dev/null
@@ -1,252 +0,0 @@
-import * as Sentry from "@sentry/nextjs";
-
-import {
-	type RemoveCategoryFromBookmarkPayload,
-	type RemoveCategoryFromBookmarkResponse,
-} from "@/app/api/category/remove-category-from-bookmark/route";
-import { useBookmarkMutationContext } from "@/hooks/use-bookmark-mutation-context";
-import { useReactQueryOptimisticMutation } from "@/hooks/use-react-query-optimistic-mutation";
-import { postApi } from "@/lib/api-helpers/api";
-import { type CategoriesData, type PaginatedBookmarks } from "@/types/apiTypes";
-import {
-	BOOKMARKS_COUNT_KEY,
-	BOOKMARKS_KEY,
-	CATEGORIES_KEY,
-	REMOVE_CATEGORY_FROM_BOOKMARK_API,
-	UNCATEGORIZED_CATEGORY_ID,
-} from "@/utils/constants";
-
-type RemoveCategoryMutationOptions = {
-	skipInvalidation?: boolean;
-	preserveInList?: boolean;
-};
-
-/**
- * Mutation hook for removing a single category from a bookmark.
- * Removes only the specified category, keeping other categories intact.
- */
-export function useRemoveCategoryFromBookmarkMutation({
-	skipInvalidation = false,
-	preserveInList = false,
-}: RemoveCategoryMutationOptions = {}) {
-	const { queryClient, session, queryKey, searchQueryKey, CATEGORY_ID } =
-		useBookmarkMutationContext();
-
-	const removeCategoryFromBookmarkMutation = useReactQueryOptimisticMutation<
-		RemoveCategoryFromBookmarkResponse,
-		Error,
-		RemoveCategoryFromBookmarkPayload,
-		typeof queryKey,
-		PaginatedBookmarks
-	>({
-		mutationFn: (payload) =>
-			postApi<RemoveCategoryFromBookmarkResponse>(
-				`/api${REMOVE_CATEGORY_FROM_BOOKMARK_API}`,
-				payload,
-			),
-		queryKey,
-		secondaryQueryKey: searchQueryKey,
-		skipSecondaryInvalidation: skipInvalidation,
-
-		updater: (currentData, variables) => {
-			if (!currentData?.pages) {
-				return currentData as PaginatedBookmarks;
-			}
-
-			// If removing the current collection from a bookmark, remove from list
-			const isRemovingCurrentCollection = variables.category_id === CATEGORY_ID;
-
-			// Find the page containing the bookmark, then update only that page
-			for (
-				let pageIndex = 0;
-				pageIndex < currentData.pages.length;
-				pageIndex++
-			) {
-				const bookmarkIndex = currentData.pages[pageIndex].data.findIndex(
-					(b) => b.id === variables.bookmark_id,
-				);
-
-				if (bookmarkIndex !== -1) {
-					const bookmark = currentData.pages[pageIndex].data[bookmarkIndex];
-
-					// Filter out the removed category
-					const filteredCategories = (bookmark.addedCategories ?? []).filter(
-						(cat) => cat.id !== variables.category_id,
-					);
-
-					// EXCLUSIVE MODEL: Check if any non-0 categories remain
-					const hasNonZeroCategories = filteredCategories.some(
-						(cat) => cat.id !== UNCATEGORIZED_CATEGORY_ID,
-					);
-
-					// Determine final categories
-					let finalCategories = filteredCategories;
-					if (!hasNonZeroCategories) {
-						// Get uncategorized entry from cache
-						const allCategories =
-							(
-								queryClient.getQueryData([
-									CATEGORIES_KEY,
-									session?.user?.id,
-								]) as { data: CategoriesData[] } | undefined
-							)?.data ?? [];
-						const uncategorizedEntry = allCategories.find(
-							(cat) => cat.id === UNCATEGORIZED_CATEGORY_ID,
-						);
-
-						// Auto-add uncategorized if available in cache
-						if (uncategorizedEntry) {
-							finalCategories = [uncategorizedEntry];
-						} else {
-							if (process.env.NODE_ENV === "development") {
-								console.warn(
-									"[Optimistic Update] Uncategorized category not found in cache.",
-									{
-										bookmarkId: variables.bookmark_id,
-										categoryId: variables.category_id,
-									},
-								);
-							}
-
-							Sentry.addBreadcrumb({
-								category: "optimistic-update",
-								message: "Uncategorized category not found in cache",
-								level: "warning",
-								data: {
-									bookmarkId: variables.bookmark_id,
-									categoryId: variables.category_id,
-								},
-							});
-						}
-					}
-
-					// Found the bookmark - only clone this page
-					return {
-						...currentData,
-						pages: currentData.pages.map((page, pageIdx) =>
-							pageIdx === pageIndex
-								? {
-										...page,
-										// Remove bookmark when removing current collection (unless preserveInList), else update addedCategories
-										data:
-											isRemovingCurrentCollection && !preserveInList
-												? page.data.filter(
-														(b) => b.id !== variables.bookmark_id,
-													)
-												: page.data.map((b, idx) =>
-														idx === bookmarkIndex
-															? {
-																	...b,
-																	addedCategories: finalCategories,
-																}
-															: b,
-													),
-									}
-								: page,
-						),
-					};
-				}
-			}
-
-			// Bookmark not found in any page - return unchanged
-			return currentData;
-		},
-
-		// Additional optimistic update for single bookmark cache (preview route support)
-		additionalOptimisticUpdates: [
-			{
-				getQueryKey: (variables) => [
-					BOOKMARKS_KEY,
-					String(variables.bookmark_id),
-				],
-				updater: (currentData, variables) => {
-					const data = currentData as
-						| { data: Array<{ addedCategories?: CategoriesData[] }> }
-						| undefined;
-					if (!data?.data?.[0]) {
-						return currentData;
-					}
-
-					const existingCategories = data.data[0].addedCategories ?? [];
-					const filteredCategories = existingCategories.filter(
-						(cat) => cat.id !== variables.category_id,
-					);
-
-					// Check if any non-zero categories remain
-					const hasNonZeroCategories = filteredCategories.some(
-						(cat) => cat.id !== UNCATEGORIZED_CATEGORY_ID,
-					);
-
-					let finalCategories = filteredCategories;
-					if (!hasNonZeroCategories) {
-						// Get uncategorized entry from cache
-						const allCategories =
-							(
-								queryClient.getQueryData([
-									CATEGORIES_KEY,
-									session?.user?.id,
-								]) as { data: CategoriesData[] } | undefined
-							)?.data ?? [];
-						const uncategorizedEntry = allCategories.find(
-							(cat) => cat.id === UNCATEGORIZED_CATEGORY_ID,
-						);
-
-						if (uncategorizedEntry) {
-							finalCategories = [uncategorizedEntry];
-						} else {
-							if (process.env.NODE_ENV === "development") {
-								console.warn(
-									"[Optimistic Update] Uncategorized category not found in cache (single bookmark).",
-									{
-										bookmarkId: variables.bookmark_id,
-										categoryId: variables.category_id,
-									},
-								);
-							}
-
-							Sentry.addBreadcrumb({
-								category: "optimistic-update",
-								message:
-									"Uncategorized category not found in cache (single bookmark)",
-								level: "warning",
-								data: {
-									bookmarkId: variables.bookmark_id,
-									categoryId: variables.category_id,
-								},
-							});
-						}
-					}
-
-					return {
-						...data,
-						data: data.data.map((bookmark) => ({
-							...bookmark,
-							addedCategories: finalCategories,
-						})),
-					};
-				},
-			},
-		],
-
-		onSettled: (_data, error) => {
-			// Single bookmark cache is now updated optimistically via additionalOptimisticUpdates
-			if (error || skipInvalidation) {
-				return;
-			}
-
-			// Invalidate bookmark counts
-			void queryClient.invalidateQueries({
-				queryKey: [BOOKMARKS_COUNT_KEY, session?.user?.id],
-			});
-
-			// Invalidate ALL bookmark queries for user (covers all collections)
-			void queryClient.invalidateQueries({
-				queryKey: [BOOKMARKS_KEY, session?.user?.id],
-			});
-		},
-		showSuccessToast: true,
-		successMessage: "Collection removed",
-	});
-
-	return { removeCategoryFromBookmarkMutation };
-}
diff --git a/src/async/mutationHooks/category/use-remove-category-from-bookmark-optimistic-mutation.ts b/src/async/mutationHooks/category/use-remove-category-from-bookmark-optimistic-mutation.ts
new file mode 100644
index 00000000..b3eadf67
--- /dev/null
+++ b/src/async/mutationHooks/category/use-remove-category-from-bookmark-optimistic-mutation.ts
@@ -0,0 +1,210 @@
+import { produce } from "immer";
+
+import {
+	type RemoveCategoryFromBookmarkPayload,
+	type RemoveCategoryFromBookmarkResponse,
+} from "@/app/api/category/remove-category-from-bookmark/route";
+import { useBookmarkMutationContext } from "@/hooks/use-bookmark-mutation-context";
+import { useReactQueryOptimisticMutation } from "@/hooks/use-react-query-optimistic-mutation";
+import { postApi } from "@/lib/api-helpers/api";
+import { type CategoriesData, type PaginatedBookmarks } from "@/types/apiTypes";
+import { logCacheMiss } from "@/utils/cache-debug-helpers";
+import {
+	BOOKMARKS_COUNT_KEY,
+	BOOKMARKS_KEY,
+	CATEGORIES_KEY,
+	REMOVE_CATEGORY_FROM_BOOKMARK_API,
+	UNCATEGORIZED_CATEGORY_ID,
+} from "@/utils/constants";
+
+type RemoveCategoryMutationOptions = {
+	skipInvalidation?: boolean;
+	preserveInList?: boolean;
+};
+
+/**
+ * Mutation hook for removing a single category from a bookmark.
+ * Removes only the specified category, keeping other categories intact.
+ */
+export function useRemoveCategoryFromBookmarkOptimisticMutation({
+	skipInvalidation = false,
+	preserveInList = false,
+}: RemoveCategoryMutationOptions = {}) {
+	const { queryClient, session, queryKey, searchQueryKey, CATEGORY_ID } =
+		useBookmarkMutationContext();
+
+	const removeCategoryFromBookmarkOptimisticMutation =
+		useReactQueryOptimisticMutation<
+			RemoveCategoryFromBookmarkResponse,
+			Error,
+			RemoveCategoryFromBookmarkPayload,
+			typeof queryKey,
+			PaginatedBookmarks
+		>({
+			mutationFn: (payload) =>
+				postApi<RemoveCategoryFromBookmarkResponse>(
+					`/api${REMOVE_CATEGORY_FROM_BOOKMARK_API}`,
+					payload,
+				),
+			queryKey,
+			secondaryQueryKey: searchQueryKey,
+			skipSecondaryInvalidation: skipInvalidation,
+
+			updater: (currentData, variables) => {
+				if (!currentData?.pages) {
+					return currentData as PaginatedBookmarks;
+				}
+
+				// If removing the current collection from a bookmark, remove from list
+				const isRemovingCurrentCollection =
+					variables.category_id === CATEGORY_ID;
+				const shouldRemoveFromList =
+					isRemovingCurrentCollection && !preserveInList;
+
+				// Get uncategorized entry upfront (may be needed for exclusive model)
+				const allCategories =
+					(
+						queryClient.getQueryData([CATEGORIES_KEY, session?.user?.id]) as
+							| { data: CategoriesData[] }
+							| undefined
+					)?.data ?? [];
+				const uncategorizedEntry = allCategories.find(
+					(cat) => cat.id === UNCATEGORIZED_CATEGORY_ID,
+				);
+
+				return produce(currentData, (draft) => {
+					for (const page of draft.pages) {
+						if (!page?.data) {
+							continue;
+						}
+
+						const bookmarkIndex = page.data.findIndex(
+							(b) => b.id === variables.bookmark_id,
+						);
+						if (bookmarkIndex === -1) {
+							continue;
+						}
+
+						// Remove bookmark from list if removing current collection
+						if (shouldRemoveFromList) {
+							page.data.splice(bookmarkIndex, 1);
+							return;
+						}
+
+						// Update categories
+						const bookmark = page.data[bookmarkIndex];
+						const filteredCategories = (bookmark.addedCategories ?? []).filter(
+							(cat) => cat.id !== variables.category_id,
+						);
+
+						// EXCLUSIVE MODEL: Check if any non-0 categories remain
+						const hasNonZeroCategories = filteredCategories.some(
+							(cat) => cat.id !== UNCATEGORIZED_CATEGORY_ID,
+						);
+
+						if (!hasNonZeroCategories && uncategorizedEntry) {
+							bookmark.addedCategories = [uncategorizedEntry];
+						} else if (!hasNonZeroCategories) {
+							// Uncategorized not in cache - log warning
+							logCacheMiss(
+								"Optimistic Update",
+								"Uncategorized category not found in cache",
+								{
+									bookmarkId: variables.bookmark_id,
+									categoryId: variables.category_id,
+								},
+							);
+							bookmark.addedCategories = filteredCategories;
+						} else {
+							bookmark.addedCategories = filteredCategories;
+						}
+
+						return;
+					}
+				});
+			},
+
+			// Additional optimistic update for single bookmark cache (preview route support)
+			additionalOptimisticUpdates: [
+				{
+					getQueryKey: (variables) => [
+						BOOKMARKS_KEY,
+						String(variables.bookmark_id),
+					],
+					updater: (currentData, variables) => {
+						const data = currentData as
+							| { data: Array<{ addedCategories?: CategoriesData[] }> }
+							| undefined;
+						if (!data?.data?.[0]) {
+							return currentData;
+						}
+
+						const existingCategories = data.data[0].addedCategories ?? [];
+						const filteredCategories = existingCategories.filter(
+							(cat) => cat.id !== variables.category_id,
+						);
+
+						// Check if any non-zero categories remain
+						const hasNonZeroCategories = filteredCategories.some(
+							(cat) => cat.id !== UNCATEGORIZED_CATEGORY_ID,
+						);
+
+						let finalCategories = filteredCategories;
+						if (!hasNonZeroCategories) {
+							// Get uncategorized entry from cache
+							const allCategories =
+								(
+									queryClient.getQueryData([
+										CATEGORIES_KEY,
+										session?.user?.id,
+									]) as { data: CategoriesData[] } | undefined
+								)?.data ?? [];
+							const uncategorizedEntry = allCategories.find(
+								(cat) => cat.id === UNCATEGORIZED_CATEGORY_ID,
+							);
+
+							if (uncategorizedEntry) {
+								finalCategories = [uncategorizedEntry];
+							} else {
+								logCacheMiss(
+									"Optimistic Update",
+									"Uncategorized category not found in cache (single bookmark)",
+									{
+										bookmarkId: variables.bookmark_id,
+										categoryId: variables.category_id,
+									},
+								);
+							}
+						}
+
+						return produce(data, (draft) => {
+							for (const bookmark of draft.data) {
+								bookmark.addedCategories = finalCategories;
+							}
+						});
+					},
+				},
+			],
+
+			onSettled: (_data, error) => {
+				// Single bookmark cache is now updated optimistically via additionalOptimisticUpdates
+				if (error || skipInvalidation) {
+					return;
+				}
+
+				// Invalidate bookmark counts
+				void queryClient.invalidateQueries({
+					queryKey: [BOOKMARKS_COUNT_KEY, session?.user?.id],
+				});
+
+				// Invalidate ALL bookmark queries for user (covers all collections)
+				void queryClient.invalidateQueries({
+					queryKey: [BOOKMARKS_KEY, session?.user?.id],
+				});
+			},
+			showSuccessToast: true,
+			successMessage: "Collection removed",
+		});
+
+	return { removeCategoryFromBookmarkOptimisticMutation };
+}
diff --git a/src/async/mutationHooks/category/use-set-bookmark-categories-mutation.ts b/src/async/mutationHooks/category/use-set-bookmark-categories-mutation.ts
deleted file mode 100644
index 55e61c6f..00000000
--- a/src/async/mutationHooks/category/use-set-bookmark-categories-mutation.ts
+++ /dev/null
@@ -1,172 +0,0 @@
-import * as Sentry from "@sentry/nextjs";
-
-import {
-	type SetBookmarkCategoriesPayload,
-	type SetBookmarkCategoriesResponse,
-} from "@/app/api/category/set-bookmark-categories/route";
-import { useBookmarkMutationContext } from "@/hooks/use-bookmark-mutation-context";
-import { useReactQueryOptimisticMutation } from "@/hooks/use-react-query-optimistic-mutation";
-import { postApi } from "@/lib/api-helpers/api";
-import { type CategoriesData, type PaginatedBookmarks } from "@/types/apiTypes";
-import {
-	BOOKMARKS_COUNT_KEY,
-	BOOKMARKS_KEY,
-	CATEGORIES_KEY,
-	SET_BOOKMARK_CATEGORIES_API,
-	UNCATEGORIZED_CATEGORY_ID,
-} from "@/utils/constants";
-
-type SetBookmarkCategoriesMutationOptions = {
-	skipInvalidation?: boolean;
-	preserveInList?: boolean;
-};
-
-/**
- * Mutation hook for setting all categories for a bookmark.
- * Replaces existing categories with the new set.
- */
-export function useSetBookmarkCategoriesMutation({
-	skipInvalidation = false,
-	preserveInList = false,
-}: SetBookmarkCategoriesMutationOptions = {}) {
-	const { queryClient, session, queryKey, searchQueryKey, CATEGORY_ID } =
-		useBookmarkMutationContext();
-
-	const setBookmarkCategoriesMutation = useReactQueryOptimisticMutation<
-		SetBookmarkCategoriesResponse,
-		Error,
-		SetBookmarkCategoriesPayload,
-		typeof queryKey,
-		PaginatedBookmarks
-	>({
-		mutationFn: (payload) =>
-			postApi<SetBookmarkCategoriesResponse>(
-				`/api${SET_BOOKMARK_CATEGORIES_API}`,
-				payload,
-			),
-		queryKey,
-		secondaryQueryKey: searchQueryKey,
-		updater: (currentData, variables) => {
-			if (!currentData?.pages) {
-				return currentData as PaginatedBookmarks;
-			}
-
-			// Resolve categories from cache - skip optimistic update if not found
-			const allCategories =
-				(
-					queryClient.getQueryData([CATEGORIES_KEY, session?.user?.id]) as
-						| { data: CategoriesData[] }
-						| undefined
-				)?.data ?? [];
-
-			// EXCLUSIVE MODEL: Filter out 0 from input (users cannot manually assign to 0)
-			const nonZeroCategoryIds = variables.category_ids.filter(
-				(id) => id !== UNCATEGORIZED_CATEGORY_ID,
-			);
-
-			// Determine final category IDs based on exclusive model
-			// Empty = only uncategorized, Non-empty = only real categories
-			const finalCategoryIds =
-				nonZeroCategoryIds.length === 0
-					? [UNCATEGORIZED_CATEGORY_ID]
-					: nonZeroCategoryIds;
-
-			// Filter to only categories that exist in cache
-			const newCategories = finalCategoryIds
-				.map((id) => allCategories.find((cat) => cat.id === id))
-				.filter((cat): cat is CategoriesData => cat !== undefined);
-
-			// If any categories weren't in cache, skip optimistic update and wait for server
-			if (newCategories.length !== finalCategoryIds.length) {
-				const missingCategoryIds = finalCategoryIds.filter(
-					(id) => !newCategories.some((cat) => cat.id === id),
-				);
-				if (process.env.NODE_ENV === "development") {
-					console.warn(
-						`[Optimistic Update] ${missingCategoryIds.length} categories not found in cache.`,
-						{
-							bookmarkId: variables.bookmark_id,
-							requestedCategoryIds: finalCategoryIds,
-							missingCategoryIds,
-						},
-					);
-				}
-
-				Sentry.addBreadcrumb({
-					category: "optimistic-update",
-					message: "Categories not found in cache",
-					level: "warning",
-					data: {
-						bookmarkId: variables.bookmark_id,
-						requestedCategoryIds: finalCategoryIds,
-						missingCategoryIds,
-					},
-				});
-				return currentData;
-			}
-
-			// Check if new categories include current collection
-			const includesCurrentCollection =
-				typeof CATEGORY_ID === "number" &&
-				variables.category_ids.includes(CATEGORY_ID);
-
-			// Find the page containing the bookmark, then update only that page
-			for (
-				let pageIndex = 0;
-				pageIndex < currentData.pages.length;
-				pageIndex++
-			) {
-				const bookmarkIndex = currentData.pages[pageIndex].data.findIndex(
-					(b) => b.id === variables.bookmark_id,
-				);
-
-				if (bookmarkIndex !== -1) {
-					// Found the bookmark - only clone this page
-					return {
-						...currentData,
-						pages: currentData.pages.map((page, pageIdx) =>
-							pageIdx === pageIndex
-								? {
-										...page,
-										// Remove bookmark if current collection is removed (unless preserveInList), else update categories
-										data:
-											!includesCurrentCollection && !preserveInList
-												? page.data.filter(
-														(b) => b.id !== variables.bookmark_id,
-													)
-												: page.data.map((bookmark, idx) =>
-														idx === bookmarkIndex
-															? { ...bookmark, addedCategories: newCategories }
-															: bookmark,
-													),
-									}
-								: page,
-						),
-					};
-				}
-			}
-
-			// Bookmark not found in any page - return unchanged
-			return currentData;
-		},
-		onSettled: (_data, error) => {
-			if (error || skipInvalidation) {
-				return;
-			}
-
-			// Invalidate bookmark counts
-			void queryClient.invalidateQueries({
-				queryKey: [BOOKMARKS_COUNT_KEY, session?.user?.id],
-			});
-
-			// Invalidate ALL bookmark queries for user (covers all collections)
-			void queryClient.invalidateQueries({
-				queryKey: [BOOKMARKS_KEY, session?.user?.id],
-			});
-		},
-		showSuccessToast: true,
-		successMessage: "Collection updated",
-	});
-
-	return { setBookmarkCategoriesMutation };
-}
diff --git a/src/async/mutationHooks/category/use-set-bookmark-categories-optimistic-mutation.ts b/src/async/mutationHooks/category/use-set-bookmark-categories-optimistic-mutation.ts
new file mode 100644
index 00000000..b2aed8f8
--- /dev/null
+++ b/src/async/mutationHooks/category/use-set-bookmark-categories-optimistic-mutation.ts
@@ -0,0 +1,146 @@
+import { produce } from "immer";
+
+import {
+	type SetBookmarkCategoriesPayload,
+	type SetBookmarkCategoriesResponse,
+} from "@/app/api/category/set-bookmark-categories/route";
+import { useBookmarkMutationContext } from "@/hooks/use-bookmark-mutation-context";
+import { useReactQueryOptimisticMutation } from "@/hooks/use-react-query-optimistic-mutation";
+import { postApi } from "@/lib/api-helpers/api";
+import { type CategoriesData, type PaginatedBookmarks } from "@/types/apiTypes";
+import { logCacheMiss } from "@/utils/cache-debug-helpers";
+import {
+	BOOKMARKS_COUNT_KEY,
+	BOOKMARKS_KEY,
+	CATEGORIES_KEY,
+	SET_BOOKMARK_CATEGORIES_API,
+	UNCATEGORIZED_CATEGORY_ID,
+} from "@/utils/constants";
+
+type SetBookmarkCategoriesMutationOptions = {
+	skipInvalidation?: boolean;
+	preserveInList?: boolean;
+};
+
+/**
+ * Mutation hook for setting all categories for a bookmark.
+ * Replaces existing categories with the new set.
+ */
+export function useSetBookmarkCategoriesOptimisticMutation({
+	skipInvalidation = false,
+	preserveInList = false,
+}: SetBookmarkCategoriesMutationOptions = {}) {
+	const { queryClient, session, queryKey, searchQueryKey, CATEGORY_ID } =
+		useBookmarkMutationContext();
+
+	const setBookmarkCategoriesOptimisticMutation =
+		useReactQueryOptimisticMutation<
+			SetBookmarkCategoriesResponse,
+			Error,
+			SetBookmarkCategoriesPayload,
+			typeof queryKey,
+			PaginatedBookmarks
+		>({
+			mutationFn: (payload) =>
+				postApi<SetBookmarkCategoriesResponse>(
+					`/api${SET_BOOKMARK_CATEGORIES_API}`,
+					payload,
+				),
+			queryKey,
+			secondaryQueryKey: searchQueryKey,
+			updater: (currentData, variables) => {
+				if (!currentData?.pages) {
+					return currentData as PaginatedBookmarks;
+				}
+
+				// Resolve categories from cache - skip optimistic update if not found
+				const allCategories =
+					(
+						queryClient.getQueryData([CATEGORIES_KEY, session?.user?.id]) as
+							| { data: CategoriesData[] }
+							| undefined
+					)?.data ?? [];
+
+				// EXCLUSIVE MODEL: Filter out 0 from input (users cannot manually assign to 0)
+				const nonZeroCategoryIds = variables.category_ids.filter(
+					(id) => id !== UNCATEGORIZED_CATEGORY_ID,
+				);
+
+				// Determine final category IDs based on exclusive model
+				// Empty = only uncategorized, Non-empty = only real categories
+				const finalCategoryIds =
+					nonZeroCategoryIds.length === 0
+						? [UNCATEGORIZED_CATEGORY_ID]
+						: nonZeroCategoryIds;
+
+				// Filter to only categories that exist in cache
+				const newCategories = finalCategoryIds
+					.map((id) => allCategories.find((cat) => cat.id === id))
+					.filter((cat): cat is CategoriesData => cat !== undefined);
+
+				// If any categories weren't in cache, skip optimistic update and wait for server
+				if (newCategories.length !== finalCategoryIds.length) {
+					const missingCategoryIds = finalCategoryIds.filter(
+						(id) => !newCategories.some((cat) => cat.id === id),
+					);
+					logCacheMiss("Optimistic Update", "Categories not found in cache", {
+						bookmarkId: variables.bookmark_id,
+						requestedCategoryIds: finalCategoryIds,
+						missingCategoryIds,
+					});
+					return currentData;
+				}
+
+				// Check if new categories include current collection
+				const includesCurrentCollection =
+					typeof CATEGORY_ID === "number" &&
+					variables.category_ids.includes(CATEGORY_ID);
+				const shouldRemoveFromList =
+					!includesCurrentCollection && !preserveInList;
+
+				return produce(currentData, (draft) => {
+					for (const page of draft.pages) {
+						if (!page?.data) {
+							continue;
+						}
+
+						const bookmarkIndex = page.data.findIndex(
+							(b) => b.id === variables.bookmark_id,
+						);
+						if (bookmarkIndex === -1) {
+							continue;
+						}
+
+						// Remove bookmark from list if current collection is removed
+						if (shouldRemoveFromList) {
+							page.data.splice(bookmarkIndex, 1);
+							return;
+						}
+
+						// Update categories
+						page.data[bookmarkIndex].addedCategories = newCategories;
+						return;
+					}
+				});
+			},
+			onSettled: (_data, error) => {
+				if (error || skipInvalidation) {
+					return;
+				}
+
+				// Invalidate bookmark counts
+				void queryClient.invalidateQueries({
+					queryKey: [BOOKMARKS_COUNT_KEY, session?.user?.id],
+				});
+
+				// Invalidate ALL bookmark queries for user (covers all collections)
+				void queryClient.invalidateQueries({
+					queryKey: [BOOKMARKS_KEY, session?.user?.id],
+				});
+			},
+			showSuccessToast: true,
+			successMessage: "Collection updated",
+		});
+
+	return { setBookmarkCategoriesOptimisticMutation };
+}
diff --git a/src/async/mutationHooks/category/use-update-category-optimistic-mutation.ts b/src/async/mutationHooks/category/use-update-category-optimistic-mutation.ts
new file mode 100644
index 00000000..ac0dd4d1
--- /dev/null
+++ b/src/async/mutationHooks/category/use-update-category-optimistic-mutation.ts
@@ -0,0 +1,84 @@
+"use client";
+
+import { useQueryClient } from "@tanstack/react-query";
+import { produce } from "immer";
+
+import {
+	type UpdateCategoryPayload,
+	type UpdateCategoryResponse,
+} from "@/app/api/category/update-user-category/route";
+import { useReactQueryOptimisticMutation } from "@/hooks/use-react-query-optimistic-mutation";
+import { postApi } from "@/lib/api-helpers/api";
+import { useSupabaseSession } from "@/store/componentStore";
+import { type CategoriesData } from "@/types/apiTypes";
+import { CATEGORIES_KEY, UPDATE_USER_CATEGORIES_API } from "@/utils/constants";
+
+export function useUpdateCategoryOptimisticMutation() {
+	const session = useSupabaseSession((state) => state.session);
+	const queryClient = useQueryClient();
+
+	const queryKey = [CATEGORIES_KEY, session?.user?.id] as const;
+
+	const updateCategoryOptimisticMutation = useReactQueryOptimisticMutation<
+		UpdateCategoryResponse,
+		Error,
+		UpdateCategoryPayload,
+		typeof queryKey,
+		{ data: CategoriesData[] } | undefined
+	>({
+		mutationFn: (payload) =>
+			postApi<UpdateCategoryResponse>(
+				`/api${UPDATE_USER_CATEGORIES_API}`,
+				payload,
+			),
+		queryKey,
+		updater: (currentData, variables) => {
+			if (!currentData?.data) {
+				return currentData;
+			}
+
+			return produce(currentData, (draft) => {
+				const category = draft.data.find(
+					(item) => item.id === variables.category_id,
+				);
+				if (!category) {
+					return;
+				}
+
+				const { updateData } = variables;
+				if (updateData.category_name !== undefined) {
+					category.category_name = updateData.category_name;
+				}
+
+				if (updateData.category_views !== undefined) {
+					category.category_views =
+						updateData.category_views as CategoriesData["category_views"];
+				}
+
+				if (updateData.icon !== undefined) {
+					category.icon = updateData.icon;
+				}
+
+				if (updateData.icon_color !== undefined) {
+					category.icon_color = updateData.icon_color;
+				}
+
+				if (updateData.is_public !== undefined) {
+					category.is_public = updateData.is_public;
+				}
+			});
+		},
+		onSettled: (_data, error) => {
+			if (error) {
+				return;
+			}
+
+			void queryClient.invalidateQueries({
+				queryKey: [CATEGORIES_KEY, session?.user?.id],
+			});
+		},
+		showSuccessToast: false,
+	});
+
+	return { updateCategoryOptimisticMutation };
+}
diff --git a/src/async/mutationHooks/category/useAddCategoryOptimisticMutation.ts b/src/async/mutationHooks/category/useAddCategoryOptimisticMutation.ts
deleted file mode 100644
index 8aa58221..00000000
--- a/src/async/mutationHooks/category/useAddCategoryOptimisticMutation.ts
+++ /dev/null
@@ -1,79 +0,0 @@
-import { useMutation, useQueryClient } from "@tanstack/react-query";
-
-import { useSupabaseSession } from "../../../store/componentStore";
-import { type CategoriesData } from "../../../types/apiTypes";
-import {
-	BOOKMARKS_COUNT_KEY,
-	CATEGORIES_KEY,
-	USER_PROFILE,
-} from "../../../utils/constants";
-import { addUserCategory } from "../../supabaseCrudHelpers";
-
-// adds new category optimistically
-export default function useAddCategoryOptimisticMutation() {
-	const session = useSupabaseSession((state) => state.session);
-	const queryClient = useQueryClient();
-
-	const addCategoryOptimisticMutation = useMutation({
-		mutationFn: addUserCategory,
-		onMutate: async (data) => {
-			// Cancel any outgoing refetches (so they don't overwrite our optimistic update)
-			await queryClient.cancelQueries({
-				queryKey: [CATEGORIES_KEY, session?.user?.id],
-			});
-
-			// Snapshot the previous value
-			const previousData = queryClient.getQueryData([
-				CATEGORIES_KEY,
-				session?.user?.id,
-			]);
-
-			// Optimistically update to the new value
-			queryClient.setQueryData(
-				[CATEGORIES_KEY, session?.user?.id],
-				(old: { data: CategoriesData[] } | undefined) => {
-					if (typeof old === "object") {
-						return {
-							...old,
-							data: [
-								...old.data,
-								{
-									category_name: data?.name,
-									user_id: session?.user?.id,
-									icon: "star-04",
-									icon_color: "#000000",
-								},
-							],
-						} as { data: CategoriesData[] };
-					}
-
-					return undefined;
-				},
-			);
-
-			// Return a context object with the snapshotted value
-			return { previousData };
-		},
-		// If the mutation fails, use the context returned from onMutate to roll back
-		onError: (context: { previousData: CategoriesData[] }) => {
-			queryClient.setQueryData(
-				[CATEGORIES_KEY, session?.user?.id],
-				context?.previousData,
-			);
-		},
-		// Always refetch after error or success:
-		onSettled: () => {
-			void queryClient.invalidateQueries({
-				queryKey: [CATEGORIES_KEY, session?.user?.id],
-			});
-			void queryClient.invalidateQueries({
-				queryKey: [USER_PROFILE, session?.user?.id],
-			});
-			void queryClient.invalidateQueries({
-				queryKey: [BOOKMARKS_COUNT_KEY, session?.user?.id],
-			});
-		},
-	});
-
-	return { addCategoryOptimisticMutation };
-}
diff --git a/src/async/mutationHooks/category/useUpdateCategoryOptimisticMutation.ts b/src/async/mutationHooks/category/useUpdateCategoryOptimisticMutation.ts
deleted file mode 100644
index 4658d5fa..00000000
--- a/src/async/mutationHooks/category/useUpdateCategoryOptimisticMutation.ts
+++ /dev/null
@@ -1,90 +0,0 @@
-import { useMutation, useQueryClient } from "@tanstack/react-query";
-
-import { useSupabaseSession } from "../../../store/componentStore";
-import { type CategoriesData } from "../../../types/apiTypes";
-import { CATEGORIES_KEY } from "../../../utils/constants";
-import { updateCategory } from "../../supabaseCrudHelpers";
-
-// updates a category optimistically
-export default function useUpdateCategoryOptimisticMutation() {
-	const session = useSupabaseSession((state) => state.session);
-	const queryClient = useQueryClient();
-	// const { sortBy } = useGetSortBy();
-	// const { category_id: CATEGORIES_ID } = useGetCurrentCategoryId();
-
-	const updateCategoryOptimisticMutation = useMutation({
-		mutationFn: updateCategory,
-		onMutate: async (data) => {
-			// Cancel any outgoing refetches (so they don't overwrite our optimistic update)
-			await queryClient.cancelQueries({
-				queryKey: [CATEGORIES_KEY, session?.user?.id],
-			});
-
-			// Snapshot the previous value
-			const previousData = queryClient.getQueryData([
-				CATEGORIES_KEY,
-				session?.user?.id,
-			]);
-
-			// Optimistically update to the new value
-			queryClient.setQueryData(
-				[CATEGORIES_KEY, session?.user?.id],
-				(old: { data: CategoriesData[] } | undefined) =>
-					({
-						...old,
-
-						data: old?.data?.map((item) => {
-							if (item?.id === data?.category_id) {
-								return {
-									...item,
-									category_name: data?.updateData?.category_name
-										? data?.updateData?.category_name
-										: item?.category_name,
-									category_views: data?.updateData?.category_views
-										? data?.updateData?.category_views
-										: item?.category_views,
-									icon: data?.updateData?.icon
-										? data?.updateData?.icon
-										: item?.icon,
-									icon_color: data?.updateData?.icon_color
-										? data?.updateData?.icon_color
-										: item?.icon_color,
-									is_public:
-										data?.updateData?.is_public !== undefined
-											? data?.updateData?.is_public
-											: item?.is_public,
-								};
-							}
-
-							return item;
-						}),
-					}) as { data: CategoriesData[] },
-			);
-
-			// Return a context object with the snapshotted value
-			return { previousData };
-		},
-		// If the mutation fails, use the context returned from onMutate to roll back
-		onError: (context: { previousData: CategoriesData }) => {
-			queryClient.setQueryData(
-				[CATEGORIES_KEY, session?.user?.id],
-				context?.previousData,
-			);
-		},
-		// Always refetch after error or success:
-		onSettled: () => {
-			void queryClient.invalidateQueries({
-				queryKey: [CATEGORIES_KEY, session?.user?.id],
-			});
-			// removed due to the multiple get bookmark fetch when changing sort by issue
-			// void queryClient.invalidateQueries([
-			// 	BOOKMARKS_KEY,
-			// 	session?.user?.id,
-			// 	CATEGORIES_ID,
-			// 	// sortBy
-			// ]);
-		},
-	});
-
-	return { updateCategoryOptimisticMutation };
-}
diff --git a/src/async/mutationHooks/tags/use-add-tag-to-bookmark-optimistic-mutation.ts b/src/async/mutationHooks/tags/use-add-tag-to-bookmark-optimistic-mutation.ts
new file mode 100644
index 00000000..04ff0f50
--- /dev/null
+++ b/src/async/mutationHooks/tags/use-add-tag-to-bookmark-optimistic-mutation.ts
@@ -0,0 +1,101 @@
+import {
+	type AddTagToBookmarkPayload,
+	type AddTagToBookmarkResponse,
+} from "@/app/api/tags/add-tag-to-bookmark/route";
+import { useBookmarkMutationContext } from "@/hooks/use-bookmark-mutation-context";
+import { useReactQueryOptimisticMutation } from "@/hooks/use-react-query-optimistic-mutation";
+import { postApi } from "@/lib/api-helpers/api";
+import { type PaginatedBookmarks, type UserTagsData } from "@/types/apiTypes";
+import { logCacheMiss } from "@/utils/cache-debug-helpers";
+import {
+	ADD_TAG_TO_BOOKMARK_API,
+	BOOKMARKS_KEY,
+	USER_TAGS_KEY,
+} from "@/utils/constants";
+import { updateBookmarkInPaginatedData } from "@/utils/query-cache-helpers";
+
+/**
+ * Mutation hook for adding an existing tag to a bookmark.
+ * This is additive - it adds to existing tags without removing them.
+ */
+export function useAddTagToBookmarkOptimisticMutation() {
+	const { queryClient, session, queryKey, searchQueryKey } =
+		useBookmarkMutationContext();
+
+	const addTagToBookmarkOptimisticMutation = useReactQueryOptimisticMutation<
+		AddTagToBookmarkResponse,
+		Error,
+		AddTagToBookmarkPayload,
+		typeof queryKey,
+		PaginatedBookmarks
+	>({
+		mutationFn: (payload) =>
+			postApi<AddTagToBookmarkResponse>(
+				`/api${ADD_TAG_TO_BOOKMARK_API}`,
+				payload,
+			),
+		queryKey,
+		secondaryQueryKey: searchQueryKey,
+
+		updater: (currentData, variables) => {
+			if (!currentData?.pages) {
+				return currentData as PaginatedBookmarks;
+			}
+
+			// Resolve tag from cache - skip optimistic update if not found
+			const userTagsData = queryClient.getQueryData([
+				USER_TAGS_KEY,
+				session?.user?.id,
+			]) as { data: UserTagsData[] } | undefined;
+
+			const tagInfo = userTagsData?.data?.find(
+				(tag) => tag.id === variables.tagId,
+			);
+
+			if (!tagInfo) {
+				logCacheMiss("Optimistic Update", "Tag not found in cache", {
+					bookmarkId: variables.bookmarkId,
+					tagId: variables.tagId,
+				});
+				return currentData;
+			}
+
+			return (
+				updateBookmarkInPaginatedData(
+					currentData,
+					variables.bookmarkId,
+					(bookmark) => {
+						// Check for duplicates
+						const alreadyHasTag = bookmark.addedTags?.some(
+							(tag) => tag.id === variables.tagId,
+						);
+						if (alreadyHasTag) {
+							return;
+						}
+
+						bookmark.addedTags = [
+							...(bookmark.addedTags ?? []),
+							{ id: variables.tagId, name: tagInfo.name } as UserTagsData,
+						];
+					},
+				) ?? currentData
+			);
+		},
+
+		onSettled: (_data, error) => {
+			if (error) {
+				return;
+			}
+
+			// Invalidate ALL bookmark queries for user (covers all collections)
+			void queryClient.invalidateQueries({
+				queryKey: [BOOKMARKS_KEY, session?.user?.id],
+			});
+		},
+
+		showSuccessToast: true,
+		successMessage: "Tag added",
+	});
+
+	return { addTagToBookmarkOptimisticMutation };
+}
diff --git a/src/async/mutationHooks/tags/use-create-and-assign-tag-optimistic-mutation.ts b/src/async/mutationHooks/tags/use-create-and-assign-tag-optimistic-mutation.ts
new file mode 100644
index 00000000..1e326e2e
--- /dev/null
+++ b/src/async/mutationHooks/tags/use-create-and-assign-tag-optimistic-mutation.ts
@@ -0,0 +1,202 @@
+import { produce } from "immer";
+
+import {
+	type CreateAndAssignTagPayload,
+	type CreateAndAssignTagResponse,
+} from "@/app/api/tags/create-and-assign-tag/route";
+import { useBookmarkMutationContext } from "@/hooks/use-bookmark-mutation-context";
+import { useReactQueryOptimisticMutation } from "@/hooks/use-react-query-optimistic-mutation";
+import { postApi } from "@/lib/api-helpers/api";
+import {
+	type PaginatedBookmarks,
+	type TempTag,
+	type UserTagsData,
+} from "@/types/apiTypes";
+import { logCacheMiss } from "@/utils/cache-debug-helpers";
+import {
+	BOOKMARKS_KEY,
+	CREATE_AND_ASSIGN_TAG_API,
+	USER_TAGS_KEY,
+} from "@/utils/constants";
+import {
+	swapTempTagId,
+	swapTempTagInUserTagsCache,
+	updateBookmarkInPaginatedData,
+} from "@/utils/query-cache-helpers";
+
+/**
+ * Extended payload type with optional temp ID for optimistic updates.
+ * When provided, both BOOKMARKS_KEY and USER_TAGS_KEY caches use the same
+ * temp ID, preventing UI flash from ID mismatches during lookup.
+ */
+type CreateAndAssignTagMutationPayload = CreateAndAssignTagPayload & {
+	_tempId?: number;
+};
+
+/**
+ * Internal payload type with guaranteed temp ID.
+ * The wrapper ensures _tempId is always set before mutation lifecycle runs.
+ */
+type InternalPayload = CreateAndAssignTagPayload & {
+	_tempId: number;
+};
+
+/**
+ * Mutation hook for creating a new tag and assigning it to a bookmark in one atomic operation.
+ * Uses PostgreSQL RPC function for transaction safety.
+ */
+export function useCreateAndAssignTagOptimisticMutation() {
+	const { queryClient, session, queryKey, searchQueryKey } =
+		useBookmarkMutationContext();
+
+	const baseMutation = useReactQueryOptimisticMutation<
+		CreateAndAssignTagResponse,
+		Error,
+		InternalPayload,
+		typeof queryKey,
+		PaginatedBookmarks
+	>({
+		mutationFn: (payload) =>
+			postApi<CreateAndAssignTagResponse>(
+				`/api${CREATE_AND_ASSIGN_TAG_API}`,
+				payload,
+			),
+		queryKey,
+		secondaryQueryKey: searchQueryKey,
+
+		updater: (currentData, variables) => {
+			if (!currentData?.pages) {
+				return currentData as PaginatedBookmarks;
+			}
+
+			return (
+				updateBookmarkInPaginatedData(
+					currentData,
+					variables.bookmarkId,
+					(bookmark) => {
+						const tempTag: TempTag = {
+							id: variables._tempId,
+							name: variables.name,
+						};
+						bookmark.addedTags = [...(bookmark.addedTags || []), tempTag];
+					},
+				) ?? currentData
+			);
+		},
+
+		// Additional optimistic updates for user tags cache
+		additionalOptimisticUpdates: [
+			// User tags cache
+			{
+				getQueryKey: () => [USER_TAGS_KEY, session?.user?.id],
+				updater: (currentData, variables) => {
+					const data = currentData as { data: UserTagsData[] } | undefined;
+
+					if (!data?.data) {
+						logCacheMiss("Optimistic Update", "User tags cache not found", {
+							bookmarkId: variables.bookmarkId,
+						});
+						return currentData;
+					}
+
+					// Use shared temp ID from variables to match BOOKMARKS_KEY cache
+					// Single localized cast: USER_TAGS_KEY cache expects full UserTagsData,
+					// but temp tags only have id/name/user_id until server responds
+					const tempTag: TempTag & { user_id?: string } = {
+						id: variables._tempId,
+						name: variables.name,
+						user_id: session?.user?.id,
+					};
+
+					return produce(data, (draft) => {
+						draft.data.push(tempTag as UserTagsData);
+					});
+				},
+			},
+		],
+
+		onSettled: (data, error, variables) => {
+			if (error || !data) {
+				return;
+			}
+
+			const { _tempId: tempId } = variables;
+			const realTag = data.tag;
+
+			// Update primary cache - swap temp tag with real tag
+			queryClient.setQueryData<PaginatedBookmarks>(queryKey, (current) =>
+				updateBookmarkInPaginatedData(
+					current,
+					variables.bookmarkId,
+					(bookmark) => {
+						swapTempTagId(bookmark, tempId, realTag);
+					},
+				),
+			);
+
+			// Update search cache if active
+			if (searchQueryKey) {
+				queryClient.setQueryData<PaginatedBookmarks>(
+					searchQueryKey,
+					(current) =>
+						updateBookmarkInPaginatedData(
+							current,
+							variables.bookmarkId,
+							(bookmark) => {
+								swapTempTagId(bookmark, tempId, realTag);
+							},
+						),
+				);
+			}
+
+			// Update USER_TAGS_KEY cache - swap temp tag with real tag
+			queryClient.setQueryData<{ data: UserTagsData[] }>(
+				[USER_TAGS_KEY, session?.user?.id],
+				(current) =>
+					swapTempTagInUserTagsCache(current, tempId, {
+						id: realTag.id,
+						name: realTag.name,
+						user_id: realTag.user_id ?? undefined,
+						created_at: realTag.created_at ?? undefined,
+					}),
+			);
+
+			void queryClient.invalidateQueries({
+				queryKey: [BOOKMARKS_KEY, session?.user?.id],
+			});
+			void queryClient.invalidateQueries({
+				queryKey: [USER_TAGS_KEY, session?.user?.id],
+			});
+		},
+
+		showSuccessToast: true,
+		successMessage: "Tag created",
+	});
+
+	// Wrap mutation to ensure _tempId is generated once before any lifecycle hook runs
+	const createAndAssignTagOptimisticMutation = {
+		...baseMutation,
+		mutate: (
+			variables: CreateAndAssignTagMutationPayload,
+			options?: Parameters<typeof baseMutation.mutate>[1],
+		) => {
+			const enrichedVariables: InternalPayload = {
+				...variables,
+				_tempId: variables._tempId ?? -Date.now(),
+			};
+			baseMutation.mutate(enrichedVariables, options);
+		},
+		mutateAsync: (
+			variables: CreateAndAssignTagMutationPayload,
+			options?: Parameters<typeof baseMutation.mutateAsync>[1],
+		) => {
+			const enrichedVariables: InternalPayload = {
+				...variables,
+				_tempId: variables._tempId ?? -Date.now(),
+			};
+			return baseMutation.mutateAsync(enrichedVariables, options);
+		},
+	};
+
+	return { createAndAssignTagOptimisticMutation };
+}
diff --git a/src/async/mutationHooks/tags/use-remove-tag-from-bookmark-optimistic-mutation.ts b/src/async/mutationHooks/tags/use-remove-tag-from-bookmark-optimistic-mutation.ts
new file mode 100644
index 00000000..6b11e1e6
--- /dev/null
+++ b/src/async/mutationHooks/tags/use-remove-tag-from-bookmark-optimistic-mutation.ts
@@ -0,0 +1,69 @@
+import {
+	type RemoveTagFromBookmarkPayload,
+	type RemoveTagFromBookmarkResponse,
+} from "@/app/api/tags/remove-tag-from-bookmark/route";
+import { useBookmarkMutationContext } from "@/hooks/use-bookmark-mutation-context";
+import { useReactQueryOptimisticMutation } from "@/hooks/use-react-query-optimistic-mutation";
+import { postApi } from "@/lib/api-helpers/api";
+import { type PaginatedBookmarks } from "@/types/apiTypes";
+import { BOOKMARKS_KEY, REMOVE_TAG_FROM_BOOKMARK_API } from "@/utils/constants";
+import { updateBookmarkInPaginatedData } from "@/utils/query-cache-helpers";
+
+/**
+ * Mutation hook for removing a tag from a bookmark.
+ */
+export function useRemoveTagFromBookmarkOptimisticMutation() {
+	const { queryClient, session, queryKey, searchQueryKey } =
+		useBookmarkMutationContext();
+
+	const removeTagFromBookmarkOptimisticMutation =
+		useReactQueryOptimisticMutation<
+			RemoveTagFromBookmarkResponse,
+			Error,
+			RemoveTagFromBookmarkPayload,
+			typeof queryKey,
+			PaginatedBookmarks
+		>({
+			mutationFn: (payload) =>
+				postApi<RemoveTagFromBookmarkResponse>(
+					`/api${REMOVE_TAG_FROM_BOOKMARK_API}`,
+					payload,
+				),
+			queryKey,
+			secondaryQueryKey: searchQueryKey,
+
+			updater: (currentData, variables) => {
+				if (!currentData?.pages) {
+					return currentData as PaginatedBookmarks;
+				}
+
+				return (
+					updateBookmarkInPaginatedData(
+						currentData,
+						variables.bookmarkId,
+						(bookmark) => {
+							bookmark.addedTags = bookmark.addedTags?.filter(
+								(tag) => tag.id !== variables.tagId,
+							);
+						},
+					) ?? currentData
+				);
+			},
+
+			onSettled: (_data, error) => {
+				if (error) {
+					return;
+				}
+
+				// Invalidate ALL bookmark queries for user (covers all collections)
+				void queryClient.invalidateQueries({
+					queryKey: [BOOKMARKS_KEY, session?.user?.id],
+				});
+			},
+
+			showSuccessToast: true,
+			successMessage: "Tag removed",
+		});
+
+	return { removeTagFromBookmarkOptimisticMutation };
+}
diff --git a/src/async/mutationHooks/tags/useAddTagToBookmarkMutation.ts b/src/async/mutationHooks/tags/useAddTagToBookmarkMutation.ts
deleted file mode 100644
index 60490d85..00000000
--- a/src/async/mutationHooks/tags/useAddTagToBookmarkMutation.ts
+++ /dev/null
@@ -1,196 +0,0 @@
-import { useMutation, useQueryClient } from "@tanstack/react-query";
-import { find, isArray } from "lodash";
-
-import useGetCurrentCategoryId from "../../../hooks/useGetCurrentCategoryId";
-import useGetSortBy from "../../../hooks/useGetSortBy";
-import {
-	useMiscellaneousStore,
-	useSupabaseSession,
-} from "../../../store/componentStore";
-import {
-	type AddTagToBookmarkApiPayload,
-	type SingleListData,
-	type UserTagsData,
-} from "../../../types/apiTypes";
-import { BOOKMARKS_KEY, USER_TAGS_KEY } from "../../../utils/constants";
-import { addTagToBookmark } from "../../supabaseCrudHelpers";
-
-import useDebounce from "@/hooks/useDebounce";
-
-// add tag to a bookmark
-export function useAddTagToBookmarkMutation() {
-	const queryClient = useQueryClient();
-	const session = useSupabaseSession((state) => state.session);
-	const { category_id: CATEGORY_ID } = useGetCurrentCategoryId();
-	const { sortBy } = useGetSortBy();
-	const searchText = useMiscellaneousStore((state) => state.searchText);
-	const debouncedSearch = useDebounce(searchText, 500);
-
-	const addTagToBookmarkMutation = useMutation({
-		mutationFn: addTagToBookmark,
-		onMutate: async (data: AddTagToBookmarkApiPayload) => {
-			// Cancel any outgoing refetches (so they don't overwrite our optimistic update)
-			await queryClient.cancelQueries({
-				queryKey: [BOOKMARKS_KEY, session?.user?.id, CATEGORY_ID, sortBy],
-			});
-			if (debouncedSearch) {
-				await queryClient.cancelQueries({
-					queryKey: [
-						BOOKMARKS_KEY,
-						session?.user?.id,
-						CATEGORY_ID,
-						debouncedSearch,
-					],
-				});
-			}
-
-			// Snapshot the previous value
-			const previousData = queryClient.getQueryData([
-				BOOKMARKS_KEY,
-				session?.user?.id,
-				CATEGORY_ID,
-				sortBy,
-			]);
-			const previousSearchData = debouncedSearch
-				? queryClient.getQueryData([
-						BOOKMARKS_KEY,
-						session?.user?.id,
-						CATEGORY_ID,
-						debouncedSearch,
-					])
-				: undefined;
-
-			const userTagsData = queryClient.getQueryData([
-				USER_TAGS_KEY,
-				session?.user?.id,
-			]) as {
-				data: UserTagsData[];
-			};
-
-			const updatingTag = find(
-				userTagsData?.data,
-				(item) =>
-					item?.id ===
-					(!isArray(data?.selectedData) ? data?.selectedData.tag_id : null),
-			);
-
-			// Helper to update bookmark tags in paginated data
-			const updateBookmarkTagsInCache = (oldData: unknown) => {
-				const old = oldData as { pages: Array<{ data: SingleListData[] }> };
-				if (!old?.pages) {
-					return oldData;
-				}
-
-				return {
-					...old,
-					pages: old?.pages?.map((pagesItem) => ({
-						...pagesItem,
-						data: pagesItem?.data?.map((dataItem) => {
-							if (
-								dataItem?.id ===
-								(!isArray(data?.selectedData)
-									? data?.selectedData.bookmark_id
-									: null)
-							) {
-								if (dataItem?.addedTags) {
-									return {
-										...dataItem,
-										addedTags: [
-											...dataItem.addedTags,
-											{ id: updatingTag?.id, name: updatingTag?.name },
-										],
-									};
-								} else {
-									return {
-										...dataItem,
-										addedTags: [
-											{ id: updatingTag?.id, name: updatingTag?.name },
-										],
-									};
-								}
-							} else {
-								return dataItem;
-							}
-						}),
-					})),
-				};
-			};
-
-			// Optimistically update regular bookmarks cache
-			queryClient.setQueryData(
-				[BOOKMARKS_KEY, session?.user?.id, CATEGORY_ID, sortBy],
-				updateBookmarkTagsInCache,
-			);
-
-			if (debouncedSearch) {
-				queryClient.setQueryData(
-					[BOOKMARKS_KEY, session?.user?.id, CATEGORY_ID, debouncedSearch],
-					updateBookmarkTagsInCache,
-				);
-			}
-
-			// Return a context object with the snapshotted value (include debouncedSearch to avoid stale closure)
-			return { previousData, previousSearchData, debouncedSearch };
-		},
-		// If the mutation fails, use the context returned from onMutate to roll back
-		onError: (
-			_error,
-			_variables,
-			context:
-				| {
-						previousData: unknown;
-						previousSearchData: unknown;
-						debouncedSearch: string;
-				  }
-				| undefined,
-		) => {
-			if (context?.previousData) {
-				queryClient.setQueryData(
-					[BOOKMARKS_KEY, session?.user?.id, CATEGORY_ID, sortBy],
-					context.previousData,
-				);
-			}
-
-			if (context?.previousSearchData && context?.debouncedSearch) {
-				queryClient.setQueryData(
-					[
-						BOOKMARKS_KEY,
-						session?.user?.id,
-						CATEGORY_ID,
-						context.debouncedSearch,
-					],
-					context.previousSearchData,
-				);
-			}
-		},
-		// Always refetch after error or success:
-		onSettled: (
-			_data,
-			_error,
-			_variables,
-			context:
-				| {
-						previousData: unknown;
-						previousSearchData: unknown;
-						debouncedSearch: string;
-				  }
-				| undefined,
-		) => {
-			void queryClient.invalidateQueries({
-				queryKey: [BOOKMARKS_KEY, session?.user?.id, CATEGORY_ID, sortBy],
-			});
-			// Use captured debouncedSearch from context to avoid stale closure
-			if (context?.debouncedSearch) {
-				void queryClient.invalidateQueries({
-					queryKey: [
-						BOOKMARKS_KEY,
-						session?.user?.id,
-						CATEGORY_ID,
-						context.debouncedSearch,
-					],
-				});
-			}
-		},
-	});
-	return { addTagToBookmarkMutation };
-}
diff --git a/src/async/mutationHooks/tags/useCreateAndAssignTagMutation.ts b/src/async/mutationHooks/tags/useCreateAndAssignTagMutation.ts
deleted file mode 100644
index 164f6257..00000000
--- a/src/async/mutationHooks/tags/useCreateAndAssignTagMutation.ts
+++ /dev/null
@@ -1,243 +0,0 @@
-import { useMutation, useQueryClient } from "@tanstack/react-query";
-
-import useGetCurrentCategoryId from "../../../hooks/useGetCurrentCategoryId";
-import useGetSortBy from "../../../hooks/useGetSortBy";
-import {
-	useMiscellaneousStore,
-	useSupabaseSession,
-} from "../../../store/componentStore";
-import {
-	type BookmarksTagData,
-	type SingleListData,
-	type UserTagsData,
-} from "../../../types/apiTypes";
-import { BOOKMARKS_KEY, USER_TAGS_KEY } from "../../../utils/constants";
-import { addTagToBookmark, addUserTags } from "../../supabaseCrudHelpers";
-
-import useDebounce from "@/hooks/useDebounce";
-import { handleClientError } from "@/utils/error-utils/client";
-
-type CreateAndAssignTagPayload = {
-	tagName: string;
-	bookmarkId: number;
-};
-
-export function useCreateAndAssignTagMutation() {
-	const queryClient = useQueryClient();
-	const session = useSupabaseSession((state) => state.session);
-	const { category_id: CATEGORY_ID } = useGetCurrentCategoryId();
-	const { sortBy } = useGetSortBy();
-	const searchText = useMiscellaneousStore((state) => state.searchText);
-	const debouncedSearch = useDebounce(searchText, 500);
-
-	const createAndAssignTagMutation = useMutation({
-		mutationFn: async ({ tagName, bookmarkId }: CreateAndAssignTagPayload) => {
-			const tagResponse = (await addUserTags({
-				tagsData: { name: tagName },
-			})) as { data: UserTagsData[] };
-
-			if (!tagResponse?.data || "message" in tagResponse) {
-				handleClientError("Failed to create tag");
-				throw new Error("Failed to create tag");
-			}
-
-			const newTagId = tagResponse?.data?.[0]?.id;
-			if (!newTagId) {
-				handleClientError("Failed to create tag: missing tag ID");
-				throw new Error("Failed to create tag: missing tag ID");
-			}
-
-			const bookmarkResponse = (await addTagToBookmark({
-				selectedData: {
-					bookmark_id: bookmarkId,
-					tag_id: newTagId,
-				} as BookmarksTagData,
-			})) as { data: SingleListData } | { message: string };
-
-			if (!("data" in bookmarkResponse) || "message" in bookmarkResponse) {
-				handleClientError("Failed to assign tag to bookmark");
-				throw new Error("Failed to assign tag to bookmark");
-			}
-
-			return { tagId: newTagId, tagName };
-		},
-		onMutate: async ({ tagName, bookmarkId }: CreateAndAssignTagPayload) => {
-			// Cancel outgoing refetches
-			await queryClient.cancelQueries({
-				queryKey: [USER_TAGS_KEY, session?.user?.id],
-			});
-			await queryClient.cancelQueries({
-				queryKey: [BOOKMARKS_KEY, session?.user?.id, CATEGORY_ID, sortBy],
-			});
-			if (debouncedSearch) {
-				await queryClient.cancelQueries({
-					queryKey: [
-						BOOKMARKS_KEY,
-						session?.user?.id,
-						CATEGORY_ID,
-						debouncedSearch,
-					],
-				});
-			}
-
-			const previousUserTags = queryClient.getQueryData([
-				USER_TAGS_KEY,
-				session?.user?.id,
-			]);
-			const previousBookmarks = queryClient.getQueryData([
-				BOOKMARKS_KEY,
-				session?.user?.id,
-				CATEGORY_ID,
-				sortBy,
-			]);
-			const previousSearchData = debouncedSearch
-				? queryClient.getQueryData([
-						BOOKMARKS_KEY,
-						session?.user?.id,
-						CATEGORY_ID,
-						debouncedSearch,
-					])
-				: undefined;
-
-			const tempId = -Date.now();
-
-			queryClient.setQueryData(
-				[USER_TAGS_KEY, session?.user?.id],
-				(oldData: { data: UserTagsData[] } | undefined) => {
-					const newTag = {
-						id: tempId,
-						name: tagName,
-						user_id: session?.user?.id,
-					};
-					if (!oldData) {
-						return { data: [newTag] };
-					}
-
-					return { ...oldData, data: [...(oldData.data || []), newTag] };
-				},
-			);
-
-			// Helper to update bookmark tags in paginated data
-			const updateBookmarkTagsInCache = (oldData: unknown) => {
-				const old = oldData as {
-					pages: Array<{ data: SingleListData[] }>;
-				};
-				if (!old?.pages) {
-					return oldData;
-				}
-
-				return {
-					...old,
-					pages: old.pages.map((pagesItem) => ({
-						...pagesItem,
-						data: pagesItem?.data?.map((dataItem) => {
-							if (dataItem?.id === bookmarkId) {
-								return {
-									...dataItem,
-									addedTags: [
-										...(dataItem.addedTags || []),
-										{ id: tempId, name: tagName },
-									],
-								};
-							}
-
-							return dataItem;
-						}),
-					})),
-				};
-			};
-
-			// Update regular bookmarks cache
-			queryClient.setQueryData(
-				[BOOKMARKS_KEY, session?.user?.id, CATEGORY_ID, sortBy],
-				updateBookmarkTagsInCache,
-			);
-
-			if (debouncedSearch) {
-				queryClient.setQueryData(
-					[BOOKMARKS_KEY, session?.user?.id, CATEGORY_ID, debouncedSearch],
-					updateBookmarkTagsInCache,
-				);
-			}
-
-			return {
-				previousUserTags,
-				previousBookmarks,
-				previousSearchData,
-				tempId,
-				debouncedSearch,
-			};
-		},
-		onError: (
-			_error,
-			_variables,
-			context:
-				| {
-						previousUserTags: unknown;
-						previousBookmarks: unknown;
-						previousSearchData: unknown;
-						debouncedSearch: string;
-				  }
-				| undefined,
-		) => {
-			if (context?.previousUserTags) {
-				queryClient.setQueryData(
-					[USER_TAGS_KEY, session?.user?.id],
-					context.previousUserTags,
-				);
-			}
-
-			if (context?.previousBookmarks) {
-				queryClient.setQueryData(
-					[BOOKMARKS_KEY, session?.user?.id, CATEGORY_ID, sortBy],
-					context.previousBookmarks,
-				);
-			}
-
-			if (context?.previousSearchData && context?.debouncedSearch) {
-				queryClient.setQueryData(
-					[
-						BOOKMARKS_KEY,
-						session?.user?.id,
-						CATEGORY_ID,
-						context?.debouncedSearch,
-					],
-					context.previousSearchData,
-				);
-			}
-		},
-		onSettled: (
-			_data,
-			_error,
-			_variables,
-			context:
-				| {
-						previousUserTags: unknown;
-						previousBookmarks: unknown;
-						previousSearchData: unknown;
-						debouncedSearch: string;
-				  }
-				| undefined,
-		) => {
-			void queryClient.invalidateQueries({
-				queryKey: [USER_TAGS_KEY, session?.user?.id],
-			});
-			void queryClient.invalidateQueries({
-				queryKey: [BOOKMARKS_KEY, session?.user?.id, CATEGORY_ID, sortBy],
-			});
-			// Use captured debouncedSearch from context to avoid stale closure
-			if (context?.debouncedSearch) {
-				void queryClient.invalidateQueries({
-					queryKey: [
-						BOOKMARKS_KEY,
-						session?.user?.id,
-						CATEGORY_ID,
-						context?.debouncedSearch,
-					],
-				});
-			}
-		},
-	});
-
-	return { createAndAssignTagMutation };
-}
diff --git a/src/async/mutationHooks/tags/useRemoveTagFromBookmarkMutation.ts b/src/async/mutationHooks/tags/useRemoveTagFromBookmarkMutation.ts
deleted file mode 100644
index febada9c..00000000
--- a/src/async/mutationHooks/tags/useRemoveTagFromBookmarkMutation.ts
+++ /dev/null
@@ -1,194 +0,0 @@
-import { useMutation, useQueryClient } from "@tanstack/react-query";
-import { find, isArray } from "lodash";
-
-import useGetCurrentCategoryId from "../../../hooks/useGetCurrentCategoryId";
-import useGetSortBy from "../../../hooks/useGetSortBy";
-import {
-	useMiscellaneousStore,
-	useSupabaseSession,
-} from "../../../store/componentStore";
-import {
-	type SingleListData,
-	type UserTagsData,
-} from "../../../types/apiTypes";
-import { BOOKMARKS_KEY, USER_TAGS_KEY } from "../../../utils/constants";
-import { removeTagFromBookmark } from "../../supabaseCrudHelpers";
-
-import useDebounce from "@/hooks/useDebounce";
-
-// remove tag from a bookmark
-export function useRemoveTagFromBookmarkMutation() {
-	const queryClient = useQueryClient();
-	const session = useSupabaseSession((state) => state.session);
-	const { category_id: CATEGORY_ID } = useGetCurrentCategoryId();
-	const { sortBy } = useGetSortBy();
-	const searchText = useMiscellaneousStore((state) => state.searchText);
-	const debouncedSearch = useDebounce(searchText, 500);
-
-	const removeTagFromBookmarkMutation = useMutation({
-		mutationFn: removeTagFromBookmark,
-		onMutate: async (data) => {
-			// Cancel any outgoing refetches (so they don't overwrite our optimistic update)
-			await queryClient.cancelQueries({
-				queryKey: [BOOKMARKS_KEY, session?.user?.id, CATEGORY_ID, sortBy],
-			});
-			if (debouncedSearch) {
-				await queryClient.cancelQueries({
-					queryKey: [
-						BOOKMARKS_KEY,
-						session?.user?.id,
-						CATEGORY_ID,
-						debouncedSearch,
-					],
-				});
-			}
-
-			// Snapshot the previous value
-			const previousData = queryClient.getQueryData([
-				BOOKMARKS_KEY,
-				session?.user?.id,
-				CATEGORY_ID,
-				sortBy,
-			]);
-			const previousSearchData = debouncedSearch
-				? queryClient.getQueryData([
-						BOOKMARKS_KEY,
-						session?.user?.id,
-						CATEGORY_ID,
-						debouncedSearch,
-					])
-				: undefined;
-
-			const userTagsData = queryClient.getQueryData([
-				USER_TAGS_KEY,
-				session?.user?.id,
-			]) as {
-				data: UserTagsData[];
-			};
-
-			const updatingTag = find(
-				userTagsData?.data,
-				(item) =>
-					item?.id ===
-					(!isArray(data?.selectedData) ? data?.selectedData.tag_id : null),
-			);
-
-			// Helper to remove tag from bookmark in paginated data
-			const removeTagFromBookmarkInCache = (oldData: unknown) => {
-				const old = oldData as { pages: Array<{ data: SingleListData[] }> };
-				if (!old?.pages) {
-					return oldData;
-				}
-
-				return {
-					...old,
-					pages: old?.pages?.map((pagesItem) => ({
-						...pagesItem,
-						data: pagesItem?.data?.map((dataItem) => {
-							if (
-								dataItem?.id ===
-								(!isArray(data?.selectedData)
-									? data?.selectedData.bookmark_id
-									: null)
-							) {
-								if (dataItem?.addedTags) {
-									return {
-										...dataItem,
-										addedTags: dataItem.addedTags?.filter(
-											(tagItem) => tagItem.id !== updatingTag?.id,
-										),
-									};
-								} else {
-									return {
-										...dataItem,
-										addedTags: [],
-									};
-								}
-							} else {
-								return dataItem;
-							}
-						}),
-					})),
-				};
-			};
-
-			// Optimistically update regular bookmarks cache
-			queryClient.setQueryData(
-				[BOOKMARKS_KEY, session?.user?.id, CATEGORY_ID, sortBy],
-				removeTagFromBookmarkInCache,
-			);
-
-			// Also update search cache if searching
-			if (debouncedSearch) {
-				queryClient.setQueryData(
-					[BOOKMARKS_KEY, session?.user?.id, CATEGORY_ID, debouncedSearch],
-					removeTagFromBookmarkInCache,
-				);
-			}
-
-			// Return a context object with the snapshotted value (include debouncedSearch to avoid stale closure)
-			return { previousData, previousSearchData, debouncedSearch };
-		},
-		// If the mutation fails, use the context returned from onMutate to roll back
-		onError: (
-			_error,
-			_variables,
-			context:
-				| {
-						previousData: unknown;
-						previousSearchData: unknown;
-						debouncedSearch: string;
-				  }
-				| undefined,
-		) => {
-			if (context?.previousData) {
-				queryClient.setQueryData(
-					[BOOKMARKS_KEY, session?.user?.id, CATEGORY_ID, sortBy],
-					context.previousData,
-				);
-			}
-
-			if (context?.previousSearchData && context?.debouncedSearch) {
-				queryClient.setQueryData(
-					[
-						BOOKMARKS_KEY,
-						session?.user?.id,
-						CATEGORY_ID,
-						context.debouncedSearch,
-					],
-					context.previousSearchData,
-				);
-			}
-		},
-		// Always refetch after error or success:
-		onSettled: (
-			_data,
-			_error,
-			_variables,
-			context:
-				| {
-						previousData: unknown;
-						previousSearchData: unknown;
-						debouncedSearch: string;
-				  }
-				| undefined,
-		) => {
-			void queryClient.invalidateQueries({
-				queryKey: [BOOKMARKS_KEY, session?.user?.id, CATEGORY_ID, sortBy],
-			});
-			// Use captured debouncedSearch from context to avoid stale closure
-			if (context?.debouncedSearch) {
-				void queryClient.invalidateQueries({
-					queryKey: [
-						BOOKMARKS_KEY,
-						session?.user?.id,
-						CATEGORY_ID,
-						context.debouncedSearch,
-					],
-				});
-			}
-		},
-	});
-
-	return { removeTagFromBookmarkMutation };
-}
diff --git a/src/async/queryHooks/bookmarks/use-fetch-discover-bookmarks.ts b/src/async/queryHooks/bookmarks/use-fetch-discover-bookmarks.ts
new file mode 100644
index 00000000..bde7dd0a
--- /dev/null
+++ b/src/async/queryHooks/bookmarks/use-fetch-discover-bookmarks.ts
@@ -0,0 +1,56 @@
+import { useInfiniteQuery } from "@tanstack/react-query";
+
+import { getApi } from "@/lib/api-helpers/api";
+import { type SingleListData } from "@/types/apiTypes";
+import {
+	BOOKMARKS_KEY,
+	DISCOVER_URL,
+	FETCH_BOOKMARKS_DISCOVERABLE_API,
+	NEXT_API_URL,
+	PAGINATION_LIMIT,
+} from "@/utils/constants";
+
+type UseFetchDiscoverBookmarksOptions = {
+	enabled?: boolean;
+};
+
+export const useFetchDiscoverBookmarks = (
+	options: UseFetchDiscoverBookmarksOptions = {},
+) => {
+	const { enabled = true } = options;
+
+	const {
+		data: discoverData,
+		fetchNextPage,
+		hasNextPage,
+		isFetchingNextPage,
+		isLoading,
+	} = useInfiniteQuery({
+		queryKey: [BOOKMARKS_KEY, DISCOVER_URL],
+		queryFn: async ({ pageParam }) => {
+			const data = await getApi<SingleListData[]>(
+				`${NEXT_API_URL}${FETCH_BOOKMARKS_DISCOVERABLE_API}?page=${pageParam}`,
+			);
+			return { data };
+		},
+		initialPageParam: 0,
+		getNextPageParam: (lastPage, pages) => {
+			const lastPageLength = lastPage?.data?.length ?? 0;
+
+			if (lastPageLength < PAGINATION_LIMIT) {
+				return undefined;
+			}
+
+			return pages.length;
+		},
+		enabled,
+	});
+
+	return {
+		discoverData,
+		fetchNextPage,
+		hasNextPage: hasNextPage ?? false,
+		isFetchingNextPage,
+		isLoading,
+	};
+};
diff --git a/src/async/queryHooks/bookmarks/useFetchBookmarkById.ts b/src/async/queryHooks/bookmarks/useFetchBookmarkById.ts
index d140a3cb..7b9ef75a 100644
--- a/src/async/queryHooks/bookmarks/useFetchBookmarkById.ts
+++ b/src/async/queryHooks/bookmarks/useFetchBookmarkById.ts
@@ -1,20 +1,26 @@
-import { useQuery, type UseQueryOptions } from "@tanstack/react-query";
+import { useQuery } from "@tanstack/react-query";
 
+import { type SingleListData } from "../../../types/apiTypes";
 import { BOOKMARKS_KEY } from "../../../utils/constants";
 import { fetchBookmarkById } from "../../supabaseCrudHelpers";
 
-type Bookmark = {
-	[key: string]: unknown;
-	id: string;
+type BookmarkResponse = {
+	data: SingleListData;
+};
+
+type UseFetchBookmarkByIdOptions = {
+	enabled?: boolean;
 };
 
 export const useFetchBookmarkById = (
 	id: string,
-	options?: UseQueryOptions<Bookmark>,
-) =>
-	useQuery({
+	options?: UseFetchBookmarkByIdOptions,
+) => {
+	const { enabled = true } = options ?? {};
+
+	return useQuery<BookmarkResponse>({
 		queryKey: [BOOKMARKS_KEY, id],
-		queryFn: async () => await (fetchBookmarkById(id) as Promise<Bookmark>),
-		enabled: Boolean(id),
-		...options,
+		queryFn: async () => (await fetchBookmarkById(id)) as BookmarkResponse,
+		enabled: enabled && Boolean(id),
 	});
+};
diff --git a/src/async/queryHooks/bookmarks/useFetchPaginatedBookmarks.ts b/src/async/queryHooks/bookmarks/useFetchPaginatedBookmarks.ts
index 5f1e8d9b..2ceb783e 100644
--- a/src/async/queryHooks/bookmarks/useFetchPaginatedBookmarks.ts
+++ b/src/async/queryHooks/bookmarks/useFetchPaginatedBookmarks.ts
@@ -13,11 +13,22 @@ import {
 	type SupabaseSessionType,
 } from "../../../types/apiTypes";
 import { type BookmarksSortByTypes } from "../../../types/componentStoreTypes";
-import { BOOKMARKS_KEY, PAGINATION_LIMIT } from "../../../utils/constants";
+import {
+	BOOKMARKS_KEY,
+	DISCOVER_URL,
+	PAGINATION_LIMIT,
+} from "../../../utils/constants";
 import { fetchBookmarksData } from "../../supabaseCrudHelpers";
 
+type UseFetchPaginatedBookmarksOptions = {
+	enabled?: boolean;
+};
+
 // fetches paginated bookmarks pages on user location like everything or categories etc...
-export default function useFetchPaginatedBookmarks() {
+export default function useFetchPaginatedBookmarks(
+	options: UseFetchPaginatedBookmarksOptions = {},
+) {
+	const { enabled = true } = options;
 	const session = useSupabaseSession((state) => state.session);
 
 	const isSortByLoading = useLoadersStore((state) => state.isSortByLoading);
@@ -46,6 +57,7 @@ export default function useFetchPaginatedBookmarks() {
 			),
 		initialPageParam: 0,
 		getNextPageParam: (_lastPage, pages) => pages.length * PAGINATION_LIMIT,
+		enabled: enabled && CATEGORY_ID !== DISCOVER_URL,
 	});
 
 	useEffect(() => {
diff --git a/src/async/queryHooks/bookmarks/useSearchBookmarks.ts b/src/async/queryHooks/bookmarks/useSearchBookmarks.ts
index 0c7fa44d..0e4814e2 100644
--- a/src/async/queryHooks/bookmarks/useSearchBookmarks.ts
+++ b/src/async/queryHooks/bookmarks/useSearchBookmarks.ts
@@ -21,8 +21,15 @@ import {
 } from "../../../utils/constants";
 import { searchBookmarks } from "../../supabaseCrudHelpers";
 
+type UseSearchBookmarksOptions = {
+	enabled?: boolean;
+};
+
 // searches bookmarks
-export default function useSearchBookmarks() {
+export default function useSearchBookmarks(
+	options: UseSearchBookmarksOptions = {},
+) {
+	const { enabled = true } = options;
 	const searchText = useMiscellaneousStore((state) => state.searchText);
 	const session = useSupabaseSession((state) => state.session);
 	const toggleIsSearchLoading = useLoadersStore(
@@ -52,20 +59,19 @@ export default function useSearchBookmarks() {
 
 	const { data, isLoading, fetchNextPage, hasNextPage, isFetchingNextPage } =
 		useInfiniteQuery({
-			// eslint-disable-next-line @tanstack/query/exhaustive-deps
 			queryKey: [
 				BOOKMARKS_KEY,
 				session?.user?.id,
 				CATEGORY_ID,
 				debouncedSearch,
 			] as const,
-			enabled: !isEmpty(searchText),
+			enabled: enabled && !isEmpty(debouncedSearch),
 			refetchOnWindowFocus: false,
 			initialPageParam: 0,
 			queryFn: async ({ pageParam: pageParameter }) => {
-				if (searchText) {
+				if (debouncedSearch) {
 					const result = await searchBookmarks(
-						searchText,
+						debouncedSearch,
 						CATEGORY_ID,
 						isSharedCategory,
 						pageParameter,
diff --git a/src/async/supabaseCrudHelpers/index.ts b/src/async/supabaseCrudHelpers/index.ts
index 242c82ad..ca2bc5ad 100644
--- a/src/async/supabaseCrudHelpers/index.ts
+++ b/src/async/supabaseCrudHelpers/index.ts
@@ -12,8 +12,6 @@ import isNull from "lodash/isNull";
 import {
 	type AddBookmarkMinDataPayloadTypes,
 	type AddBookmarkScreenshotPayloadTypes,
-	type AddTagToBookmarkApiPayload,
-	type AddUserTagsApiPayload,
 	type BookmarksCountTypes,
 	type BookmarksPaginatedDataTypes,
 	type BookmarkViewDataTypes,
@@ -28,7 +26,6 @@ import {
 	type RemoveUserProfilePicPayload,
 	type SingleListData,
 	type SupabaseSessionType,
-	type UpdateCategoryApiPayload,
 	type UpdateCategoryOrderApiPayload,
 	type UpdateSharedCategoriesUserAccessApiPayload,
 	type UpdateUsernameApiPayload,
@@ -44,12 +41,9 @@ import { type BookmarksSortByTypes } from "../../types/componentStoreTypes";
 import { type CategoryIdUrlTypes } from "../../types/componentTypes";
 import {
 	ADD_BOOKMARK_MIN_DATA,
-	ADD_TAG_TO_BOOKMARK_API,
 	ADD_URL_SCREENSHOT_API,
 	CHECK_API_KEY_API,
 	CLEAR_BOOKMARK_TRASH_API,
-	CREATE_USER_CATEGORIES_API,
-	CREATE_USER_TAGS_API,
 	DELETE_API_KEY_API,
 	DELETE_BOOKMARK_DATA_API,
 	DELETE_SHARED_CATEGORIES_USER_API,
@@ -72,13 +66,11 @@ import {
 	NO_BOOKMARKS_ID_ERROR,
 	PAGINATION_LIMIT,
 	REMOVE_PROFILE_PIC_API,
-	REMOVE_TAG_FROM_BOOKMARK_API,
 	SAVE_API_KEY_API,
 	SEARCH_BOOKMARKS,
 	SEND_COLLABORATION_EMAIL_API,
 	UPDATE_CATEGORY_ORDER_API,
 	UPDATE_SHARED_CATEGORY_USER_ROLE_API,
-	UPDATE_USER_CATEGORIES_API,
 	UPDATE_USER_PROFILE_API,
 	UPDATE_USERNAME_API,
 	UPLOAD_FILE_API,
@@ -406,48 +398,6 @@ export const fetchUserTags = async (): Promise<{
 	}
 };
 
-export const addUserTags = async ({ tagsData }: AddUserTagsApiPayload) => {
-	try {
-		const response = await axios.post<{ data: UserTagsData }>(
-			`${NEXT_API_URL}${CREATE_USER_TAGS_API}`,
-			{ name: tagsData?.name },
-		);
-		return response?.data;
-	} catch (error) {
-		return error;
-	}
-};
-
-export const addTagToBookmark = async ({
-	selectedData,
-}: AddTagToBookmarkApiPayload) => {
-	try {
-		const response = await axios.post<{ data: SingleListData }>(
-			`${NEXT_API_URL}${ADD_TAG_TO_BOOKMARK_API}`,
-			{ data: selectedData },
-		);
-		return response?.data;
-	} catch (error) {
-		return error;
-	}
-};
-
-export const removeTagFromBookmark = async ({
-	selectedData,
-}: {
-	selectedData: { bookmark_id: number; tag_id: number };
-}) => {
-	try {
-		const response = await axios.post<{ data: UserTagsData; error: Error }>(
-			`${NEXT_API_URL}${REMOVE_TAG_FROM_BOOKMARK_API}`,
-			{ tag_id: selectedData?.tag_id, bookmark_id: selectedData?.bookmark_id },
-		);
-		return response?.data;
-	} catch (error) {
-		return error;
-	}
-};
-
 export const fetchBookmarksViews = async ({
 	category_id,
 }: {
@@ -503,27 +453,6 @@ export const fetchCategoriesData = async (): Promise<{
 	}
 };
 
-export const addUserCategory = async ({
-	name,
-	category_order,
-}: {
-	category_order: number[];
-	name: string;
-}) => {
-	try {
-		const response = await axios.post<{
-			data: CategoriesData[] | null;
-			error: Error;
-		}>(`${NEXT_API_URL}${CREATE_USER_CATEGORIES_API}`, {
-			name,
-			category_order,
-		});
-		return response?.data;
-	} catch (error) {
-		return error;
-	}
-};
-
 export const deleteUserCategory = async ({
 	category_id,
 	category_order,
@@ -542,22 +471,6 @@ export const deleteUserCategory = async ({
 	}
 };
 
-export const updateCategory = async ({
-	category_id,
-	updateData,
-}: UpdateCategoryApiPayload) => {
-	try {
-		const response = await axios.post(
-			`${NEXT_API_URL}${UPDATE_USER_CATEGORIES_API}`,
-			{ category_id, updateData },
-		);
-
-		return response;
-	} catch (error) {
-		return error;
-	}
-};
-
 export const updateCategoryOrder = async ({
 	order,
 }: UpdateCategoryOrderApiPayload) => {
diff --git a/src/components/customDropdowns.tsx/bookmarksSortDropdown.tsx b/src/components/customDropdowns.tsx/bookmarksSortDropdown.tsx
index 3532293e..92baaeec 100644
--- a/src/components/customDropdowns.tsx/bookmarksSortDropdown.tsx
+++ b/src/components/customDropdowns.tsx/bookmarksSortDropdown.tsx
@@ -4,7 +4,7 @@ import useGetSortBy from "../../hooks/useGetSortBy";
 import AlphabeticalIcon from "../../icons/sortByIcons/alphabeticalIcon";
 import ClockRewindIcon from "../../icons/sortByIcons/clockRewindIcon";
 import DateIcon from "../../icons/sortByIcons/dateIcon";
-import TickIcon from "../../icons/tickIcon";
+import { TickIcon } from "../../icons/tickIcon";
 import {
 	type BookmarksSortByTypes,
 	type BookmarkViewCategories,
@@ -94,7 +94,7 @@ const BookmarksSortDropdown = (props: BookmarksSortDropdownTypes) => {
 				{find(sortOptions, (item) => item?.label === value)?.label}
 				{value === currentValue?.label ? (
 					<figure className="h-3 w-3">
-						<TickIcon color="var(--color-gray-800)" />
+						<TickIcon className="text-gray-800" />
 					</figure>
 				) : null}
 			</div>
diff --git a/src/components/customDropdowns.tsx/categoryIconsDropdown.tsx b/src/components/customDropdowns.tsx/categoryIconsDropdown.tsx
index e8c17d0d..38b21ff1 100644
--- a/src/components/customDropdowns.tsx/categoryIconsDropdown.tsx
+++ b/src/components/customDropdowns.tsx/categoryIconsDropdown.tsx
@@ -8,9 +8,8 @@ import {
 } from "ariakit/combobox";
 import { Menu, MenuButton, useMenuState } from "ariakit/menu";
 
-import useUpdateCategoryOptimisticMutation from "../../async/mutationHooks/category/useUpdateCategoryOptimisticMutation";
+import { useUpdateCategoryOptimisticMutation } from "../../async/mutationHooks/category/use-update-category-optimistic-mutation";
 import SearchIconSmallGray from "../../icons/searchIconSmallGray";
-import { mutationApiCall } from "../../utils/apiHelpers";
 import { iconOptions } from "../../utils/commonData";
 import { colorPickerColors } from "../../utils/constants";
 import Button from "../atoms/button";
@@ -41,23 +40,19 @@ const CategoryIconsDropdown = (props: CategoryIconsDropdownTypes) => {
 	const iconsList = iconOptions;
 
 	const handleIconColorChange = (iconColor: string) => {
-		void mutationApiCall(
-			updateCategoryOptimisticMutation.mutateAsync({
-				category_id: iconId,
-				updateData: {
-					icon_color: iconColor,
-				},
-			}),
-		);
+		updateCategoryOptimisticMutation.mutate({
+			category_id: iconId,
+			updateData: {
+				icon_color: iconColor,
+			},
+		});
 	};
 
 	const handleIconSelect = (icon: string) => {
-		void mutationApiCall(
-			updateCategoryOptimisticMutation.mutateAsync({
-				category_id: iconId,
-				updateData: { icon },
-			}),
-		);
+		updateCategoryOptimisticMutation.mutate({
+			category_id: iconId,
+			updateData: { icon },
+		});
 	};
 
 	// constants
diff --git a/src/components/guest/email-client-components.tsx b/src/components/guest/email-client-components.tsx
index 500a5202..21962889 100644
--- a/src/components/guest/email-client-components.tsx
+++ b/src/components/guest/email-client-components.tsx
@@ -120,12 +120,13 @@ function EmailField({ ref, value, onChange, autoFocus }: EmailFieldProps) {
 }
 
 function EmailFieldWithQueryState() {
-	const [email, setEmail] = useQueryState("email", { defaultValue: "" });
+	const [urlEmail] = useQueryState("email", { defaultValue: "" });
+	const [localEmail, setLocalEmail] = React.useState(urlEmail);
 	const inputRef = React.useRef<HTMLInputElement>(null);
 
 	// Select all text when email value is pre-filled for easy clearing
 	useIsomorphicLayoutEffect(() => {
-		if (inputRef.current && email) {
+		if (inputRef.current && urlEmail) {
 			inputRef.current.select();
 		}
 	}, []);
@@ -133,8 +134,8 @@ function EmailFieldWithQueryState() {
 	return (
 		<EmailField
 			ref={inputRef}
-			value={email}
-			onChange={(event) => setEmail(event.target.value)}
+			value={localEmail}
+			onChange={(event) => setLocalEmail(event.target.value)}
 			autoFocus
 		/>
 	);
diff --git a/src/components/lightbox/LightBox.tsx b/src/components/lightbox/LightBox.tsx
index e2aa646c..2d8b1ced 100644
--- a/src/components/lightbox/LightBox.tsx
+++ b/src/components/lightbox/LightBox.tsx
@@ -81,7 +81,7 @@ export const CustomLightBox = ({
 		}
 	}, [setLightboxShowSidepane]);
 
-	// Transform bookmarks into slides using custom hook
+	// Transform bookmarks into slides using custom hook (with embedded bookmark data)
 	const slides = useLightboxSlides(bookmarks);
 
 	// Handle navigation, query invalidation and URL updates using custom hook
@@ -225,6 +225,8 @@ export const CustomLightBox = ({
 					? "calc(100% - min(max(320px, 20%), 400px))"
 					: "100%",
 				animation: "custom-fade-scale-in 0.25s ease-in-out",
+				// Prevent browser navigation on swipe gestures
+				overscrollBehavior: "none" as const,
 			},
 			slide: {
 				height: "100%",
diff --git a/src/components/lightbox/LightBoxPlugin.tsx b/src/components/lightbox/LightBoxPlugin.tsx
index fa2dad93..97099d66 100644
--- a/src/components/lightbox/LightBoxPlugin.tsx
+++ b/src/components/lightbox/LightBoxPlugin.tsx
@@ -11,8 +11,6 @@
 import { useEffect, useRef, useState } from "react";
 import Image from "next/image";
 import { useRouter } from "next/router";
-import { type PostgrestError } from "@supabase/supabase-js";
-import { useQueryClient } from "@tanstack/react-query";
 import { format } from "date-fns";
 import { AnimatePresence, motion } from "motion/react";
 import {
@@ -22,26 +20,15 @@ import {
 } from "yet-another-react-lightbox";
 
 import { useFetchBookmarkById } from "../../async/queryHooks/bookmarks/useFetchBookmarkById";
-import useGetCurrentCategoryId from "../../hooks/useGetCurrentCategoryId";
-import useGetSortBy from "../../hooks/useGetSortBy";
+import { usePageContext } from "../../hooks/use-page-context";
 import { GeminiAiIcon } from "../../icons/geminiAiIcon";
 import ImageIcon from "../../icons/imageIcon";
-import {
-	useMiscellaneousStore,
-	useSupabaseSession,
-} from "../../store/componentStore";
-import {
-	type CategoriesData,
-	type SingleListData,
-	type UserTagsData,
-} from "../../types/apiTypes";
-import { BOOKMARKS_KEY, CATEGORIES_KEY } from "../../utils/constants";
-import { searchSlugKey } from "../../utils/helpers";
+import { useMiscellaneousStore } from "../../store/componentStore";
 import { Icon } from "../atoms/icon";
 import { Spinner } from "../spinner";
 
 import { CategoryMultiSelect } from "./category-multi-select";
-import { highlightSearch } from "./LightboxUtils";
+import { highlightSearch, type CustomSlide } from "./LightboxUtils";
 
 /**
  * Formats a date string into a more readable format (e.g., "Jan 1, 2023")
@@ -62,7 +49,7 @@ const formatDate = (dateString: string) => {
  */
 
 const MyComponent = () => {
-	const { currentIndex } = useLightboxState();
+	const { currentIndex, slides } = useLightboxState();
 	const [isInitialMount, setIsInitialMount] = useState(true);
 
 	useEffect(() => {
@@ -75,56 +62,37 @@ const MyComponent = () => {
 	const descriptionRef = useRef<HTMLParagraphElement>(null);
 	const aiSummaryScrollRef = useRef<HTMLDivElement>(null);
 
-	const queryClient = useQueryClient();
-	const session = useSupabaseSession((state) => state.session);
-	const { category_id: CATEGORY_ID } = useGetCurrentCategoryId();
+	const router = useRouter();
+
+	const { isPublicPage, isDiscoverPage } = usePageContext();
 
-	const categoryData = queryClient.getQueryData([
-		CATEGORIES_KEY,
-		session?.user?.id,
-	]) as {
-		data: CategoriesData[];
-		error: PostgrestError;
-	};
 	const searchText = useMiscellaneousStore((state) => state.searchText);
 	const trimmedSearchText = searchText?.trim() ?? "";
-	const { sortBy } = useGetSortBy();
 
-	// if there is text in searchbar we get the cache of searched data else we get from everything
-	const previousData = queryClient.getQueryData([
-		BOOKMARKS_KEY,
-		session?.user?.id,
-		searchText ? searchSlugKey(categoryData) : CATEGORY_ID,
-		searchText ? searchText : sortBy,
-	]) as {
-		data: SingleListData[];
-		pages: Array<{ data: SingleListData[] }>;
-	};
-	const router = useRouter();
+	// Get bookmark from slide data (primary source)
+	const currentSlide = slides[currentIndex] as CustomSlide | undefined;
+	let currentBookmark = currentSlide?.data?.bookmark;
 
+	// Fallback: fetch by ID only if bookmark not in slide data (direct URL access)
 	const { id } = router.query;
-	const shouldFetch = !previousData && Boolean(id);
+	const shouldFetch =
+		!currentBookmark && typeof id === "string" && id.length > 0;
 
-	// @ts-expect-error - props passed to useQuery - false-positive
 	const { data: bookmark } = useFetchBookmarkById(id as string, {
 		enabled: shouldFetch,
 	});
-	let currentBookmark;
-	// handling the case where user opens a preview link directly
-	if (!previousData) {
-		// @ts-expect-error bookmark is not undefined
-		currentBookmark = bookmark?.data?.[0];
-	} else {
-		currentBookmark = previousData?.pages?.flatMap(
-			(page) => page?.data ?? [],
-		)?.[currentIndex];
+
+	// Use fetched bookmark if slide data is unavailable
+	if (!currentBookmark && bookmark?.data) {
+		currentBookmark = bookmark.data;
 	}
 
 	const [hasAIOverflowContent, setHasAIOverflowContent] = useState(false);
 	const expandableRef = useRef<HTMLDivElement>(null);
 
 	const metaData = currentBookmark?.meta_data;
-	const collapsedOffset = currentBookmark?.addedTags?.length > 0 ? 145 : 110;
+	const collapsedOffset =
+		(currentBookmark?.addedTags?.length ?? 0) > 0 ? 145 : 110;
 	const lightboxShowSidepane = useMiscellaneousStore(
 		(state) => state.lightboxShowSidepane,
 	);
@@ -274,13 +242,14 @@ const MyComponent = () => {
 								)}
 							</div>
 						)}
-						<CategoryMultiSelect
-							bookmarkId={currentBookmark?.id}
-							shouldFetch={shouldFetch}
-						/>
+						{!isDiscoverPage && !isPublicPage && (
+							<CategoryMultiSelect
+								bookmarkId={currentBookmark?.id}
+								shouldFetch={shouldFetch}
+							/>
+						)}
 					</div>
 					{(currentBookmark?.addedTags?.length > 0 ||
-						metaData?.image_caption ||
 						metaData?.img_caption ||
 						metaData?.ocr) && (
 						<motion.div
@@ -302,20 +271,20 @@ const MyComponent = () => {
 							{currentBookmark?.addedTags?.length > 0 && (
 								<div className="px-5 pb-[19px]">
 									<div className="flex flex-wrap gap-[6px]">
-										{currentBookmark?.addedTags?.map((tag: UserTagsData) => (
-											<span
-												className="align-middle text-13 leading-[115%] font-450 tracking-[0.01em] text-gray-600"
-												key={tag?.id}
-											>
-												{highlightSearch("#" + tag?.name, trimmedSearchText)}
-											</span>
-										))}
+										{currentBookmark?.addedTags?.map(
+											(tag: { id: number; name: string }) => (
+												<span
+													className="align-middle text-13 leading-[115%] font-450 tracking-[0.01em] text-gray-600"
+													key={tag?.id}
+												>
+													{highlightSearch("#" + tag?.name, trimmedSearchText)}
+												</span>
+											),
+										)}
 									</div>
 								</div>
 							)}
-							{(metaData?.img_caption ||
-								metaData?.image_caption ||
-								metaData?.ocr) && (
+							{(metaData?.img_caption || metaData?.ocr) && (
 								<motion.div
 									className={`relative px-5 py-3 text-sm ${
 										hasAIOverflowContent ? "cursor-pointer" : ""
@@ -348,11 +317,10 @@ const MyComponent = () => {
 									>
 										<p className="text-13 leading-[138%] tracking-[0.01em] text-gray-500">
 											{highlightSearch(
-												metaData?.img_caption || metaData?.image_caption || "",
+												metaData?.img_caption || "",
 												trimmedSearchText,
 											)}
-											{(metaData?.img_caption || metaData?.image_caption) &&
-												metaData?.ocr && <br />}
+											{metaData?.img_caption && metaData?.ocr && <br />}
 											{highlightSearch(metaData?.ocr ?? "", trimmedSearchText)}
 										</p>
 									</div>
diff --git a/src/components/lightbox/LightboxRenderers.tsx b/src/components/lightbox/LightboxRenderers.tsx
index 390a39a2..726ef501 100644
--- a/src/components/lightbox/LightboxRenderers.tsx
+++ b/src/components/lightbox/LightboxRenderers.tsx
@@ -70,7 +70,8 @@ export const VideoSlide = ({ bookmark, isActive }: SlideProps) => (
 			<VideoPlayer
 				isActive={isActive ?? false}
 				src={
-					bookmark?.type === tweetType && bookmark?.meta_data?.video_url
+					(bookmark?.type === tweetType || bookmark?.type === "instagram") &&
+					bookmark?.meta_data?.video_url
 						? bookmark?.meta_data?.video_url
 						: (bookmark?.url ?? "")
 				}
diff --git a/src/components/lightbox/LightboxUtils.tsx b/src/components/lightbox/LightboxUtils.tsx
index 244506bf..f043f34f 100644
--- a/src/components/lightbox/LightboxUtils.tsx
+++ b/src/components/lightbox/LightboxUtils.tsx
@@ -1,5 +1,6 @@
 import { type Slide as BaseSlide } from "yet-another-react-lightbox";
 
+import { type SingleListData } from "../../types/apiTypes";
 import {
 	ESCAPE_REGEXP_PATTERN,
 	YOUTU_BE,
@@ -51,8 +52,20 @@ export const isYouTubeVideo = (
 	}
 };
 
+/**
+ * Custom slide type that extends the base Slide with bookmark data
+ * This allows the plugin to access bookmark metadata directly from slides
+ * without needing global state or additional queries
+ */
 export type CustomSlide = BaseSlide & {
 	data?: {
+		/**
+		 * The full bookmark object for this slide
+		 */
+		bookmark?: SingleListData;
+		/**
+		 * Legacy type field (kept for backwards compatibility)
+		 */
 		type?: string;
 	};
 	placeholder?: string;
diff --git a/src/components/lightbox/category-multi-select.tsx b/src/components/lightbox/category-multi-select.tsx
index a5aa6ed9..36095b04 100644
--- a/src/components/lightbox/category-multi-select.tsx
+++ b/src/components/lightbox/category-multi-select.tsx
@@ -90,13 +90,13 @@ export const CategoryMultiSelect = ({
 									<Combobox.List>
 										{(item: CategoriesData) => (
 											<Combobox.Item key={item.id} value={item}>
-												<Combobox.ItemIndicator />
 												<CollectionIcon
 													bookmarkCategoryData={item}
 													iconSize="10"
 													size="16"
 												/>
 												<span className="truncate">{item.category_name}</span>
+												<Combobox.ItemIndicator />
 											</Combobox.Item>
 										)}
 									</Combobox.List>
diff --git a/src/components/lightbox/hooks/useLightboxLogic.ts b/src/components/lightbox/hooks/useLightboxLogic.ts
index ac2329a3..19d9c902 100644
--- a/src/components/lightbox/hooks/useLightboxLogic.ts
+++ b/src/components/lightbox/hooks/useLightboxLogic.ts
@@ -2,6 +2,7 @@ import { useCallback, useEffect, useMemo, useRef } from "react";
 import { useRouter } from "next/router";
 import { useQueryClient } from "@tanstack/react-query";
 
+import { usePageContext } from "../../../hooks/use-page-context";
 import {
 	useMiscellaneousStore,
 	useSupabaseSession,
@@ -11,21 +12,27 @@ import { type SingleListData } from "../../../types/apiTypes";
 import {
 	BOOKMARKS_COUNT_KEY,
 	BOOKMARKS_KEY,
-	CATEGORY_ID_PATHNAME,
 	IMAGE_TYPE_PREFIX,
 	PDF_MIME_TYPE,
 	PDF_TYPE,
-	PREVIEW_PATH,
 	tweetType,
 	VIDEO_TYPE_PREFIX,
 } from "../../../utils/constants";
-import { getCategorySlugFromRouter } from "../../../utils/url";
+import {
+	getCategorySlugFromRouter,
+	getPublicPageInfo,
+} from "../../../utils/url";
+import {
+	buildAuthenticatedPreviewUrl,
+	buildPublicPreviewUrl,
+} from "../../../utils/url-builders";
 import { isYouTubeVideo, type CustomSlide } from "../LightboxUtils";
 
 import { handleClientError } from "@/utils/error-utils/client";
 
 /**
  * Hook to transform bookmarks into lightbox slides
+ * Embeds full bookmark data in each slide for plugin access
  */
 export const useLightboxSlides = (bookmarks: SingleListData[] | undefined) => {
 	const iframeEnabled = useIframeStore((state) => state.iframeEnabled);
@@ -52,7 +59,15 @@ export const useLightboxSlides = (bookmarks: SingleListData[] | undefined) => {
 					: isImage
 						? IMAGE_TYPE_PREFIX
 						: undefined,
-
+				// Embed bookmark data in slide for plugin access
+				data: {
+					bookmark,
+					type: isVideo
+						? VIDEO_TYPE_PREFIX
+						: isImage
+							? IMAGE_TYPE_PREFIX
+							: undefined,
+				},
 				// Only include dimensions if not a PDF or not a YouTube video
 				...(bookmark?.meta_data?.mediaType !== PDF_MIME_TYPE &&
 					!bookmark?.type?.includes(PDF_TYPE) &&
@@ -106,6 +121,8 @@ export const useLightboxNavigation = ({
 	);
 	const router = useRouter();
 
+	const { isPublicPage, isDiscoverPage } = usePageContext();
+
 	/**
 	 * Invalidate queries for a given bookmark index.
 	 * Uses broad invalidation because we can't track which specific categories
@@ -156,25 +173,36 @@ export const useLightboxNavigation = ({
 			setActiveIndex(index);
 		}
 
-		// Invalidate queries when slide changes
-		if (index !== lastInvalidatedIndex.current && isCollectionChanged) {
+		// Invalidate queries when slide changes (only for authenticated pages)
+		if (
+			index !== lastInvalidatedIndex.current &&
+			isCollectionChanged &&
+			!isPublicPage &&
+			!isDiscoverPage
+		) {
 			void invalidateQueriesForIndex(index);
 		}
 
-		// Update browser URL
-		void router?.push(
-			{
-				pathname: `${CATEGORY_ID_PATHNAME}`,
-				query: {
-					category_id: getCategorySlugFromRouter(router),
-					id: bookmarks?.[index]?.id,
-				},
-			},
-			`${getCategorySlugFromRouter(router)}${PREVIEW_PATH}/${
-				bookmarks?.[index]?.id
-			}`,
-			{ shallow: true },
-		);
+		// Update browser URL for both authenticated and public pages
+		if (isPublicPage && !isDiscoverPage) {
+			const publicInfo = getPublicPageInfo(router);
+			if (publicInfo && bookmarks?.[index]?.id) {
+				const { pathname, query, as } = buildPublicPreviewUrl({
+					publicInfo,
+					bookmarkId: bookmarks[index].id,
+				});
+				void router?.push({ pathname, query }, as, { shallow: true });
+			}
+		} else {
+			const categorySlug = getCategorySlugFromRouter(router);
+			if (categorySlug) {
+				const { pathname, query, as } = buildAuthenticatedPreviewUrl({
+					categorySlug,
+					bookmarkId: bookmarks?.[index]?.id,
+				});
+				void router?.push({ pathname, query }, as, { shallow: true });
+			}
+		}
 	};
 
 	/**
diff --git a/src/components/lightbox/hooks/useLightboxPrefetch.ts b/src/components/lightbox/hooks/useLightboxPrefetch.ts
index a85a0f80..d9ef8b86 100644
--- a/src/components/lightbox/hooks/useLightboxPrefetch.ts
+++ b/src/components/lightbox/hooks/useLightboxPrefetch.ts
@@ -1,11 +1,14 @@
 import { useEffect } from "react";
+import { useRouter } from "next/router";
 import { isEmpty } from "lodash";
 
+import { useFetchDiscoverBookmarks } from "@/async/queryHooks/bookmarks/use-fetch-discover-bookmarks";
 import useFetchPaginatedBookmarks from "@/async/queryHooks/bookmarks/useFetchPaginatedBookmarks";
 import useSearchBookmarks from "@/async/queryHooks/bookmarks/useSearchBookmarks";
 import { useMiscellaneousStore } from "@/store/componentStore";
-import { PAGINATION_LIMIT } from "@/utils/constants";
+import { DISCOVER_URL, PAGINATION_LIMIT } from "@/utils/constants";
 import { handleClientError } from "@/utils/error-utils/client";
+import { getCategorySlugFromRouter } from "@/utils/url";
 
 type UseLightboxPrefetchParams = {
 	activeIndex: number;
@@ -24,9 +27,18 @@ export function useLightboxPrefetch({
 	bookmarksLength,
 	pages,
 }: UseLightboxPrefetchParams) {
+	const router = useRouter();
+	const categorySlug = getCategorySlugFromRouter(router);
+	const isDiscoverPage = categorySlug === DISCOVER_URL;
+
 	const { fetchNextPage: fetchNextBookmarkPage } = useFetchPaginatedBookmarks();
 	const { fetchNextPage: fetchNextSearchPage, hasNextPage: searchHasNextPage } =
 		useSearchBookmarks();
+	const {
+		fetchNextPage: fetchNextDiscoverPage,
+		hasNextPage: discoverHasNextPage,
+	} = useFetchDiscoverBookmarks();
+
 	// Determine if we're currently searching
 	const searchText = useMiscellaneousStore((state) => state.searchText);
 
@@ -46,7 +58,13 @@ export function useLightboxPrefetch({
 		if (shouldFetchMore && hasMoreData) {
 			const prefetch = async () => {
 				try {
-					if (isSearching && searchHasNextPage) {
+					if (isDiscoverPage) {
+						if (isSearching && searchHasNextPage) {
+							await fetchNextSearchPage();
+						} else if (!isSearching && discoverHasNextPage) {
+							await fetchNextDiscoverPage();
+						}
+					} else if (isSearching && searchHasNextPage) {
 						await fetchNextSearchPage();
 					} else if (!isSearching) {
 						await fetchNextBookmarkPage();
@@ -64,9 +82,12 @@ export function useLightboxPrefetch({
 		open,
 		pages,
 		isSearching,
+		isDiscoverPage,
 		searchHasNextPage,
+		discoverHasNextPage,
 		fetchNextSearchPage,
 		fetchNextBookmarkPage,
+		fetchNextDiscoverPage,
 		shouldFetchMore,
 		hasMoreData,
 	]);
diff --git a/src/components/lightbox/previewLightBox.tsx b/src/components/lightbox/previewLightBox.tsx
index 1c4057c3..4e2f2d8e 100644
--- a/src/components/lightbox/previewLightBox.tsx
+++ b/src/components/lightbox/previewLightBox.tsx
@@ -4,6 +4,7 @@ import { type PostgrestError } from "@supabase/supabase-js";
 import { useQueryClient } from "@tanstack/react-query";
 import { type DraggableItemProps } from "react-aria";
 
+import { usePageContext } from "../../hooks/use-page-context";
 import useDebounce from "../../hooks/useDebounce";
 import useGetCurrentCategoryId from "../../hooks/useGetCurrentCategoryId";
 import useGetSortBy from "../../hooks/useGetSortBy";
@@ -15,11 +16,15 @@ import { type CategoriesData, type SingleListData } from "../../types/apiTypes";
 import {
 	BOOKMARKS_KEY,
 	CATEGORIES_KEY,
-	CATEGORY_ID_PATHNAME,
+	DISCOVER_URL,
 	EVERYTHING_URL,
 } from "../../utils/constants";
 import { searchSlugKey } from "../../utils/helpers";
-import { getCategorySlugFromRouter } from "../../utils/url";
+import { getCategorySlugFromRouter, getPublicPageInfo } from "../../utils/url";
+import {
+	buildAuthenticatedCategoryUrl,
+	buildPublicCategoryUrl,
+} from "../../utils/url-builders";
 
 import { useLightboxPrefetch } from "./hooks/useLightboxPrefetch";
 import { CustomLightBox } from "./LightBox";
@@ -28,52 +33,81 @@ type PreviewLightBoxProps = {
 	id: DraggableItemProps["key"] | null;
 	open: boolean;
 	setOpen: (value: boolean) => void;
+	bookmarks?: SingleListData[];
 };
 
 export const PreviewLightBox = ({
 	id,
 	open,
 	setOpen,
+	bookmarks: bookmarksProp,
 }: PreviewLightBoxProps) => {
 	const router = useRouter();
 	const queryClient = useQueryClient();
 	const session = useSupabaseSession((state) => state.session);
 	const { category_id: CATEGORY_ID } = useGetCurrentCategoryId();
-	const categoryData = queryClient.getQueryData([
+	const categoryDataRaw = queryClient.getQueryData([
 		CATEGORIES_KEY,
 		session?.user?.id,
-	]) as {
-		data: CategoriesData[];
-		error: PostgrestError;
-	};
+	]);
+	const categoryData =
+		categoryDataRaw &&
+		typeof categoryDataRaw === "object" &&
+		"data" in categoryDataRaw &&
+		"error" in categoryDataRaw
+			? (categoryDataRaw as {
+					data: CategoriesData[];
+					error: PostgrestError;
+				})
+			: undefined;
 	const [activeIndex, setActiveIndex] = useState(-1);
 	const { sortBy } = useGetSortBy();
 	const searchText = useMiscellaneousStore((state) => state.searchText);
 	const debouncedSearch = useDebounce(searchText, 500);
+
+	const { isPublicPage, isDiscoverPage } = usePageContext();
+
+	// Determine the correct query key based on whether we're on discover page
+	const queryKey = isDiscoverPage
+		? searchText
+			? [BOOKMARKS_KEY, session?.user?.id, DISCOVER_URL, debouncedSearch]
+			: [BOOKMARKS_KEY, DISCOVER_URL]
+		: [
+				BOOKMARKS_KEY,
+				session?.user?.id,
+				searchText && categoryData ? searchSlugKey(categoryData) : CATEGORY_ID,
+				searchText ? debouncedSearch : sortBy,
+			];
+
 	// if there is text in searchbar we get the cache of searched data else we get from everything
-	const previousData = queryClient.getQueryData([
-		BOOKMARKS_KEY,
-		session?.user?.id,
-		searchText ? searchSlugKey(categoryData) : CATEGORY_ID,
-		searchText ? debouncedSearch : sortBy,
-	]) as {
-		data: SingleListData[];
-		pages: Array<{ data: SingleListData[] }>;
-	};
-	// Get and transform bookmarks from query cache
+	// Skip query cache lookup for public pages since bookmarks are provided via props
+	const previousData = isPublicPage
+		? undefined
+		: (queryClient.getQueryData(queryKey) as {
+				data: SingleListData[];
+				pages: Array<{ data: SingleListData[] }>;
+			});
+	// Get and transform bookmarks from query cache or use provided bookmarks prop
 	const bookmarks = useMemo(() => {
+		// If bookmarks are provided as prop (e.g., for public pages), use them
+		if (bookmarksProp) {
+			return bookmarksProp;
+		}
+
+		// Otherwise, get from query cache (for logged-in users)
 		const rawBookmarks =
 			previousData?.pages?.flatMap((page) => page?.data ?? []) ?? [];
 		// Transform SingleListData to match the expected type in CustomLightBox
 		return rawBookmarks;
-	}, [previousData?.pages]);
+	}, [bookmarksProp, previousData?.pages]);
 
 	// Prefetch next page when approaching the end of current data
+	// For public pages, pass undefined pages to skip prefetching since all data is provided via props
 	useLightboxPrefetch({
-		open,
+		open: open && !isPublicPage,
 		activeIndex,
 		bookmarksLength: bookmarks?.length ?? 0,
-		pages: previousData?.pages,
+		pages: isPublicPage ? undefined : previousData?.pages,
 	});
 
 	// Only update activeIndex when the lightbox is being opened
@@ -96,22 +130,24 @@ export const PreviewLightBox = ({
 	const handleClose = useCallback(() => {
 		setOpen(false);
 
-		// Update URL without page reload
-		// Clean up path by removing leading slashes
-		void router.push(
-			{
-				pathname: `${CATEGORY_ID_PATHNAME}`,
-				query: {
-					category_id: router?.query?.category_id ?? EVERYTHING_URL,
-				},
-			},
-			getCategorySlugFromRouter(router) ?? EVERYTHING_URL,
-			{ shallow: true },
-		);
+		// Update URL to remove preview segment for both authenticated and public pages
+		if (isPublicPage && !isDiscoverPage) {
+			const publicInfo = getPublicPageInfo(router);
+			if (publicInfo) {
+				const { pathname, query, as } = buildPublicCategoryUrl(publicInfo);
+				void router.push({ pathname, query }, as, { shallow: true });
+			}
+		} else {
+			// Update URL without page reload for logged-in users
+			const categorySlug = getCategorySlugFromRouter(router) ?? EVERYTHING_URL;
+			const { pathname, query, as } =
+				buildAuthenticatedCategoryUrl(categorySlug);
+			void router.push({ pathname, query }, as, { shallow: true });
+		}
 
 		// Reset state after animation
 		setActiveIndex(-1);
-	}, [setOpen, router]);
+	}, [setOpen, router, isPublicPage, isDiscoverPage]);
 
 	// Only render CustomLightBox when activeIndex is valid
 	if (!open || activeIndex === -1) {
diff --git a/src/components/radioGroup.tsx b/src/components/radioGroup.tsx
index 54064aca..edefa294 100644
--- a/src/components/radioGroup.tsx
+++ b/src/components/radioGroup.tsx
@@ -6,7 +6,7 @@ import {
 } from "ariakit/radio";
 import classNames from "classnames";
 
-import TickIcon from "../icons/tickIcon";
+import { TickIcon } from "../icons/tickIcon";
 import { type ChildrenTypes } from "../types/componentTypes";
 
 type RadioGroupProps = {
@@ -67,11 +67,7 @@ const RadioGroup = (props: RadioGroupProps) => {
 							/>
 							{item?.label}
 						</div>
-						{isRadioSelected && (
-							<figure className="text-gray-800">
-								<TickIcon color="currentColor" />
-							</figure>
-						)}
+						{isRadioSelected && <TickIcon className="text-gray-800" />}
 					</label>
 				);
 			})}
diff --git a/src/components/ui/recollect/combobox/index.tsx b/src/components/ui/recollect/combobox/index.tsx
index f7261e04..c69f091f 100644
--- a/src/components/ui/recollect/combobox/index.tsx
+++ b/src/components/ui/recollect/combobox/index.tsx
@@ -8,8 +8,8 @@ import {
 	useComboboxContext,
 	type ComboboxContextValue,
 } from "./context";
-import { CheckIcon } from "@/icons/check-icon";
 import { LightboxCloseIcon } from "@/icons/lightbox-close-icon";
+import { TickIcon } from "@/icons/tickIcon";
 import { cn } from "@/utils/tailwind-merge";
 
 const CREATE_NEW_MARKER = Symbol("create-new");
@@ -374,12 +374,12 @@ function ItemIndicator({
 			keepMounted
 			data-slot="combobox-item-indicator"
 			className={cn(
-				"flex size-4 shrink-0 items-center justify-center rounded-[5px] bg-plain-reverse text-plain-reverse data-selected:text-plain",
+				"ml-auto flex size-4 shrink-0 items-center justify-center text-plain opacity-0 data-selected:text-plain data-selected:opacity-100",
 				className,
 			)}
 			{...props}
 		>
-			{children ?? <CheckIcon className="size-2.5" />}
+			{children ?? <TickIcon className="text-gray-800" />}
 		</ComboboxPrimitive.ItemIndicator>
 	);
 }
diff --git a/src/hooks/use-category-multi-select.ts b/src/hooks/use-category-multi-select.ts
index e2058ca5..1697f493 100644
--- a/src/hooks/use-category-multi-select.ts
+++ b/src/hooks/use-category-multi-select.ts
@@ -1,7 +1,7 @@
 import { useMemo } from "react";
 
-import { useAddCategoryToBookmarkMutation } from "@/async/mutationHooks/category/use-add-category-to-bookmark-mutation";
-import { useRemoveCategoryFromBookmarkMutation } from "@/async/mutationHooks/category/use-remove-category-from-bookmark-mutation";
+import { useAddCategoryToBookmarkOptimisticMutation } from "@/async/mutationHooks/category/use-add-category-to-bookmark-optimistic-mutation";
+import { useRemoveCategoryFromBookmarkOptimisticMutation } from "@/async/mutationHooks/category/use-remove-category-from-bookmark-optimistic-mutation";
 import useFetchCategories from "@/async/queryHooks/category/useFetchCategories";
 import { useBookmarkCategories } from "@/hooks/use-bookmark-categories";
 import { type CategoriesData } from "@/types/apiTypes";
@@ -30,11 +30,12 @@ export const useCategoryMultiSelect = ({
 	// Get selected IDs from cache
 	const selectedCategoryIds = useBookmarkCategories(bookmarkId);
 
-	const { addCategoryToBookmarkMutation } = useAddCategoryToBookmarkMutation({
-		skipInvalidation: mutationOptions.skipInvalidation,
-	});
-	const { removeCategoryFromBookmarkMutation } =
-		useRemoveCategoryFromBookmarkMutation({
+	const { addCategoryToBookmarkOptimisticMutation } =
+		useAddCategoryToBookmarkOptimisticMutation({
+			skipInvalidation: mutationOptions.skipInvalidation,
+		});
+	const { removeCategoryFromBookmarkOptimisticMutation } =
+		useRemoveCategoryFromBookmarkOptimisticMutation({
 			skipInvalidation: mutationOptions.skipInvalidation,
 			preserveInList: mutationOptions.preserveInList,
 		});
@@ -61,7 +62,7 @@ export const useCategoryMultiSelect = ({
 	);
 
 	const handleAdd = (category: CategoriesData) => {
-		addCategoryToBookmarkMutation.mutate({
+		addCategoryToBookmarkOptimisticMutation.mutate({
 			bookmark_id: bookmarkId,
 			category_id: category.id,
 		});
@@ -69,7 +70,7 @@ export const useCategoryMultiSelect = ({
 	};
 
 	const handleRemove = (category: CategoriesData) => {
-		removeCategoryFromBookmarkMutation.mutate({
+		removeCategoryFromBookmarkOptimisticMutation.mutate({
 			bookmark_id: bookmarkId,
 			category_id: category.id,
 		});
@@ -83,9 +84,9 @@ export const useCategoryMultiSelect = ({
 		handleRemove,
 		getItemId: (cat: CategoriesData) => cat.id,
 		getItemLabel: (cat: CategoriesData) => cat.category_name,
-		isAdding: addCategoryToBookmarkMutation.isPending,
-		isRemoving: removeCategoryFromBookmarkMutation.isPending,
-		addError: addCategoryToBookmarkMutation.error,
-		removeError: removeCategoryFromBookmarkMutation.error,
+		isAdding: addCategoryToBookmarkOptimisticMutation.isPending,
+		isRemoving: removeCategoryFromBookmarkOptimisticMutation.isPending,
+		addError: addCategoryToBookmarkOptimisticMutation.error,
+		removeError: removeCategoryFromBookmarkOptimisticMutation.error,
 	};
 };
diff --git a/src/hooks/use-page-context.ts b/src/hooks/use-page-context.ts
new file mode 100644
index 00000000..fdf892df
--- /dev/null
+++ b/src/hooks/use-page-context.ts
@@ -0,0 +1,56 @@
+import { useMemo } from "react";
+import { useRouter } from "next/router";
+
+import { DISCOVER_URL, isPublicPath } from "@/utils/constants";
+import { getCategorySlugFromRouter } from "@/utils/url";
+
+/**
+ * Page context information derived from router
+ */
+export type PageContext = {
+	/**
+	 * Whether the current page is a public page (e.g., /public/user/collection)
+	 */
+	isPublicPage: boolean;
+	/**
+	 * Whether the current page is the discover page
+	 */
+	isDiscoverPage: boolean;
+	/**
+	 * Current category slug from the URL, or null if not in a category route
+	 */
+	categorySlug: string | null;
+};
+
+/**
+ * Hook to get page context information from the router
+ *
+ * This hook provides a centralized way to determine the current page type
+ * and category context, eliminating the need to pass these values as props
+ * through multiple component layers.
+ * @example
+ * ```tsx
+ * const { isPublicPage, isDiscoverPage, categorySlug } = usePageContext();
+ *
+ * if (isPublicPage) {
+ *   // Public page logic
+ * }
+ *
+ * if (isDiscoverPage) {
+ *   // Discover page logic
+ * }
+ * ```
+ */
+export const usePageContext = (): PageContext => {
+	const router = useRouter();
+
+	return useMemo(() => {
+		const categorySlug = getCategorySlugFromRouter(router);
+
+		return {
+			isPublicPage: isPublicPath(router.asPath),
+			isDiscoverPage: categorySlug === DISCOVER_URL,
+			categorySlug,
+		};
+	}, [router]);
+};
diff --git a/src/icons/discover-icon.tsx b/src/icons/discover-icon.tsx
new file mode 100644
index 00000000..756a1271
--- /dev/null
+++ b/src/icons/discover-icon.tsx
@@ -0,0 +1,21 @@
+import { Icon, type IconProps } from "@/components/ui/recollect/icon";
+
+export const DiscoverIcon = (props: IconProps) => (
+	<Icon
+		width="24"
+		height="24"
+		viewBox="0 0 24 24"
+		fill="none"
+		xmlns="http://www.w3.org/2000/svg"
+		{...props}
+	>
+		<circle cx="12" cy="12" r="10" stroke="currentColor" strokeWidth="2" />
+		<path
+			d="M14.5 9.5L13 13L9.5 14.5L11 11L14.5 9.5Z"
+			stroke="currentColor"
+			strokeWidth="2"
+			fill="none"
+			strokeLinejoin="round"
+		/>
+	</Icon>
+);
diff --git a/src/icons/tickIcon.tsx b/src/icons/tickIcon.tsx
index 57474043..1e5788c9 100644
--- a/src/icons/tickIcon.tsx
+++ b/src/icons/tickIcon.tsx
@@ -1,22 +1,12 @@
-type TickIconProps = {
-	color?: string;
-};
+import { Icon, type IconProps } from "@/components/ui/recollect/icon";
 
-const TickIcon = ({ color = "#383838" }: TickIconProps) => (
-	<svg
-		fill="none"
-		height="12"
-		viewBox="0 0 12 12"
-		width="12"
-		xmlns="http://www.w3.org/2000/svg"
-	>
+export const TickIcon = (props: IconProps) => (
+	<Icon fill="none" viewBox="0 0 12 12" {...props}>
 		<path
 			clipRule="evenodd"
 			d="M10.5739 2.19354C10.8456 2.42818 10.8756 2.83864 10.641 3.11032L5.01371 9.62614C4.89175 9.76735 4.715 9.84934 4.52842 9.85125C4.34185 9.85316 4.16345 9.7748 4.03863 9.63611L1.37307 6.67438C1.13292 6.40755 1.15455 5.99656 1.42139 5.75641C1.68822 5.51626 2.09921 5.53789 2.33935 5.80472L4.51172 8.21846L9.65713 2.26062C9.89177 1.98893 10.3022 1.9589 10.5739 2.19354Z"
-			fill={color}
+			fill="currentColor"
 			fillRule="evenodd"
 		/>
-	</svg>
+	</Icon>
 );
-
-export default TickIcon;
diff --git a/src/lib/api-helpers/create-handler.ts b/src/lib/api-helpers/create-handler.ts
index 0d041685..34aa48b2 100644
--- a/src/lib/api-helpers/create-handler.ts
+++ b/src/lib/api-helpers/create-handler.ts
@@ -2,26 +2,146 @@ import { NextResponse, type NextRequest } from "next/server";
 import { type SupabaseClient, type User } from "@supabase/supabase-js";
 import { type z } from "zod";
 
-import { apiError, apiSuccess, parseBody } from "./response";
+import { apiError, apiSuccess, parseBody, parseQuery } from "./response";
 import { requireAuth } from "@/lib/supabase/api";
 import { type Database } from "@/types/database.types";
 
-type HandlerContext<TInput> = {
+// Context types for handlers
+type AuthHandlerContext<TInput> = {
 	data: TInput;
 	route: string;
 	supabase: SupabaseClient<Database>;
 	user: User;
 };
 
-type CreateSupabasePostApiHandlerConfig<TInput, TOutput> = {
-	handler: (ctx: HandlerContext<TInput>) => Promise<NextResponse | TOutput>;
+type PublicHandlerContext<TInput> = {
+	input: TInput;
+	route: string;
+};
+
+// Config types
+type AuthHandlerConfig<TInput, TOutput> = {
+	handler: (ctx: AuthHandlerContext<TInput>) => Promise<NextResponse | TOutput>;
+	inputSchema: z.ZodType<TInput>;
+	outputSchema: z.ZodType<TOutput>;
+	route: string;
+};
+
+type PublicHandlerConfig<TInput, TOutput> = {
+	handler: (
+		ctx: PublicHandlerContext<TInput>,
+	) => Promise<NextResponse | TOutput>;
 	inputSchema: z.ZodType<TInput>;
 	outputSchema: z.ZodType<TOutput>;
 	route: string;
 };
 
-export const createSupabasePostApiHandler = <TInput, TOutput>(
-	config: CreateSupabasePostApiHandlerConfig<TInput, TOutput>,
+// ============================================================
+// Public Handlers (no auth)
+// ============================================================
+
+export const createGetApiHandler = <TInput, TOutput>(
+	config: PublicHandlerConfig<TInput, TOutput>,
+) => {
+	const { route, inputSchema, outputSchema, handler } = config;
+
+	return async (request: NextRequest) => {
+		try {
+			const query = parseQuery({ request, schema: inputSchema, route });
+			if (query.errorResponse) {
+				return query.errorResponse;
+			}
+
+			const result = await handler({ input: query.data, route });
+
+			if (result instanceof NextResponse) {
+				return result;
+			}
+
+			return apiSuccess({ route, data: result, schema: outputSchema });
+		} catch (error) {
+			return apiError({
+				route,
+				message: "An unexpected error occurred",
+				error,
+				operation: `${route}_unexpected`,
+			});
+		}
+	};
+};
+
+export const createPostApiHandler = <TInput, TOutput>(
+	config: PublicHandlerConfig<TInput, TOutput>,
+) => {
+	const { route, inputSchema, outputSchema, handler } = config;
+
+	return async (request: NextRequest) => {
+		try {
+			const body = await parseBody({ request, schema: inputSchema, route });
+			if (body.errorResponse) {
+				return body.errorResponse;
+			}
+
+			const result = await handler({ input: body.data, route });
+
+			if (result instanceof NextResponse) {
+				return result;
+			}
+
+			return apiSuccess({ route, data: result, schema: outputSchema });
+		} catch (error) {
+			return apiError({
+				route,
+				message: "An unexpected error occurred",
+				error,
+				operation: `${route}_unexpected`,
+			});
+		}
+	};
+};
+
+// ============================================================
+// Authenticated Handlers (with auth)
+// ============================================================
+
+export const createGetApiHandlerWithAuth = <TInput, TOutput>(
+	config: AuthHandlerConfig<TInput, TOutput>,
+) => {
+	const { route, inputSchema, outputSchema, handler } = config;
+
+	return async (request: NextRequest) => {
+		try {
+			const auth = await requireAuth(route);
+			if (auth.errorResponse) {
+				return auth.errorResponse;
+			}
+
+			const query = parseQuery({ request, schema: inputSchema, route });
+			if (query.errorResponse) {
+				return query.errorResponse;
+			}
+
+			const { supabase, user } = auth;
+			const result = await handler({ data: query.data, supabase, user, route });
+
+			if (result instanceof NextResponse) {
+				return result;
+			}
+
+			return apiSuccess({ route, data: result, schema: outputSchema });
+		} catch (error) {
+			return apiError({
+				route,
+				message: "An unexpected error occurred",
+				error,
+				operation: `${route}_unexpected`,
+			});
+		}
+	};
+};
+
+export const createPostApiHandlerWithAuth = <TInput, TOutput>(
+	config: AuthHandlerConfig<TInput, TOutput>,
 ) => {
 	const { route, inputSchema, outputSchema, handler } = config;
 
diff --git a/src/lib/api-helpers/response.ts b/src/lib/api-helpers/response.ts
index 90ca8130..9009d044 100644
--- a/src/lib/api-helpers/response.ts
+++ b/src/lib/api-helpers/response.ts
@@ -1,4 +1,4 @@
-import { NextResponse } from "next/server";
+import { NextResponse, type NextRequest } from "next/server";
 import * as Sentry from "@sentry/nextjs";
 import { type z, type ZodSchema } from "zod";
 
@@ -162,3 +162,46 @@ export async function parseBody<T>({
 
 	return { data: parsed.data, errorResponse: null };
 }
+
+type ParseQueryResult<T> =
+	| { data: T; errorResponse: null }
+	| { data: null; errorResponse: NextResponse<ApiErrorResponse> };
+
+type ParseQueryProps<T> = {
+	request: NextRequest;
+	route: string;
+	schema: ZodSchema<T>;
+};
+
+/**
+ * Parse and validate query parameters against a Zod schema.
+ * Returns discriminated union for type narrowing (same pattern as parseBody).
+ * Query parameters are strings - use z.coerce.* for numeric values.
+ */
+export function parseQuery<T>({
+	request,
+	schema,
+	route,
+}: ParseQueryProps<T>): ParseQueryResult<T> {
+	const searchParams = request.nextUrl.searchParams;
+	const params = Object.fromEntries(searchParams.entries());
+
+	const parsed = schema.safeParse(params);
+
+	if (!parsed.success) {
+		const firstError = parsed.error.issues[0];
+		const userMessage = firstError?.message || "Invalid query parameters";
+
+		return {
+			data: null,
+			errorResponse: apiWarn({
+				route,
+				message: userMessage,
+				status: HttpStatus.BAD_REQUEST,
+				context: { errors: parsed.error.issues },
+			}),
+		};
+	}
+
+	return { data: parsed.data, errorResponse: null };
+}
diff --git a/src/lib/validation/tag-category-schema.ts b/src/lib/validation/tag-category-schema.ts
new file mode 100644
index 00000000..11a2eba3
--- /dev/null
+++ b/src/lib/validation/tag-category-schema.ts
@@ -0,0 +1,34 @@
+import { z } from "zod";
+
+import {
+	MAX_TAG_COLLECTION_NAME_LENGTH,
+	MIN_TAG_COLLECTION_NAME_LENGTH,
+} from "@/utils/constants";
+
+/**
+ * Shared validation schema for tag and category names.
+ * Used by both client (edit-popover) and server (API routes).
+ *
+ * Features:
+ * - Auto-trims whitespace via `.trim()`
+ * - Validates minimum length (prevents empty strings)
+ * - Validates maximum length
+ * - Provides clear error messages
+ */
+export const tagCategoryNameSchema = z
+	.string({ error: "Name is required" })
+	.trim()
+	.min(
+		MIN_TAG_COLLECTION_NAME_LENGTH,
+		`Name must be at least ${MIN_TAG_COLLECTION_NAME_LENGTH} character${MIN_TAG_COLLECTION_NAME_LENGTH === 1 ? "" : "s"}`,
+	)
+	.max(
+		MAX_TAG_COLLECTION_NAME_LENGTH,
+		`Name must be at most ${MAX_TAG_COLLECTION_NAME_LENGTH} characters`,
+	);
+
+/**
+ * Type inference for validated tag/category names.
+ * This is the output type after Zod validation (already trimmed).
+ */
+export type TagCategoryName = z.output<typeof tagCategoryNameSchema>;
diff --git a/src/pageComponents/dashboard/cardSection/bookmarksSkeleton.tsx b/src/pageComponents/dashboard/cardSection/bookmarksSkeleton.tsx
index fb13b938..94c06c53 100644
--- a/src/pageComponents/dashboard/cardSection/bookmarksSkeleton.tsx
+++ b/src/pageComponents/dashboard/cardSection/bookmarksSkeleton.tsx
@@ -3,7 +3,11 @@ import { useIsMobileView } from "../../../hooks/useIsMobileView";
 import { viewValues } from "../../../utils/constants";
 import { getColumnCount } from "../../../utils/helpers";
 
-const precomputedHeights = generateRandomHeights(26);
+// Deterministic heights to avoid hydration mismatches between server and client
+const PRECOMPUTED_HEIGHTS = [
+	330, 243, 691, 644, 514, 545, 408, 287, 450, 650, 332, 461, 483, 271, 726,
+	616, 404, 309, 586, 552, 675, 252, 617, 614, 709, 309,
+];
 
 export const BookmarksSkeletonLoader = ({
 	count = 26,
@@ -16,7 +20,10 @@ export const BookmarksSkeletonLoader = ({
 }) => {
 	const { isDesktop } = useIsMobileView();
 
-	const skeletonHeights = precomputedHeights.slice(0, count);
+	const skeletonHeights = Array.from({ length: count }, (_, index) => {
+		const height = PRECOMPUTED_HEIGHTS[index % PRECOMPUTED_HEIGHTS.length];
+		return height ?? 300;
+	});
 	const columnCount = getColumnCount(isDesktop, colCount);
 
 	// List View Skeleton
@@ -119,10 +126,3 @@ export const BookmarksSkeletonLoader = ({
 		</div>
 	);
 };
-
-function generateRandomHeights(count: number): number[] {
-	return Array.from(
-		{ length: count },
-		() => Math.floor(Math.random() * (850 - 250 + 1)) + 250,
-	);
-}
diff --git a/src/pageComponents/dashboard/cardSection/discover-checkbox.tsx b/src/pageComponents/dashboard/cardSection/discover-checkbox.tsx
new file mode 100644
index 00000000..652e7f2b
--- /dev/null
+++ b/src/pageComponents/dashboard/cardSection/discover-checkbox.tsx
@@ -0,0 +1,39 @@
+import { useToggleDiscoverableOptimisticMutation } from "@/async/mutationHooks/bookmarks/use-toggle-discoverable-optimistic-mutation";
+import { Checkbox } from "@/components/ui/recollect/checkbox";
+
+type DiscoverableCheckboxProps = {
+	bookmarkId: number;
+	isDiscoverable: boolean;
+};
+
+export const DiscoverCheckbox = ({
+	bookmarkId,
+	isDiscoverable,
+}: DiscoverableCheckboxProps) => {
+	const { toggleDiscoverableOptimisticMutation } =
+		useToggleDiscoverableOptimisticMutation();
+
+	const handleCheckedChange = (checked: boolean) => {
+		toggleDiscoverableOptimisticMutation.mutate({
+			bookmark_id: bookmarkId,
+			make_discoverable: checked,
+		});
+	};
+
+	return (
+		<div className="flex items-center gap-2 px-2 py-1.5">
+			{/* eslint-disable-next-line jsx-a11y/label-has-associated-control */}
+			<label className="flex cursor-pointer items-center gap-2">
+				<Checkbox
+					checked={isDiscoverable}
+					onCheckedChange={handleCheckedChange}
+					className="flex size-4 items-center justify-center rounded border-2 border-gray-400 data-checked:border-gray-800 data-checked:bg-gray-800 [&_svg]:h-3 [&_svg]:w-3 [&_svg]:text-plain data-checked:[&_svg]:text-gray-200"
+				/>
+
+				<span className="text-sm font-medium text-gray-800">
+					Make discoverable
+				</span>
+			</label>
+		</div>
+	);
+};
diff --git a/src/pageComponents/dashboard/cardSection/edit-popover.tsx b/src/pageComponents/dashboard/cardSection/edit-popover.tsx
index 737cfc8e..6d821db2 100644
--- a/src/pageComponents/dashboard/cardSection/edit-popover.tsx
+++ b/src/pageComponents/dashboard/cardSection/edit-popover.tsx
@@ -1,10 +1,9 @@
 import { useMemo, useState } from "react";
 import { Popover } from "@base-ui/react/popover";
-import { z } from "zod";
 
-import { useAddTagToBookmarkMutation } from "@/async/mutationHooks/tags/useAddTagToBookmarkMutation";
-import { useCreateAndAssignTagMutation } from "@/async/mutationHooks/tags/useCreateAndAssignTagMutation";
-import { useRemoveTagFromBookmarkMutation } from "@/async/mutationHooks/tags/useRemoveTagFromBookmarkMutation";
+import { useAddTagToBookmarkOptimisticMutation } from "@/async/mutationHooks/tags/use-add-tag-to-bookmark-optimistic-mutation";
+import { useCreateAndAssignTagOptimisticMutation } from "@/async/mutationHooks/tags/use-create-and-assign-tag-optimistic-mutation";
+import { useRemoveTagFromBookmarkOptimisticMutation } from "@/async/mutationHooks/tags/use-remove-tag-from-bookmark-optimistic-mutation";
 import useFetchUserTags from "@/async/queryHooks/userTags/useFetchUserTags";
 import { CollectionIcon } from "@/components/collectionIcon";
 import { Combobox } from "@/components/ui/recollect/combobox";
@@ -13,16 +12,15 @@ import { useBookmarkTags } from "@/hooks/use-bookmark-tags";
 import { useCategoryMultiSelect } from "@/hooks/use-category-multi-select";
 import { useIsPublicPage } from "@/hooks/use-is-public-page";
 import { EditIcon } from "@/icons/edit-icon";
+import { tagCategoryNameSchema } from "@/lib/validation/tag-category-schema";
+import { DiscoverCheckbox } from "@/pageComponents/dashboard/cardSection/discover-checkbox";
 import {
 	type CategoriesData,
 	type SingleListData,
 	type UserTagsData,
 } from "@/types/apiTypes";
-import { MAX_TAG_NAME_LENGTH } from "@/utils/constants";
 import { cn } from "@/utils/tailwind-merge";
 
-const TAG_CREATE_SCHEMA = z.string().max(MAX_TAG_NAME_LENGTH);
-
 type EditPopoverProps = {
 	post: SingleListData;
 	userId: string;
@@ -78,6 +76,12 @@ export const EditPopover = ({ post, userId }: EditPopoverProps) => {
 									<CategoryMultiSelect bookmarkId={post.id} />
 								</div>
 							</div>
+							<div className="w-full">
+								<DiscoverCheckbox
+									bookmarkId={post.id}
+									isDiscoverable={post.make_discoverable !== null}
+								/>
+							</div>
 						</div>
 					</Popover.Popup>
 				</Popover.Positioner>
@@ -92,9 +96,12 @@ type TagMultiSelectProps = {
 
 export const TagMultiSelect = ({ bookmarkId }: TagMultiSelectProps) => {
 	const { userTags } = useFetchUserTags();
-	const { addTagToBookmarkMutation } = useAddTagToBookmarkMutation();
-	const { removeTagFromBookmarkMutation } = useRemoveTagFromBookmarkMutation();
-	const { createAndAssignTagMutation } = useCreateAndAssignTagMutation();
+	const { addTagToBookmarkOptimisticMutation } =
+		useAddTagToBookmarkOptimisticMutation();
+	const { removeTagFromBookmarkOptimisticMutation } =
+		useRemoveTagFromBookmarkOptimisticMutation();
+	const { createAndAssignTagOptimisticMutation } =
+		useCreateAndAssignTagOptimisticMutation();
 
 	const selectedTagIds = useBookmarkTags(bookmarkId);
 	const allTags = useMemo(() => userTags?.data ?? [], [userTags?.data]);
@@ -113,27 +120,25 @@ export const TagMultiSelect = ({ bookmarkId }: TagMultiSelectProps) => {
 	);
 
 	const handleAdd = (tag: UserTagsData) => {
-		addTagToBookmarkMutation.mutate({
-			selectedData: {
-				bookmark_id: bookmarkId,
-				tag_id: tag.id,
-			},
+		addTagToBookmarkOptimisticMutation.mutate({
+			bookmarkId,
+			tagId: tag.id,
 		});
 	};
 
 	const handleRemove = (tag: UserTagsData) => {
-		removeTagFromBookmarkMutation.mutate({
-			selectedData: {
-				bookmark_id: bookmarkId,
-				tag_id: tag.id,
-			},
+		removeTagFromBookmarkOptimisticMutation.mutate({
+			bookmarkId,
+			tagId: tag.id,
 		});
 	};
 
 	const handleCreate = (tagName: string) => {
-		createAndAssignTagMutation.mutate({
-			tagName,
+		createAndAssignTagOptimisticMutation.mutate({
+			name: tagName,
 			bookmarkId,
+			// Pre-generate temp ID so both BOOKMARKS_KEY and USER_TAGS_KEY caches use same ID
+			_tempId: -Date.now(),
 		});
 	};
 
@@ -146,7 +151,7 @@ export const TagMultiSelect = ({ bookmarkId }: TagMultiSelectProps) => {
 			onAdd={handleAdd}
 			onRemove={handleRemove}
 			onCreate={handleCreate}
-			createSchema={TAG_CREATE_SCHEMA}
+			createSchema={tagCategoryNameSchema}
 		>
 			<Combobox.Chips>
 				<Combobox.Value>
@@ -171,8 +176,8 @@ export const TagMultiSelect = ({ bookmarkId }: TagMultiSelectProps) => {
 							<Combobox.List>
 								{(item: UserTagsData) => (
 									<Combobox.Item key={item.id} value={item}>
-										<Combobox.ItemIndicator />
 										<span className="truncate">{item.name}</span>
+										<Combobox.ItemIndicator />
 									</Combobox.Item>
 								)}
 							</Combobox.List>
@@ -239,13 +244,13 @@ export const CategoryMultiSelect = ({
 							<Combobox.List>
 								{(item: CategoriesData) => (
 									<Combobox.Item key={item.id} value={item}>
-										<Combobox.ItemIndicator />
 										<CollectionIcon
 											bookmarkCategoryData={item}
 											iconSize="10"
 											size="16"
 										/>
 										<span className="truncate">{item.category_name}</span>
+										<Combobox.ItemIndicator />
 									</Combobox.Item>
 								)}
 							</Combobox.List>
diff --git a/src/pageComponents/dashboard/cardSection/imageCard.tsx b/src/pageComponents/dashboard/cardSection/imageCard.tsx
index 0645a78c..31ed604f 100644
--- a/src/pageComponents/dashboard/cardSection/imageCard.tsx
+++ b/src/pageComponents/dashboard/cardSection/imageCard.tsx
@@ -58,9 +58,9 @@ const ImgLogicComponent = ({
 	const imgClassName = classNames({
 		"min-h-[48px] min-w-[80px] max-h-[48px] max-w-[80px] object-cover rounded-sm":
 			cardTypeCondition === viewValues.list,
-		" w-full object-cover rounded-lg  duration-150 moodboard-card-img aspect-[1.9047]":
+		" w-full object-cover rounded-lg group-hover:rounded-b-none  duration-150 moodboard-card-img aspect-[1.9047]":
 			cardTypeCondition === viewValues.card,
-		"w-full rounded-lg  moodboard-card-img min-h-[192px] object-cover":
+		"w-full rounded-lg group-hover:rounded-b-none duration-150  moodboard-card-img min-h-[192px] object-cover":
 			cardTypeCondition === viewValues.moodboard ||
 			cardTypeCondition === viewValues.timeline,
 		"relative z-[-1]":
@@ -159,10 +159,10 @@ const LoaderImgPlaceholder = ({
 	const loaderClassName = classNames({
 		"h-[48px] w-[80px] flex items-center justify-center bg-gray-100 rounded-lg":
 			cardTypeCondition === viewValues.list,
-		"w-full aspect-[1.9047] flex items-center justify-center bg-gray-100 rounded-lg flex-col gap-2 text-center":
+		"w-full aspect-[1.9047] flex items-center justify-center bg-gray-100 rounded-lg flex-col gap-2 text-center  group-hover:rounded-b-none duration-150 ":
 			cardTypeCondition === viewValues.card ||
 			cardTypeCondition === viewValues.timeline,
-		"w-full aspect-[1.8] flex items-center justify-center bg-gray-100 rounded-lg flex-col gap-2 text-center":
+		"w-full aspect-[1.8] flex items-center justify-center bg-gray-100 rounded-lg flex-col gap-2 text-center  group-hover:rounded-b-none duration-150 ":
 			cardTypeCondition === viewValues.moodboard,
 	});
 	return (
diff --git a/src/pageComponents/dashboard/cardSection/index.tsx b/src/pageComponents/dashboard/cardSection/index.tsx
index 53af881a..4b4b45a9 100644
--- a/src/pageComponents/dashboard/cardSection/index.tsx
+++ b/src/pageComponents/dashboard/cardSection/index.tsx
@@ -38,6 +38,7 @@ import { type BookmarksViewTypes } from "../../../types/componentStoreTypes";
 import {
 	BOOKMARKS_KEY,
 	CATEGORIES_KEY,
+	DISCOVER_URL,
 	EVERYTHING_URL,
 	IMAGE_TYPE_PREFIX,
 	PDF_MIME_TYPE,
@@ -77,8 +78,8 @@ export type CardSectionProps = {
 	isOgImgLoading: boolean;
 	isPublicPage?: boolean;
 	listData: SingleListData[];
-	onDeleteClick: (post: SingleListData[]) => void;
-	onMoveOutOfTrashClick: (post: SingleListData) => void;
+	onDeleteClick?: (post: SingleListData[]) => void;
+	onMoveOutOfTrashClick?: (post: SingleListData) => void;
 	showAvatar: boolean;
 	userId: string;
 	isLoadingProfile?: boolean;
@@ -163,9 +164,10 @@ const CardSection = ({
 		pages: Array<{ data: SingleListData[]; error: PostgrestError }>;
 	};
 
-	const bookmarksList = isEmpty(searchText)
-		? listData
-		: (searchBookmarksData?.pages?.flatMap((page) => page?.data ?? []) ?? []);
+	const bookmarksList =
+		isPublicPage || isEmpty(searchText)
+			? listData
+			: (searchBookmarksData?.pages?.flatMap((page) => page?.data ?? []) ?? []);
 	const bookmarksInfoValue = useGetViewValue(
 		"cardContentViewArray",
 		[],
@@ -257,7 +259,7 @@ const CardSection = ({
 					isBottomBar={false}
 					label="Delete Bookmark"
 					onClearTrash={() => {
-						onDeleteClick([post]);
+						onDeleteClick?.([post]);
 					}}
 					isClearingTrash={false}
 					isOpen={isTrashMenuOpen}
@@ -268,7 +270,7 @@ const CardSection = ({
 			) : (
 				<Button
 					className="z-15 ml-2 hidden rounded-lg bg-whites-700 p-[5px] backdrop-blur-xs outline-none group-hover:flex focus-visible:ring-2 focus-visible:ring-blue-500"
-					onClick={() => onDeleteClick([post])}
+					onClick={() => onDeleteClick?.([post])}
 				>
 					<TrashIconGray />
 				</Button>
@@ -307,7 +309,7 @@ const CardSection = ({
 				>
 					<Button
 						className="z-15 rounded-lg bg-whites-700 p-[5px] backdrop-blur-xs outline-none group-hover:flex focus-visible:ring-2 focus-visible:ring-blue-500"
-						onClick={() => onMoveOutOfTrashClick(post)}
+						onClick={() => onMoveOutOfTrashClick?.(post)}
 					>
 						<BackIcon />
 					</Button>
@@ -417,13 +419,12 @@ const CardSection = ({
 		const figureClassName = classNames({
 			"relative z-[-1]": isAudio || isVideo,
 			"h-[48px] w-[80px] mr-3": cardTypeCondition === viewValues.list,
-			"w-full shadow-custom-8 rounded-lg group-hover:rounded-b-none":
-				cardTypeCondition === viewValues.card,
+			"w-full shadow-custom-8": cardTypeCondition === viewValues.card,
 			"aspect-[1.8]":
 				cardTypeCondition === viewValues.moodboard &&
 				(isOgImgLoading || isBookmarkLoading) &&
 				img === undefined,
-			"rounded-lg shadow-custom-8": cardTypeCondition === viewValues.moodboard,
+			"shadow-custom-8 rounded-lg": cardTypeCondition === viewValues.moodboard,
 		});
 
 		const playSvgClassName = classNames({
@@ -607,7 +608,7 @@ const CardSection = ({
 	};
 
 	const moodboardAndCardInfoWrapperClass = classNames({
-		"card-moodboard-info-wrapper space-y-[6px] rounded-b-lg px-2 py-3 dark:group-hover:bg-gray-alpha-100 duration-150 transition-all": true,
+		"card-moodboard-info-wrapper space-y-[6px] px-2 py-3 dark:group-hover:bg-gray-alpha-100 rounded-b-lg duration-150 transition-all": true,
 		grow: cardTypeCondition === viewValues.card,
 	});
 
@@ -739,7 +740,7 @@ const CardSection = ({
 	);
 
 	const listWrapperClass = classNames({
-		"mt-[47px]": true,
+		"mt-[47px]": !isPublicPage || categorySlug === DISCOVER_URL,
 		"px-4 py-2": cardTypeCondition === viewValues.list,
 		"py-2 px-3":
 			cardTypeCondition === viewValues.moodboard ||
@@ -820,6 +821,7 @@ const CardSection = ({
 		<>
 			<div className={listWrapperClass}>{renderItem()}</div>
 			<PreviewLightBox
+				bookmarks={isPublicPage ? bookmarksList : undefined}
 				id={lightboxId}
 				open={lightboxOpen}
 				setOpen={setLightboxOpen}
diff --git a/src/pageComponents/dashboard/cardSection/listBox.tsx b/src/pageComponents/dashboard/cardSection/listBox.tsx
index b8b3942e..02777979 100644
--- a/src/pageComponents/dashboard/cardSection/listBox.tsx
+++ b/src/pageComponents/dashboard/cardSection/listBox.tsx
@@ -50,7 +50,7 @@ import { handleBulkBookmarkDelete } from "../handleBookmarkDelete";
 import Option from "./option";
 import useDeleteBookmarksOptimisticMutation from "@/async/mutationHooks/bookmarks/useDeleteBookmarksOptimisticMutation";
 import useMoveBookmarkToTrashOptimisticMutation from "@/async/mutationHooks/bookmarks/useMoveBookmarkToTrashOptimisticMutation";
-import { useAddCategoryToBookmarksMutation } from "@/async/mutationHooks/category/use-add-category-to-bookmarks-mutation";
+import { useAddCategoryToBookmarksOptimisticMutation } from "@/async/mutationHooks/category/use-add-category-to-bookmarks-optimistic-mutation";
 import useSearchBookmarks from "@/async/queryHooks/bookmarks/useSearchBookmarks";
 import { ClearTrashDropdown } from "@/components/clearTrashDropdown";
 import { Checkbox } from "@/components/ui/recollect/checkbox";
@@ -78,8 +78,8 @@ const ListBox = (props: ListBoxDropTypes) => {
 		isPublicPage,
 	} = props;
 
-	const { addCategoryToBookmarksMutation } =
-		useAddCategoryToBookmarksMutation();
+	const { addCategoryToBookmarksOptimisticMutation } =
+		useAddCategoryToBookmarksOptimisticMutation();
 
 	const deleteBookmarkId = useMiscellaneousStore(
 		(state) => state.deleteBookmarkId,
@@ -528,7 +528,7 @@ const ListBox = (props: ListBoxDropTypes) => {
 												state.selectionManager.selectedKeys.keys(),
 											).map(Number);
 
-											addCategoryToBookmarksMutation.mutate(
+											addCategoryToBookmarksOptimisticMutation.mutate(
 												{
 													bookmark_ids: selectedIds,
 													category_id: dropdownItem?.value,
diff --git a/src/pageComponents/dashboard/cardSection/option.tsx b/src/pageComponents/dashboard/cardSection/option.tsx
index 32fa5ce5..3b40ba90 100644
--- a/src/pageComponents/dashboard/cardSection/option.tsx
+++ b/src/pageComponents/dashboard/cardSection/option.tsx
@@ -17,12 +17,15 @@ import { type DraggableCollectionState, type ListState } from "react-stately";
 
 import { useMiscellaneousStore } from "../../../store/componentStore";
 import { type SingleListData } from "../../../types/apiTypes";
+import { DISCOVER_URL, viewValues } from "../../../utils/constants";
 import {
-	CATEGORY_ID_PATHNAME,
-	PREVIEW_PATH,
-	viewValues,
-} from "../../../utils/constants";
-import { getCategorySlugFromRouter } from "../../../utils/url";
+	getCategorySlugFromRouter,
+	getPublicPageInfo,
+} from "../../../utils/url";
+import {
+	buildAuthenticatedPreviewUrl,
+	buildPublicPreviewUrl,
+} from "../../../utils/url-builders";
 
 import { Checkbox } from "@/components/ui/recollect/checkbox";
 import { cn } from "@/utils/tailwind-merge";
@@ -54,6 +57,8 @@ const Option = ({
 	const { optionProps, isSelected } = useOption({ key: item.key }, state, ref);
 	const { focusProps } = useFocusRing();
 	const router = useRouter();
+	const categorySlug = getCategorySlugFromRouter(router);
+	const isDiscoverPage = categorySlug === DISCOVER_URL;
 	const { setLightboxId, setLightboxOpen, lightboxOpen } =
 		useMiscellaneousStore();
 	// Register the item as a drag source.
@@ -110,16 +115,12 @@ const Option = ({
 			{/* eslint-disable-next-line jsx-a11y/anchor-has-content */}
 			<a
 				className={`absolute top-0 left-0 h-full w-full rounded-lg ${
-					isTrashPage || isPublicPage ? "cursor-auto" : "cursor-pointer"
+					isTrashPage ? "cursor-auto" : "cursor-pointer"
 				}`}
 				draggable={false}
 				href={url}
 				onClick={(event) => {
-					if (
-						isTrashPage ||
-						item?.key?.toString().startsWith("$") ||
-						isPublicPage
-					) {
+					if (isTrashPage || item?.key?.toString().startsWith("$")) {
 						event.preventDefault();
 						return;
 					}
@@ -127,21 +128,25 @@ const Option = ({
 					event.preventDefault();
 					setLightboxId(item?.key?.toString());
 					setLightboxOpen(true);
-					void router.push(
-						{
-							// https://github.com/vercel/next.js/discussions/11625
-							// https://github.com/adamwathan/headbangstagram/pull/1/files
-							pathname: `${CATEGORY_ID_PATHNAME}`,
-							query: {
-								category_id: getCategorySlugFromRouter(router),
-								id: item?.key,
-							},
-						},
-						`/${getCategorySlugFromRouter(router)}${PREVIEW_PATH}/${item?.key}`,
-						{
-							shallow: true,
-						},
-					);
+					if (isPublicPage && !isDiscoverPage) {
+						const publicInfo = getPublicPageInfo(router);
+						if (publicInfo) {
+							const { pathname, query, as } = buildPublicPreviewUrl({
+								publicInfo,
+								bookmarkId: item?.key,
+							});
+							void router.push({ pathname, query }, as, { shallow: true });
+						}
+					} else {
+						const categorySlug = getCategorySlugFromRouter(router);
+						if (categorySlug) {
+							const { pathname, query, as } = buildAuthenticatedPreviewUrl({
+								categorySlug,
+								bookmarkId: item?.key,
+							});
+							void router.push({ pathname, query }, as, { shallow: true });
+						}
+					}
 				}}
 			/>
 			{item.rendered}
diff --git a/src/pageComponents/dashboard/dashboardLayout/headingComponents.tsx b/src/pageComponents/dashboard/dashboardLayout/headingComponents.tsx
index 54625af8..a5987d7c 100644
--- a/src/pageComponents/dashboard/dashboardLayout/headingComponents.tsx
+++ b/src/pageComponents/dashboard/dashboardLayout/headingComponents.tsx
@@ -1,12 +1,11 @@
 import { useEffect, useState } from "react";
 import isEmpty from "lodash/isEmpty";
 
-import useUpdateCategoryOptimisticMutation from "../../../async/mutationHooks/category/useUpdateCategoryOptimisticMutation";
+import { useUpdateCategoryOptimisticMutation } from "../../../async/mutationHooks/category/use-update-category-optimistic-mutation";
 import ToolTip from "../../../components/tooltip";
 import GlobeIcon from "../../../icons/globeIcon";
 import UsersCollabIcon from "../../../icons/usersCollabIcon";
 import { type CategoriesData } from "../../../types/apiTypes";
-import { mutationApiCall } from "../../../utils/apiHelpers";
 
 type NavBarHeadingProps = {
 	currentCategoryData: CategoriesData | undefined;
@@ -98,14 +97,12 @@ const NavBarHeadingInput = (props: NavBarHeadingInputProps) => {
 		useUpdateCategoryOptimisticMutation();
 
 	const updateCategoryName = (categoryId: number, name: string) => {
-		void mutationApiCall(
-			updateCategoryOptimisticMutation.mutateAsync({
-				category_id: categoryId,
-				updateData: {
-					category_name: name,
-				},
-			}),
-		);
+		updateCategoryOptimisticMutation.mutate({
+			category_id: categoryId,
+			updateData: {
+				category_name: name,
+			},
+		});
 	};
 
 	const handleSave = () => {
diff --git a/src/pageComponents/dashboard/discoverBookmarkCards.tsx b/src/pageComponents/dashboard/discoverBookmarkCards.tsx
new file mode 100644
index 00000000..d129ad7b
--- /dev/null
+++ b/src/pageComponents/dashboard/discoverBookmarkCards.tsx
@@ -0,0 +1,193 @@
+import { useMemo, useRef } from "react";
+import dynamic from "next/dynamic";
+import isEmpty from "lodash/isEmpty";
+import InfiniteScroll from "react-infinite-scroll-component";
+
+import { useFetchDiscoverBookmarks } from "../../async/queryHooks/bookmarks/use-fetch-discover-bookmarks";
+import useSearchBookmarks from "../../async/queryHooks/bookmarks/useSearchBookmarks";
+import useDebounce from "../../hooks/useDebounce";
+import useGetSortBy from "../../hooks/useGetSortBy";
+import useGetViewValue from "../../hooks/useGetViewValue";
+import {
+	useLoadersStore,
+	useMiscellaneousStore,
+} from "../../store/componentStore";
+import {
+	type BookmarkViewDataTypes,
+	type SingleListData,
+} from "../../types/apiTypes";
+import {
+	type BookmarksSortByTypes,
+	type BookmarksViewTypes,
+} from "../../types/componentStoreTypes";
+import { viewValues } from "../../utils/constants";
+
+const CardSection = dynamic(async () => await import("./cardSection"), {
+	ssr: false,
+});
+
+type SearchProps = {
+	data: SingleListData[];
+	hasNextPage: boolean;
+	fetchNextPage: () => void;
+	isLoading: boolean;
+	dataLength: number;
+};
+
+type DiscoverProps = {
+	data: SingleListData[];
+	hasNextPage: boolean;
+	fetchNextPage: () => void;
+	isLoading: boolean;
+	isFetching: boolean;
+	dataLength: number;
+};
+
+export const useDiscoverDataSource = (
+	isSearching: boolean,
+	searchProps: SearchProps,
+	discoverProps: DiscoverProps,
+) =>
+	isSearching
+		? {
+				displayData: searchProps.data,
+				hasMore: searchProps.hasNextPage,
+				fetchNext: searchProps.fetchNextPage,
+				isLoading: searchProps.isLoading && searchProps.dataLength === 0,
+				isOgImgLoading: false,
+			}
+		: {
+				displayData: discoverProps.data,
+				hasMore: discoverProps.hasNextPage,
+				fetchNext: discoverProps.fetchNextPage,
+				isLoading: discoverProps.isLoading && discoverProps.dataLength === 0,
+				isOgImgLoading: discoverProps.isFetching,
+			};
+
+export const DiscoverBookmarkCards = () => {
+	const infiniteScrollRef = useRef<HTMLDivElement>(null);
+
+	// Search functionality
+	const searchText = useMiscellaneousStore((state) => state.searchText);
+	const debouncedSearchText = useDebounce(searchText, 500);
+	const isSearchLoading = useLoadersStore((state) => state.isSearchLoading);
+
+	const {
+		flattenedSearchData,
+		fetchNextPage: fetchNextSearchPage,
+		hasNextPage: searchHasNextPage,
+	} = useSearchBookmarks();
+
+	// Discover data
+	const {
+		discoverData,
+		fetchNextPage: fetchNextDiscoverPage,
+		hasNextPage: discoverHasNextPage,
+		isFetchingNextPage: isFetchingNextDiscoverPage,
+		isLoading: isDiscoverLoading,
+	} = useFetchDiscoverBookmarks();
+
+	// Determine if we're currently searching (use debounced to match when query runs)
+	const isSearching = !isEmpty(debouncedSearchText);
+
+	const flattenedDiscoverData = useMemo(
+		() => discoverData?.pages?.flatMap((page) => page?.data ?? []) ?? [],
+		[discoverData],
+	);
+
+	// Get user's view preferences for discover page
+	const discoverBookmarksView = useGetViewValue(
+		"bookmarksView",
+		viewValues.card,
+		false,
+	);
+	const discoverCardContentViewArray = useGetViewValue(
+		"cardContentViewArray",
+		[],
+		false,
+	) as string[];
+	const discoverMoodboardColumns = useGetViewValue(
+		"moodboardColumns",
+		[10],
+		false,
+	) as number[];
+	const { sortBy: discoverSortBy } = useGetSortBy();
+
+	// Build categoryViewsFromProps for discover page
+	const discoverCategoryViews = useMemo<BookmarkViewDataTypes>(
+		() => ({
+			bookmarksView:
+				(discoverBookmarksView as BookmarksViewTypes) ||
+				(viewValues.card as BookmarksViewTypes),
+			cardContentViewArray: discoverCardContentViewArray || [],
+			moodboardColumns: discoverMoodboardColumns || [10],
+			sortBy:
+				(discoverSortBy as BookmarksSortByTypes) ||
+				("date-sort-acending" as BookmarksSortByTypes),
+		}),
+		[
+			discoverBookmarksView,
+			discoverCardContentViewArray,
+			discoverMoodboardColumns,
+			discoverSortBy,
+		],
+	);
+
+	// Use search results when searching, otherwise use discover data
+	const { displayData, hasMore, fetchNext, isLoading, isOgImgLoading } =
+		useDiscoverDataSource(
+			isSearching,
+			{
+				data: flattenedSearchData,
+				hasNextPage: searchHasNextPage,
+				fetchNextPage: () => {
+					void fetchNextSearchPage();
+				},
+				isLoading: isSearchLoading,
+				dataLength: flattenedSearchData.length,
+			},
+			{
+				data: flattenedDiscoverData,
+				hasNextPage: discoverHasNextPage,
+				fetchNextPage: () => {
+					void fetchNextDiscoverPage();
+				},
+				isLoading: isDiscoverLoading,
+				isFetching: isFetchingNextDiscoverPage,
+				dataLength: flattenedDiscoverData.length,
+			},
+		);
+
+	return (
+		<div
+			id="scrollableDiv"
+			ref={infiniteScrollRef}
+			className="h-screen overflow-x-hidden overflow-y-auto"
+		>
+			<InfiniteScroll
+				dataLength={displayData.length}
+				hasMore={hasMore ?? false}
+				loader={<div />}
+				next={fetchNext}
+				scrollableTarget="scrollableDiv"
+				endMessage={
+					<p className="pb-6 text-center text-plain-reverse">
+						{isSearchLoading ? "" : "Life happens, save it."}
+					</p>
+				}
+				className="h-screen overflow-visible"
+			>
+				<CardSection
+					categoryViewsFromProps={discoverCategoryViews}
+					isBookmarkLoading={false}
+					isLoading={isLoading}
+					isOgImgLoading={isOgImgLoading}
+					isPublicPage
+					listData={displayData}
+					showAvatar={false}
+					userId=""
+				/>
+			</InfiniteScroll>
+		</div>
+	);
+};
diff --git a/src/pageComponents/dashboard/index.tsx b/src/pageComponents/dashboard/index.tsx
index 756fc700..e985c276 100644
--- a/src/pageComponents/dashboard/index.tsx
+++ b/src/pageComponents/dashboard/index.tsx
@@ -18,7 +18,7 @@ import useAddBookmarkScreenshotMutation from "../../async/mutationHooks/bookmark
 import useClearBookmarksInTrashMutation from "../../async/mutationHooks/bookmarks/useClearBookmarksInTrashMutation";
 import useDeleteBookmarksOptimisticMutation from "../../async/mutationHooks/bookmarks/useDeleteBookmarksOptimisticMutation";
 import useMoveBookmarkToTrashOptimisticMutation from "../../async/mutationHooks/bookmarks/useMoveBookmarkToTrashOptimisticMutation";
-import useUpdateCategoryOptimisticMutation from "../../async/mutationHooks/category/useUpdateCategoryOptimisticMutation";
+import { useUpdateCategoryOptimisticMutation } from "../../async/mutationHooks/category/use-update-category-optimistic-mutation";
 import useFileUploadOptimisticMutation from "../../async/mutationHooks/files/useFileUploadOptimisticMutation";
 import useUpdateSharedCategoriesOptimisticMutation from "../../async/mutationHooks/share/useUpdateSharedCategoriesOptimisticMutation";
 import useUpdateUserProfileOptimisticMutation from "../../async/mutationHooks/user/useUpdateUserProfileOptimisticMutation";
@@ -31,6 +31,7 @@ import useFetchSharedCategories from "../../async/queryHooks/share/useFetchShare
 import useFetchUserProfile from "../../async/queryHooks/user/useFetchUserProfile";
 import { clipboardUpload } from "../../async/uploads/clipboard-upload";
 import { fileUpload } from "../../async/uploads/file-upload";
+import useDebounce from "../../hooks/useDebounce";
 import { useDeleteCollection } from "../../hooks/useDeleteCollection";
 import useGetCurrentCategoryId from "../../hooks/useGetCurrentCategoryId";
 import useIsInNotFoundPage from "../../hooks/useIsInNotFoundPage";
@@ -53,10 +54,10 @@ import {
 import { type FileType } from "../../types/componentTypes";
 import { mutationApiCall } from "../../utils/apiHelpers";
 import {
+	DISCOVER_URL,
 	DOCUMENTS_URL,
 	IMAGES_URL,
 	LINKS_URL,
-	SETTINGS_URL,
 	TRASH_URL,
 	TWEETS_URL,
 	UNCATEGORIZED_URL,
@@ -66,8 +67,8 @@ import { createClient } from "../../utils/supabaseClient";
 import { errorToast } from "../../utils/toastMessages";
 import { getCategorySlugFromRouter } from "../../utils/url";
 import NotFoundPage from "../notFoundPage";
-import Settings from "../settings";
 
+import { DiscoverBookmarkCards } from "./discoverBookmarkCards";
 import { handleBulkBookmarkDelete } from "./handleBookmarkDelete";
 import SettingsModal from "./modals/settingsModal";
 import SignedOutSection from "./signedOutSection";
@@ -117,6 +118,7 @@ const Dashboard = () => {
 	);
 
 	const searchText = useMiscellaneousStore((state) => state.searchText);
+	const debouncedSearchText = useDebounce(searchText, 500);
 	const isSearchLoading = useLoadersStore((state) => state.isSearchLoading);
 
 	const { category_id: CATEGORY_ID } = useGetCurrentCategoryId();
@@ -142,8 +144,9 @@ const Dashboard = () => {
 		hasNextPage: searchHasNextPage,
 	} = useSearchBookmarks();
 
-	// Determine if we're currently searching
-	const isSearching = !isEmpty(searchText);
+	// Determine if we're currently searching (use debounced to match when query runs)
+	const isSearching = !isEmpty(debouncedSearchText);
+	const isDiscoverPage = categorySlug === DISCOVER_URL;
 
 	const { sharedCategoriesData } = useFetchSharedCategories();
 
@@ -333,24 +336,22 @@ const Dashboard = () => {
 				return existingViewData;
 			};
 
-			if (currentCategory) {
+			if (currentCategory && typeof CATEGORY_ID === "number") {
 				// for a collection
 				if (isUserTheCategoryOwner) {
 					// if user is the collection owner
-					void mutationApiCall(
-						updateCategoryOptimisticMutation.mutateAsync({
-							category_id: CATEGORY_ID,
-							updateData: {
-								category_views: {
-									...currentCategory?.category_views,
-									cardContentViewArray: cardContentViewLogic(
-										currentCategory?.category_views?.cardContentViewArray,
-									),
-									[updateValue]: value,
-								},
+					updateCategoryOptimisticMutation.mutate({
+						category_id: CATEGORY_ID,
+						updateData: {
+							category_views: {
+								...currentCategory.category_views,
+								cardContentViewArray: cardContentViewLogic(
+									currentCategory.category_views.cardContentViewArray,
+								),
+								[updateValue]: value,
 							},
-						}),
-					);
+						},
+					});
 				} else {
 					// if user is not the collection owner
 					const sharedCategoriesId = find(
@@ -663,8 +664,8 @@ const Dashboard = () => {
 		if (!isInNotFoundPage) {
 			// eslint-disable-next-line @typescript-eslint/switch-exhaustiveness-check
 			switch (categorySlug) {
-				case SETTINGS_URL:
-					return <Settings />;
+				case DISCOVER_URL:
+					return <DiscoverBookmarkCards />;
 				case IMAGES_URL:
 					return renderAllBookmarkCards();
 				case VIDEOS_URL:
@@ -690,15 +691,20 @@ const Dashboard = () => {
 		void addBookmarkLogic(finalUrl);
 	};
 
-	if (isNil(session)) {
+	// Handle unsupported actions for discover page
+	const handleUnsupported = () => {
+		errorToast("This action is not available on Discover.");
+	};
+
+	if (isNil(session) && !isDiscoverPage) {
 		return <div />;
 	}
 
 	return (
 		<>
 			<DashboardLayout
-				categoryId={CATEGORY_ID}
-				onAddBookmark={onAddBookmark}
+				categoryId={isDiscoverPage ? DISCOVER_URL : CATEGORY_ID}
+				onAddBookmark={isDiscoverPage ? handleUnsupported : onAddBookmark}
 				onClearTrash={() => {
 					void mutationApiCall(clearBookmarksInTrashMutation.mutateAsync());
 				}}
@@ -709,7 +715,7 @@ const Dashboard = () => {
 				setBookmarksView={(value, type) => {
 					bookmarksViewApiLogic(value, type);
 				}}
-				uploadFileFromAddDropdown={onDrop}
+				uploadFileFromAddDropdown={isDiscoverPage ? handleUnsupported : onDrop}
 				userId={session?.user?.id ?? ""}
 			>
 				{renderMainPaneContent()}
diff --git a/src/pageComponents/dashboard/share/shareContent.tsx b/src/pageComponents/dashboard/share/shareContent.tsx
index 0ab09cc9..46c95f61 100644
--- a/src/pageComponents/dashboard/share/shareContent.tsx
+++ b/src/pageComponents/dashboard/share/shareContent.tsx
@@ -6,7 +6,7 @@ import classNames from "classnames";
 import { find, isEmpty, isNull } from "lodash";
 import { useForm, type SubmitHandler } from "react-hook-form";
 
-import useUpdateCategoryOptimisticMutation from "../../../async/mutationHooks/category/useUpdateCategoryOptimisticMutation";
+import { useUpdateCategoryOptimisticMutation } from "../../../async/mutationHooks/category/use-update-category-optimistic-mutation";
 import useDeleteSharedCategoriesUserMutation from "../../../async/mutationHooks/share/useDeleteSharedCategoriesUserMutation";
 import useSendCollaborationEmailInviteMutation from "../../../async/mutationHooks/share/useSendCollaborationEmailInviteMutation";
 import useUpdateSharedCategoriesUserAccessMutation from "../../../async/mutationHooks/share/useUpdateSharedCategoriesUserAccessMutation";
@@ -78,7 +78,7 @@ const AccessUserInfo = (props: {
 			if (isLoggedinUserTheOwner) {
 				return (
 					<AriaSelect
-						defaultValue={item.edit_access ? "Can Edit" : "Can View"}
+						defaultValue={item.edit_access ? "Editor" : "Viewer"}
 						onOptionClick={async (value) => {
 							if (value !== "No Access") {
 								const response = (await mutationApiCall(
@@ -86,7 +86,7 @@ const AccessUserInfo = (props: {
 										id: item.share_id as number,
 										updateData: {
 											edit_access: Boolean(
-												Number.parseInt(value === "Can Edit" ? "1" : "0", 10),
+												Number.parseInt(value === "Editor" ? "1" : "0", 10),
 											),
 										},
 									}),
@@ -104,14 +104,14 @@ const AccessUserInfo = (props: {
 							}
 						}}
 						options={[
-							{ label: "Can Edit", value: "Can Edit" },
-							{ label: "Can View", value: "Can View" },
+							{ label: "Editor", value: "Editor" },
+							{ label: "Viewer", value: "Viewer" },
 							{ label: "No Access", value: "No Access" },
 						]}
 						renderCustomSelectButton={() => (
 							<div className="flex items-center">
 								<p className="mr-1 text-gray-800">
-									{item.edit_access ? "Can Edit" : "Can View"}
+									{item.edit_access ? "Editor" : "Viewer"}
 								</p>
 								<figure>
 									<DownArrowGray />
@@ -123,7 +123,7 @@ const AccessUserInfo = (props: {
 			} else {
 				return (
 					<div className={rightTextStyles}>
-						{item.edit_access ? "Can Edit" : "Can View"}
+						{item.edit_access ? "Editor" : "Viewer"}
 					</div>
 				);
 			}
@@ -366,16 +366,24 @@ const ShareContent = (props: ShareContentProps) => {
 							defaultValue={
 								currentCategory?.is_public ? "View access" : "No access"
 							}
-							onOptionClick={async (value) => {
-								await mutationApiCall(
-									updateCategoryOptimisticMutation.mutateAsync({
+							onOptionClick={(value) => {
+								if (typeof dynamicCategoryId !== "number") {
+									return;
+								}
+
+								updateCategoryOptimisticMutation.mutate(
+									{
 										category_id: dynamicCategoryId,
 										updateData: {
 											is_public: value === "View access",
 										},
-									}),
+									},
+									{
+										onSuccess: () => {
+											setLinkCopied(false);
+										},
+									},
 								);
-								setLinkCopied(false);
 							}}
 							options={[
 								{ label: "View access", value: "View access" },
diff --git a/src/pageComponents/dashboard/sidePane/collectionsList.tsx b/src/pageComponents/dashboard/sidePane/collectionsList.tsx
index 3646183b..4d20ce2a 100644
--- a/src/pageComponents/dashboard/sidePane/collectionsList.tsx
+++ b/src/pageComponents/dashboard/sidePane/collectionsList.tsx
@@ -34,7 +34,6 @@ import {
 	type ListState,
 } from "react-stately";
 
-import useAddCategoryOptimisticMutation from "../../../async/mutationHooks/category/useAddCategoryOptimisticMutation";
 import useUpdateCategoryOrderOptimisticMutation from "../../../async/mutationHooks/category/useUpdateCategoryOrderOptimisticMutation";
 import useFetchPaginatedBookmarks from "../../../async/queryHooks/bookmarks/useFetchPaginatedBookmarks";
 import useSearchBookmarks from "../../../async/queryHooks/bookmarks/useSearchBookmarks";
@@ -68,6 +67,8 @@ import {
 import {
 	BOOKMARKS_COUNT_KEY,
 	CATEGORIES_KEY,
+	MAX_TAG_COLLECTION_NAME_LENGTH,
+	MIN_TAG_COLLECTION_NAME_LENGTH,
 	SHARED_CATEGORIES_TABLE_NAME,
 	USER_PROFILE,
 } from "../../../utils/constants";
@@ -77,12 +78,11 @@ import { CollectionsListSkeleton } from "./collectionLIstSkeleton";
 import SingleListItemComponent, {
 	type CollectionItemTypes,
 } from "./singleListItemComponent";
-import { useAddCategoryToBookmarkMutation } from "@/async/mutationHooks/category/use-add-category-to-bookmark-mutation";
+import { useAddCategoryOptimisticMutation } from "@/async/mutationHooks/category/use-add-category-optimistic-mutation";
+import { useAddCategoryToBookmarkOptimisticMutation } from "@/async/mutationHooks/category/use-add-category-to-bookmark-optimistic-mutation";
+import { tagCategoryNameSchema } from "@/lib/validation/tag-category-schema";
+import { handleClientError } from "@/utils/error-utils/client";
 
-// interface OnReorderPayloadTypes {
-//   target: { key: string };
-//   keys: Set<unknown>;
-// }
 type ListBoxDropTypes = ListProps<object> & {
 	getItems?: (keys: Set<Key>) => DragItem[];
 	// eslint-disable-next-line @typescript-eslint/no-explicit-any
@@ -302,7 +302,8 @@ const CollectionsList = () => {
 		useState(false);
 
 	const { addCategoryOptimisticMutation } = useAddCategoryOptimisticMutation();
-	const { addCategoryToBookmarkMutation } = useAddCategoryToBookmarkMutation();
+	const { addCategoryToBookmarkOptimisticMutation } =
+		useAddCategoryToBookmarkOptimisticMutation();
 	const { updateCategoryOrderMutation } =
 		useUpdateCategoryOrderOptimisticMutation();
 	const { allCategories, isLoadingCategories } = useFetchCategories();
@@ -373,17 +374,30 @@ const CollectionsList = () => {
 	};
 
 	const handleAddNewCategory = async (newCategoryName: string) => {
-		if (!isNull(userProfileData?.data)) {
-			const response = (await mutationApiCall(
-				addCategoryOptimisticMutation.mutateAsync({
-					name: newCategoryName,
-					category_order: userProfileData?.data[0]?.category_order ?? [],
-				}),
-			)) as { data: CategoriesData[] };
+		const result = tagCategoryNameSchema.safeParse(newCategoryName);
 
-			if (!isEmpty(response?.data)) {
-				void router.push(`/${response?.data[0]?.category_slug}`);
-			}
+		if (!result.success) {
+			handleClientError(
+				new Error(result.error.issues[0]?.message ?? "Invalid collection name"),
+				`Collection name must be between ${MIN_TAG_COLLECTION_NAME_LENGTH} and ${MAX_TAG_COLLECTION_NAME_LENGTH} characters`,
+			);
+			return;
+		}
+
+		if (!isNull(userProfileData.data)) {
+			addCategoryOptimisticMutation.mutate(
+				{
+					name: result.data,
+					category_order: (
+						userProfileData.data[0]?.category_order ?? []
+					).filter((id): id is number => id !== null),
+				},
+				{
+					onSuccess: (data) => {
+						void router.push(`/${data[0].category_slug}`);
+					},
+				},
+			);
 		}
 	};
 
@@ -428,7 +442,7 @@ const CollectionsList = () => {
 						return;
 					}
 
-					addCategoryToBookmarkMutation.mutate({
+					addCategoryToBookmarkOptimisticMutation.mutate({
 						category_id: categoryId,
 						bookmark_id: Number.parseInt(bookmarkId, 10),
 					});
@@ -558,22 +572,21 @@ const CollectionsList = () => {
 					className="bg-black/[0.004]! text-sm! leading-4! font-450! text-plain-reverse! opacity-40! placeholder:text-plain-reverse focus:ring-0! focus:ring-offset-0! focus:outline-hidden!"
 					id="add-category-input"
 					onBlur={(event) => {
-						if (!isEmpty(event?.target?.value)) {
-							void handleAddNewCategory(
-								(event.target as HTMLInputElement).value,
-							);
+						const inputValue = (event.target as HTMLInputElement)?.value;
+						if (inputValue) {
+							void handleAddNewCategory(inputValue);
 						}
 
 						setShowAddCategoryInput(false);
 					}}
 					onKeyUp={(event) => {
-						if (
-							event.key === "Enter" &&
-							!isEmpty((event.target as HTMLInputElement).value)
-						) {
-							void handleAddNewCategory(
-								(event.target as HTMLInputElement).value,
-							);
+						if (event.key === "Enter") {
+							const inputValue = (event.target as HTMLInputElement)?.value;
+
+							if (inputValue) {
+								void handleAddNewCategory(inputValue);
+							}
+
 							setShowAddCategoryInput(false);
 						}
 					}}
@@ -657,9 +670,9 @@ const CollectionsList = () => {
 										onCategoryOptionClick={handleCategoryOptionClick}
 										showDropdown
 										showSpinner={
-											addCategoryToBookmarkMutation.isPending &&
-											addCategoryToBookmarkMutation.variables?.category_id ===
-												item?.id
+											addCategoryToBookmarkOptimisticMutation.isPending &&
+											addCategoryToBookmarkOptimisticMutation.variables
+												?.category_id === item?.id
 										}
 									/>
 								</Item>
diff --git a/src/pageComponents/dashboard/sidePane/sidePaneOptionsMenu.tsx b/src/pageComponents/dashboard/sidePane/sidePaneOptionsMenu.tsx
index 91e46111..5a7b3f6d 100644
--- a/src/pageComponents/dashboard/sidePane/sidePaneOptionsMenu.tsx
+++ b/src/pageComponents/dashboard/sidePane/sidePaneOptionsMenu.tsx
@@ -40,7 +40,8 @@ const SidePaneOptionsMenu = () => {
 			item?.name === menuListItemName.inbox ||
 			item?.name === menuListItemName.everything ||
 			item?.name === menuListItemName.trash ||
-			item?.name === menuListItemName.settings
+			item?.name === menuListItemName.settings ||
+			item?.name === menuListItemName.discover
 		) {
 			return item;
 		} else {
@@ -53,11 +54,11 @@ const SidePaneOptionsMenu = () => {
 			{optionsMenuList?.map((item) => (
 				<SingleListItemComponent
 					extendedClassname="py-[7px]"
-					isLink={item?.id !== 3}
+					isLink={item?.id !== 4}
 					item={item}
 					key={item.id}
 					onClick={() => {
-						if (item?.id === 3) {
+						if (item?.id === 4) {
 							// we clicked on settings
 							toggleShowSettingsModal();
 						}
diff --git a/src/pageComponents/dashboard/sidePane/singleListItemComponent.tsx b/src/pageComponents/dashboard/sidePane/singleListItemComponent.tsx
index 285d55cb..3abbce88 100644
--- a/src/pageComponents/dashboard/sidePane/singleListItemComponent.tsx
+++ b/src/pageComponents/dashboard/sidePane/singleListItemComponent.tsx
@@ -166,7 +166,7 @@ const SingleListItemComponent = (listProps: listPropsTypes) => {
 										))}
 									</>
 								) : (
-									<div className="rounded-lg bg-gray-50">
+									<div className="w-75 rounded-lg bg-gray-50">
 										<ShareContent categoryId={item?.id} />
 									</div>
 								)}
diff --git a/src/pages/api/bookmark/search-bookmarks.ts b/src/pages/api/bookmark/search-bookmarks.ts
index 3aa82d20..7359dc97 100644
--- a/src/pages/api/bookmark/search-bookmarks.ts
+++ b/src/pages/api/bookmark/search-bookmarks.ts
@@ -8,6 +8,7 @@ import { z } from "zod";
 import { type SingleListData } from "../../../types/apiTypes";
 import {
 	bookmarkType,
+	DISCOVER_URL,
 	documentFileTypes,
 	DOCUMENTS_URL,
 	GET_HASHTAG_TAG_PATTERN,
@@ -64,20 +65,29 @@ export default async function handler(
 
 		const supabase = apiSupabaseClient(request, response);
 
-		const { data: userData, error: userError } = await supabase.auth.getUser();
-		const user_id = userData?.user?.id;
-		const email = userData?.user?.email as string;
+		const { search, category_id } = parseResult.data;
 
-		if (userError || !user_id) {
-			console.warn("[search-bookmarks] Missing user_id from Supabase auth");
-			response.status(401).json({
-				data: null,
-				error: { message: "Unauthorized" },
-			});
-			return;
-		}
+		const isDiscoverPage = category_id === DISCOVER_URL;
 
-		const { search, category_id } = parseResult.data;
+		// Discover page doesn't require authentication
+		let user_id: string | undefined;
+		let email: string | undefined;
+
+		if (!isDiscoverPage) {
+			const { data: userData, error: userError } =
+				await supabase.auth.getUser();
+			user_id = userData?.user?.id;
+			email = userData?.user?.email as string;
+
+			if (userError || !user_id) {
+				console.warn("[search-bookmarks] Missing user_id from Supabase auth");
+				response.status(401).json({
+					data: null,
+					error: { message: "Unauthorized" },
+				});
+				return;
+			}
+		}
 
 		const offset = Number.parseInt(request.query.offset as string, 10) || 0;
 		const limit = PAGINATION_LIMIT;
@@ -124,95 +134,101 @@ export default async function handler(
 				search_text: searchText,
 				url_scope: urlScope,
 				tag_scope: tagName,
-				category_scope: categoryScope,
+				category_scope: isDiscoverPage ? null : categoryScope,
 			})
 			.eq("trash", category_id === TRASH_URL)
 			.range(offset, offset + limit);
 
-		if (!userInCollections) {
-			// if user is not in any category, then get only the items that match the user_id
-			query = query.eq("user_id", user_id);
-		}
+		if (isDiscoverPage) {
+			query = query.not("make_discoverable", "is", null);
+		} else {
+			const userId = user_id as string;
+			const userEmail = email as string;
 
-		if (userInCollections) {
-			// check if user is a collaborator for the category
-			const {
-				success: isUserCollaboratorInCategorySuccess,
-				isCollaborator: isUserCollaboratorInCategoryValue,
-				error: isUserCollaboratorInCategoryError,
-			} = await isUserCollaboratorInCategory(
-				supabase,
-				category_id as string,
-				email,
-			);
-
-			if (!isUserCollaboratorInCategorySuccess) {
-				console.error(
-					"[search-bookmarks] Error checking if user is a collaborator for the category:",
-					isUserCollaboratorInCategoryError,
-				);
-				Sentry.captureException(isUserCollaboratorInCategoryError, {
-					tags: {
-						operation: "check_user_collaborator_of_category",
-					},
-					extra: { category_id },
-					user: {
-						id: user_id,
-						email,
-					},
-				});
-				response.status(500).json({
-					data: null,
-					error: {
-						message:
-							"Error checking if user is a collaborator for the category",
-					},
-				});
-				return;
+			if (!userInCollections) {
+				query = query.eq("user_id", userId);
 			}
 
-			// check if user is the owner of the category
-			const {
-				success: isUserOwnerOfCategorySuccess,
-				isOwner: isUserOwnerOfCategory,
-				error: isUserOwnerOfCategoryError,
-			} = await checkIsUserOwnerOfCategory(
-				supabase,
-				category_id as string,
-				user_id,
-			);
-
-			if (!isUserOwnerOfCategorySuccess) {
-				console.error(
-					"[search-bookmarks] Error checking if user is the owner of the category:",
-					isUserOwnerOfCategoryError,
+			if (userInCollections) {
+				// check if user is a collaborator for the category
+				const {
+					success: isUserCollaboratorInCategorySuccess,
+					isCollaborator: isUserCollaboratorInCategoryValue,
+					error: isUserCollaboratorInCategoryError,
+				} = await isUserCollaboratorInCategory(
+					supabase,
+					category_id as string,
+					userEmail,
 				);
-				Sentry.captureException(isUserOwnerOfCategoryError, {
-					tags: {
-						operation: "check_user_owner_of_category",
-					},
-					extra: { category_id },
-					user: {
-						id: user_id,
-						email,
-					},
-				});
-				response.status(500).json({
-					data: null,
-					error: {
-						message: "Error checking if user is the owner of the category",
-					},
-				});
-				return;
-			}
 
-			// check if user is not a collaborator or the owner of the category
-			const is_user_not_collaborator_or_owner =
-				!isUserCollaboratorInCategoryValue && !isUserOwnerOfCategory;
+				if (!isUserCollaboratorInCategorySuccess) {
+					console.error(
+						"[search-bookmarks] Error checking if user is a collaborator for the category:",
+						isUserCollaboratorInCategoryError,
+					);
+					Sentry.captureException(isUserCollaboratorInCategoryError, {
+						tags: {
+							operation: "check_user_collaborator_of_category",
+						},
+						extra: { category_id },
+						user: {
+							id: userId,
+							email: userEmail,
+						},
+					});
+					response.status(500).json({
+						data: null,
+						error: {
+							message:
+								"Error checking if user is a collaborator for the category",
+						},
+					});
+					return;
+				}
+
+				// check if user is the owner of the category
+				const {
+					success: isUserOwnerOfCategorySuccess,
+					isOwner: isUserOwnerOfCategory,
+					error: isUserOwnerOfCategoryError,
+				} = await checkIsUserOwnerOfCategory(
+					supabase,
+					category_id as string,
+					userId,
+				);
 
-			if (is_user_not_collaborator_or_owner) {
-				// if user is not a collaborator or the owner of the category, then get only the items that match the user_id and category_id
-				query = query.eq("user_id", user_id);
+				if (!isUserOwnerOfCategorySuccess) {
+					console.error(
+						"[search-bookmarks] Error checking if user is the owner of the category:",
+						isUserOwnerOfCategoryError,
+					);
+					Sentry.captureException(isUserOwnerOfCategoryError, {
+						tags: {
+							operation: "check_user_owner_of_category",
+						},
+						extra: { category_id },
+						user: {
+							id: userId,
+							email: userEmail,
+						},
+					});
+					response.status(500).json({
+						data: null,
+						error: {
+							message: "Error checking if user is the owner of the category",
+						},
+					});
+					return;
+				}
+
+				// check if user is not a collaborator or the owner of the category
+				const is_user_not_collaborator_or_owner =
+					!isUserCollaboratorInCategoryValue && !isUserOwnerOfCategory;
+
+				if (is_user_not_collaborator_or_owner) {
+					// if user is not a collaborator or the owner of the category, then get only the items that match the user_id and category_id
+					query = query.eq("user_id", userId);
+				}
 			}
 		}
 
@@ -252,7 +268,7 @@ export default async function handler(
 			Sentry.captureException(error, {
 				tags: {
 					operation: "search_bookmarks",
-					userId: user_id,
+					userId: user_id ?? "discover_page",
 				},
 				extra: { category_id, rawSearch: search },
 			});
diff --git a/src/pages/api/category/create-user-category.ts b/src/pages/api/category/create-user-category.ts
deleted file mode 100644
index 6d794b6f..00000000
--- a/src/pages/api/category/create-user-category.ts
+++ /dev/null
@@ -1,210 +0,0 @@
-// Next.js API route support: https://nextjs.org/docs/api-routes/introduction
-
-import { type NextApiResponse } from "next";
-import * as Sentry from "@sentry/nextjs";
-import {
-	type PostgrestError,
-	type PostgrestResponse,
-} from "@supabase/supabase-js";
-import { type VerifyErrors } from "jsonwebtoken";
-import { isEmpty } from "lodash";
-import isNull from "lodash/isNull";
-import slugify from "slugify";
-import uniqid from "uniqid";
-
-import {
-	type AddUserCategoryApiPayload,
-	type CategoriesData,
-	type NextApiRequest,
-} from "../../../types/apiTypes";
-import {
-	CATEGORIES_TABLE_NAME,
-	DUPLICATE_CATEGORY_NAME_ERROR,
-	PROFILES,
-} from "../../../utils/constants";
-import {
-	apiSupabaseClient,
-	getApiSupabaseUser,
-} from "../../../utils/supabaseServerClient";
-
-type Data = {
-	data: CategoriesData[] | null;
-	error: PostgrestError | VerifyErrors | { message: string } | null;
-};
-
-/**
- * Creates category for a user
- */
-export default async function handler(
-	request: NextApiRequest<AddUserCategoryApiPayload>,
-	response: NextApiResponse<Data>,
-) {
-	try {
-		const supabase = apiSupabaseClient(request, response);
-
-		// Check for auth errors
-		const { data: userData, error: userError } = await getApiSupabaseUser(
-			request,
-			supabase,
-		);
-		const userId = userData?.user?.id;
-
-		if (userError || !userId) {
-			console.warn("User authentication failed:", {
-				error: userError?.message,
-			});
-			response.status(401).json({
-				data: null,
-				error: { message: "Unauthorized" },
-			});
-			return;
-		}
-
-		const { name } = request.body;
-
-		console.log("create-user-category API called:", { userId, name });
-
-		// check if category name is already there for the user
-		const { data: matchedCategoryName, error: matchedCategoryNameError } =
-			await supabase
-				.from(CATEGORIES_TABLE_NAME)
-				.select(`category_name`)
-				.eq("user_id", userId)
-				.eq("category_name", name.trim());
-
-		console.log("Existing category check result:", {
-			matchedCategoryName,
-			hasMatch: !isEmpty(matchedCategoryName),
-		});
-
-		if (!isNull(matchedCategoryNameError)) {
-			console.error(
-				"Error checking existing category name:",
-				matchedCategoryNameError,
-			);
-			Sentry.captureException(matchedCategoryNameError, {
-				tags: {
-					operation: "check_existing_category",
-					userId,
-				},
-				extra: { categoryName: name },
-			});
-			response.status(500).json({
-				data: null,
-				error: { message: "Error checking existing category" },
-			});
-			return;
-		}
-
-		// Check for duplicate category name
-		if (!isEmpty(matchedCategoryName)) {
-			console.warn("Duplicate category name attempt:", {
-				categoryName: name,
-			});
-			response.status(500).json({
-				data: null,
-				error: { message: DUPLICATE_CATEGORY_NAME_ERROR },
-			});
-			return;
-		}
-
-		// Insert category
-		const { data, error }: PostgrestResponse<CategoriesData> = await supabase
-			.from(CATEGORIES_TABLE_NAME)
-			.insert([
-				{
-					category_name: name,
-					user_id: userId,
-					category_slug: `${slugify(name, { lower: true })}-${uniqid.time()}`,
-				},
-			])
-			.select();
-
-		if (error) {
-			console.error("Error inserting category:", error);
-			Sentry.captureException(error, {
-				tags: {
-					operation: "insert_category",
-					userId,
-					categoryName: name,
-				},
-			});
-			response.status(500).json({
-				data: null,
-				error: { message: "Error creating category" },
-			});
-			return;
-		}
-
-		// Check if data was returned
-		if (!data || isEmpty(data)) {
-			console.warn(
-				"No data returned from the database while creating category:",
-				{ data },
-			);
-			response.status(500).json({
-				data: null,
-				error: {
-					message: "No data returned from the database while creating category",
-				},
-			});
-			return;
-		}
-
-		console.log("Category insert result:", {
-			categoryId: data[0]?.id,
-			categorySlug: data[0]?.category_slug,
-		});
-
-		// Update category order if provided
-		const { category_order } = request.body;
-		if (category_order !== undefined) {
-			const order = !isNull(category_order) ? category_order : [];
-
-			console.log("Updating category order:", {
-				newCategoryId: data[0]?.id,
-			});
-
-			const { error: orderError } = await supabase
-				.from(PROFILES)
-				.update({
-					category_order: [...order, data[0]?.id],
-				})
-				.match({ id: userId }).select(`
-      id, category_order`);
-
-			if (orderError) {
-				console.error("Error updating category order:", orderError);
-				Sentry.captureException(orderError, {
-					tags: {
-						operation: "update_category_order",
-						userId,
-					},
-					extra: { categoryId: data[0]?.id },
-				});
-				response.status(500).json({
-					data: null,
-					error: { message: "Error updating category order" },
-				});
-				return;
-			}
-		}
-
-		// Success
-		console.log("Category created successfully:", {
-			categoryId: data[0]?.id,
-		});
-		response.status(200).json({ data, error: null });
-	} catch (error) {
-		console.error("Unexpected error in create-user-category:", error);
-		Sentry.captureException(error, {
-			tags: {
-				operation: "create_user_category_unexpected",
-			},
-		});
-		response.status(500).json({
-			data: null,
-			error: { message: "An unexpected error occurred" },
-		});
-	}
-}
diff --git a/src/pages/api/category/update-user-category.ts b/src/pages/api/category/update-user-category.ts
deleted file mode 100644
index 18ae924e..00000000
--- a/src/pages/api/category/update-user-category.ts
+++ /dev/null
@@ -1,154 +0,0 @@
-// Next.js API route support: https://nextjs.org/docs/api-routes/introduction
-
-import { type NextApiResponse } from "next";
-import * as Sentry from "@sentry/nextjs";
-import { type PostgrestError } from "@supabase/supabase-js";
-import { isEmpty } from "lodash";
-import isNull from "lodash/isNull";
-
-import {
-	type CategoriesData,
-	type NextApiRequest,
-	type UpdateCategoryApiPayload,
-} from "../../../types/apiTypes";
-import { CATEGORIES_TABLE_NAME } from "../../../utils/constants";
-import { apiSupabaseClient } from "../../../utils/supabaseServerClient";
-
-type DataResponse = CategoriesData[] | null;
-type ErrorResponse = PostgrestError | string | { message: string } | null;
-
-type Data = {
-	data: DataResponse;
-	error: ErrorResponse;
-};
-
-/**
- * Updates category for a user
- */
-
-export default async function handler(
-	request: NextApiRequest<UpdateCategoryApiPayload>,
-	response: NextApiResponse<Data>,
-) {
-	try {
-		const supabase = apiSupabaseClient(request, response);
-
-		// Authentication check
-		const { data: userData, error: userError } = await supabase.auth.getUser();
-		const userId = userData?.user?.id;
-
-		if (userError || !userId) {
-			console.warn("User authentication failed:", {
-				error: userError?.message,
-			});
-			response.status(401).json({ data: null, error: "Unauthorized" });
-			return;
-		}
-
-		// Entry point log
-		console.log("update-user-category API called:", {
-			userId,
-			categoryId: request.body.category_id,
-			categoryName: request.body.updateData?.category_name,
-		});
-
-		// check if category name is already there for the user, along with the category id
-		const { data: matchedCategoryName, error: matchedCategoryNameError } =
-			await supabase
-				.from(CATEGORIES_TABLE_NAME)
-				.select(`category_name`)
-				.eq("user_id", userId)
-				.eq("category_name", request?.body?.updateData?.category_name)
-				.neq("id", request.body.category_id);
-
-		if (!isNull(matchedCategoryNameError)) {
-			console.error(
-				"Database error while checking category name:",
-				matchedCategoryNameError,
-			);
-			Sentry.captureException(matchedCategoryNameError, {
-				tags: {
-					operation: "check_duplicate_category",
-					userId,
-				},
-			});
-			response.status(500).json({
-				data: null,
-				error: { message: "Database error while checking category name" },
-			});
-			return;
-		}
-
-		if (matchedCategoryName && matchedCategoryName.length > 0) {
-			console.warn("Duplicate category name attempt:", {
-				categoryName: request.body.updateData?.category_name,
-				userId,
-			});
-			response.status(409).json({
-				data: null,
-				error: { message: "Category name already exists" },
-			});
-			return;
-		}
-
-		const { data, error }: { data: DataResponse; error: ErrorResponse } =
-			await supabase
-				.from(CATEGORIES_TABLE_NAME)
-				.update(request.body.updateData)
-				.match({ id: request.body.category_id, user_id: userId })
-				.select();
-
-		if (!isNull(error)) {
-			console.error("Error updating category:", error);
-			Sentry.captureException(error, {
-				tags: {
-					operation: "update_category",
-					userId,
-				},
-				extra: {
-					categoryId: request.body.category_id,
-					updateData: request.body.updateData,
-				},
-			});
-			response.status(500).json({
-				data: null,
-				error: isEmpty(error) ? { message: "Something went wrong" } : error,
-			});
-			return;
-		}
-
-		if (isEmpty(data) || isNull(data)) {
-			console.error("Database returned empty data after update");
-			Sentry.captureException(new Error("DB data is empty after update"), {
-				tags: {
-					operation: "update_category",
-					userId,
-				},
-				extra: {
-					categoryId: request.body.category_id,
-				},
-			});
-			response
-				.status(500)
-				.json({ data: null, error: { message: "Something went wrong" } });
-			return;
-		}
-
-		console.log("Category updated successfully:", {
-			categoryId: data[0]?.id,
-			categoryName: data[0]?.category_name,
-		});
-		response.status(200).json({ data, error: null });
-	} catch (error) {
-		console.error("Unexpected error in update-user-category:", error);
-		Sentry.captureException(error, {
-			tags: {
-				operation: "update_user_category_unexpected",
-			},
-		});
-		response.status(500).json({
-			data: null,
-			error: { message: "An unexpected error occurred" },
-		});
-	}
-}
diff --git a/src/pages/api/tags/add-tag-to-bookmark.ts b/src/pages/api/tags/add-tag-to-bookmark.ts
deleted file mode 100644
index a4f1af4c..00000000
--- a/src/pages/api/tags/add-tag-to-bookmark.ts
+++ /dev/null
@@ -1,118 +0,0 @@
-// Next.js API route support: https://nextjs.org/docs/api-routes/introduction
-
-import { type NextApiResponse } from "next";
-import * as Sentry from "@sentry/nextjs";
-import {
-	type PostgrestError,
-	type SupabaseClient,
-} from "@supabase/supabase-js";
-import { type VerifyErrors } from "jsonwebtoken";
-import isNull from "lodash/isNull";
-
-import {
-	type BookmarksTagData,
-	type NextApiRequest,
-	type SingleListData,
-	type UserTagsData,
-} from "../../../types/apiTypes";
-import {
-	BOOKMARK_TAGS_TABLE_NAME,
-	MAIN_TABLE_NAME,
-	TAG_TABLE_NAME,
-} from "../../../utils/constants";
-import { apiSupabaseClient } from "../../../utils/supabaseServerClient";
-
-// this api adds tags to a bookmark
-
-type DataResponse = UserTagsData[] | null;
-type ErrorResponse = PostgrestError | VerifyErrors | string | null;
-
-type Data = {
-	data: DataResponse;
-	error: ErrorResponse;
-};
-
-// checks if the tag and bookmark is created by user
-export const bookmarkAndTagOwnershipCheck = async (
-	userId: SingleListData["user_id"]["id"],
-	bookmark_id: SingleListData["id"],
-	tag_id: UserTagsData["id"],
-	supabase: SupabaseClient,
-	response: NextApiResponse<Data>,
-) => {
-	const { data: bookmarksData, error: bookmarkError } = await supabase
-		.from(MAIN_TABLE_NAME)
-		.select("user_id")
-		.eq("id", bookmark_id);
-
-	if (bookmarkError) {
-		response.status(500).json({ data: null, error: bookmarkError?.message });
-
-		Sentry.captureException(
-			`bookmark owner check error ${bookmarkError?.message}`,
-		);
-		return;
-	}
-
-	if (bookmarksData?.[0]?.user_id !== userId) {
-		response
-			.status(500)
-			.json({ data: null, error: "User is not the owner of item" });
-		return;
-	}
-
-	const { data: tagData, error: tagError } = await supabase
-		.from(TAG_TABLE_NAME)
-		.select("user_id")
-		.eq("id", tag_id);
-
-	if (tagError) {
-		response.status(500).json({ data: null, error: tagError?.message });
-
-		Sentry.captureException(`tag owner check error ${tagError?.message}`);
-		return;
-	}
-
-	if (tagData?.[0]?.user_id !== userId) {
-		response
-			.status(500)
-			.json({ data: null, error: "User is not the owner of tag" });
-	}
-};
-
-export default async function handler(
-	request: NextApiRequest<{
-		data: {
-			bookmark_id: SingleListData["id"];
-			tag_id: BookmarksTagData["id"];
-		};
-	}>,
-	response: NextApiResponse<Data>,
-) {
-	const supabase = apiSupabaseClient(request, response);
-
-	const userId = (await supabase?.auth?.getUser())?.data?.user?.id as string;
-
-	await bookmarkAndTagOwnershipCheck(
-		userId,
-		request?.body?.data?.bookmark_id,
-		request?.body?.data?.tag_id as number,
-		supabase,
-		response,
-	);
-
-	const { data, error }: { data: DataResponse; error: ErrorResponse } =
-		await supabase
-			.from(BOOKMARK_TAGS_TABLE_NAME)
-			.insert({
-				...request.body.data,
-				user_id: userId,
-			})
-			.select();
-
-	if (isNull(error)) {
-		response.status(200).json({ data, error: null });
-	} else {
-		response.status(500).json({ data: null, error });
-	}
-}
diff --git a/src/pages/api/tags/create-user-tags.ts b/src/pages/api/tags/create-user-tags.ts
deleted file mode 100644
index 8a886522..00000000
--- a/src/pages/api/tags/create-user-tags.ts
+++ /dev/null
@@ -1,72 +0,0 @@
-// Next.js API route support: https://nextjs.org/docs/api-routes/introduction
-
-import { type NextApiResponse } from "next";
-import * as Sentry from "@sentry/nextjs";
-import { type PostgrestError } from "@supabase/supabase-js";
-import { type VerifyErrors } from "jsonwebtoken";
-import isNull from "lodash/isNull";
-
-import {
-	type NextApiRequest,
-	type UserTagsData,
-} from "../../../types/apiTypes";
-import {
-	MAX_TAG_NAME_LENGTH,
-	MIN_TAG_NAME_LENGTH,
-	TAG_TABLE_NAME,
-} from "../../../utils/constants";
-import { apiSupabaseClient } from "../../../utils/supabaseServerClient";
-
-type DataResponse = UserTagsData[] | null;
-type ErrorResponse = PostgrestError | VerifyErrors | string | null;
-
-type Data = {
-	data: DataResponse;
-	error: ErrorResponse;
-};
-
-// Creates tags for a specific user
-
-export default async function handler(
-	request: NextApiRequest<{
-		name: string;
-	}>,
-	response: NextApiResponse<Data>,
-) {
-	const supabase = apiSupabaseClient(request, response);
-
-	const userId = (await supabase?.auth?.getUser())?.data?.user?.id as string;
-	const rawName = request?.body?.name;
-	const trimmedName =
-		typeof rawName === "string" ? rawName.trim() : ("" as string);
-
-	if (
-		typeof rawName !== "string" ||
-		trimmedName.length < MIN_TAG_NAME_LENGTH ||
-		trimmedName.length > MAX_TAG_NAME_LENGTH
-	) {
-		response.status(400).json({
-			data: null,
-			error: `Tag name must be between ${MIN_TAG_NAME_LENGTH} and ${MAX_TAG_NAME_LENGTH} characters`,
-		});
-		return;
-	}
-
-	const { data, error }: { data: DataResponse; error: ErrorResponse } =
-		await supabase
-			.from(TAG_TABLE_NAME)
-			.insert([
-				{
-					name: trimmedName,
-					user_id: userId,
-				},
-			])
-			.select();
-
-	if (isNull(error)) {
-		response.status(200).json({ data, error: null });
-	} else {
-		response.status(500).json({ data: null, error });
-		Sentry.captureException(`create tag error : ${error?.message}`);
-	}
-}
diff --git a/src/pages/api/tags/remove-tag-from-bookmark.ts b/src/pages/api/tags/remove-tag-from-bookmark.ts
deleted file mode 100644
index c42c2d53..00000000
--- a/src/pages/api/tags/remove-tag-from-bookmark.ts
+++ /dev/null
@@ -1,67 +0,0 @@
-// Next.js API route support: https://nextjs.org/docs/api-routes/introduction
-
-import { type NextApiResponse } from "next";
-import { type PostgrestError } from "@supabase/supabase-js";
-import isEmpty from "lodash/isEmpty";
-import isNull from "lodash/isNull";
-
-import {
-	type NextApiRequest,
-	type UserTagsData,
-} from "../../../types/apiTypes";
-import { BOOKMARK_TAGS_TABLE_NAME } from "../../../utils/constants";
-import { apiSupabaseClient } from "../../../utils/supabaseServerClient";
-
-import { bookmarkAndTagOwnershipCheck } from "./add-tag-to-bookmark";
-
-// removes tags for a bookmark
-
-type DataResponse = UserTagsData[] | null;
-type ErrorResponse = PostgrestError | string | { message: string } | null;
-
-type Data = {
-	data: DataResponse;
-	error: ErrorResponse;
-};
-
-export default async function handler(
-	request: NextApiRequest<{ bookmark_id: number; tag_id: number }>,
-	response: NextApiResponse<Data>,
-) {
-	const supabase = apiSupabaseClient(request, response);
-
-	const userId = (await supabase?.auth?.getUser())?.data?.user?.id as string;
-
-	await bookmarkAndTagOwnershipCheck(
-		userId,
-		request?.body?.bookmark_id,
-		request?.body?.tag_id,
-		supabase,
-		response,
-	);
-
-	const { data, error }: { data: DataResponse; error: ErrorResponse } =
-		await supabase
-			.from(BOOKMARK_TAGS_TABLE_NAME)
-			.delete()
-			.match({
-				tag_id: request.body?.tag_id,
-				bookmark_id: request.body?.bookmark_id,
-				user_id: userId,
-			})
-			.select();
-
-	if (isEmpty(data)) {
-		response
-			.status(500)
-			.json({ data: null, error: { message: "Something went wrong" } });
-		throw new Error("ERROR");
-	}
-
-	if (isNull(error)) {
-		response.status(200).json({ data, error: null });
-	} else {
-		response.status(500).json({ data: null, error });
-		throw new Error("ERROR");
-	}
-}
diff --git a/src/pages/api/v1/ai-enrichment.ts b/src/pages/api/v1/ai-enrichment.ts
index 55999d0d..141e8dfb 100644
--- a/src/pages/api/v1/ai-enrichment.ts
+++ b/src/pages/api/v1/ai-enrichment.ts
@@ -1,12 +1,15 @@
-/* eslint-disable @typescript-eslint/no-explicit-any */
 import { type NextApiRequest, type NextApiResponse } from "next";
-import axios from "axios";
+import * as Sentry from "@sentry/nextjs";
 import { z } from "zod";
 
-import imageToText from "../../../async/ai/imageToText";
-import ocr from "../../../async/ai/ocr";
-import { MAIN_TABLE_NAME } from "../../../utils/constants";
-import { blurhashFromURL } from "../../../utils/getBlurHash";
+import {
+	IMAGE_DOWNLOAD_TIMEOUT_MS,
+	MAIN_TABLE_NAME,
+} from "../../../utils/constants";
+import {
+	enrichMetadata,
+	validateTwitterMediaUrl,
+} from "../../../utils/helpers.server";
 import { createServiceClient } from "../../../utils/supabaseClient";
 import { upload } from "../bookmark/add-remaining-bookmark-data";
 
@@ -16,20 +19,34 @@ const requestBodySchema = z.object({
 	user_id: z.uuid({ message: "user_id must be a valid UUID" }),
 	url: z.url({ message: "url must be a valid URL" }),
 	isRaindropBookmark: z.boolean().optional().default(false),
+	isTwitterBookmark: z.boolean().optional().default(false),
 	message: z.object({
 		msg_id: z.number(),
 		message: z.object({
-			meta_data: z.record(z.string(), z.any()).optional().default({}),
+			meta_data: z.object({
+				twitter_avatar_url: z.string().optional(),
+				instagram_username: z.string().max(30).optional(),
+				instagram_profile_pic: z.string().nullable().optional(),
+				favIcon: z.string(),
+				video_url: z.string().nullable().optional(),
+				saved_collection_names: z
+					.array(z.string().max(255))
+					.max(100)
+					.optional(),
+			}),
 		}),
 	}),
 	queue_name: z.string().min(1, { message: "queue_name is required" }),
 });
 
+const ROUTE = "ai-enrichment";
+
 export default async function handler(
 	request: NextApiRequest,
 	response: NextApiResponse,
 ) {
 	if (request.method !== "POST") {
+		console.warn(`[${ROUTE}] Method not allowed:`, { method: request.method });
 		response.status(405).json({ error: "Method not allowed" });
 		return;
 	}
@@ -38,7 +55,7 @@ export default async function handler(
 		const parseResult = requestBodySchema.safeParse(request.body);
 
 		if (!parseResult.success) {
-			console.warn("Validation error:", parseResult.error.issues);
+			console.warn(`[${ROUTE}] Validation error:`, parseResult.error.issues);
 			response.status(400).json({
 				error: "Validation failed",
 			});
@@ -46,77 +63,154 @@ export default async function handler(
 		}
 
 		const {
+			id,
 			ogImage: ogImageUrl,
 			user_id,
 			url,
 			isRaindropBookmark,
+			isTwitterBookmark,
 			message,
 			queue_name,
 		} = parseResult.data;
 
+		if (isTwitterBookmark) {
+			try {
+				// Validate ogImage URL
+				validateTwitterMediaUrl(ogImageUrl);
+				console.log(`[${ROUTE}] ogImage URL validated:`, { ogImageUrl });
+
+				// Validate video URL if present
+				if (message.message.meta_data?.video_url) {
+					validateTwitterMediaUrl(message.message.meta_data.video_url);
+					console.log(`[${ROUTE}] Video URL validated`);
+				}
+			} catch (validationError) {
+				console.error(`[${ROUTE}] URL validation failed:`, {
+					error: validationError,
+					ogImageUrl,
+					videoUrl: message.message.meta_data?.video_url,
+				});
+				Sentry.captureException(validationError, {
+					tags: {
+						operation: "url_validation_failed",
+						userId: user_id,
+					},
+					extra: {
+						bookmarkId: id,
+						url,
+						ogImageUrl,
+						videoUrl: message.message.meta_data?.video_url,
+					},
+				});
+				response.status(400).json({
+					error:
+						validationError instanceof Error
+							? validationError.message
+							: "URL validation failed",
+				});
+				return;
+			}
+		}
+
+		console.log(`[${ROUTE}] API called:`, {
+			bookmarkId: id,
+			userId: user_id,
+			url,
+			isRaindropBookmark,
+			isTwitterBookmark,
+			queueName: queue_name,
+			messageId: message.msg_id,
+		});
+
 		const supabase = createServiceClient();
 		let ogImage = ogImageUrl;
-		let isFailed = false;
 
-		// If from Raindrop bookmark — upload image into R2
+		// If from Raindrop bookmark — upload ogImage into R2
 		if (isRaindropBookmark) {
-			const image = await axios.get(ogImage, {
-				responseType: "arraybuffer",
-				headers: {
-					"User-Agent": "Mozilla/5.0",
-					Accept: "image/*,*/*;q=0.8",
-				},
-				timeout: 10_000,
-			});
+			console.log(`[${ROUTE}] Uploading Raindrop image to R2:`, { url });
+			try {
+				const imageResponse = await fetch(ogImage, {
+					headers: {
+						"User-Agent": "Mozilla/5.0",
+						Accept: "image/*,*/*;q=0.8",
+					},
+					signal: AbortSignal.timeout(IMAGE_DOWNLOAD_TIMEOUT_MS),
+				});
 
-			const returnedB64 = Buffer.from(image.data).toString("base64");
-			ogImage = (await upload(returnedB64, user_id, null)) || ogImageUrl;
-		}
+				if (!imageResponse.ok) {
+					throw new Error(`HTTP error! status: ${imageResponse.status}`);
+				}
 
-		const newMeta: any = { ...message.message.meta_data };
+				const arrayBuffer = await imageResponse.arrayBuffer();
+				const returnedB64 = Buffer.from(arrayBuffer).toString("base64");
+				ogImage = (await upload(returnedB64, user_id, null)) || ogImageUrl;
 
-		// Step 2: Caption generation
-		const caption = await imageToText(ogImage, supabase, user_id);
-		if (!caption) {
-			console.error("imageToText returned empty result", url);
-			isFailed = true;
-		} else {
-			newMeta.image_caption = caption;
+				console.log(`[${ROUTE}] Raindrop image uploaded successfully`);
+			} catch (error) {
+				console.error(`[${ROUTE}] Error downloading Raindrop image:`, error);
+				Sentry.captureException(error, {
+					tags: {
+						operation: "raindrop_image_upload",
+						userId: user_id,
+					},
+					extra: {
+						bookmarkId: id,
+						url,
+						ogImageUrl,
+					},
+				});
+			}
 		}
 
-		// Step 3: OCR
-		const ocrResult = await ocr(ogImage, supabase, user_id);
-		if (!ocrResult) {
-			console.error("ocr returned empty result", url);
-			isFailed = true;
-		} else {
-			newMeta.ocr = ocrResult;
-		}
+		console.log(`[${ROUTE}] Starting metadata enrichment:`, { url });
 
-		// Step 4: Blurhash
-		const { width, height, encoded } = await blurhashFromURL(ogImage);
-		if (!encoded || !width || !height) {
-			console.error("blurhashFromURL returned empty result", url);
-			isFailed = true;
+		// Enrich metadata with AI-generated content
+		const { metadata: newMeta, isFailed } = await enrichMetadata({
+			existingMetadata: message.message.meta_data,
+			ogImage,
+			isTwitterBookmark,
+			videoUrl: message.message.meta_data?.video_url,
+			userId: user_id,
+			supabase,
+			url,
+		});
+
+		if (isFailed) {
+			console.warn(`[${ROUTE}] Metadata enrichment partially failed:`, { url });
 		} else {
-			newMeta.width = width;
-			newMeta.height = height;
-			newMeta.ogImgBlurUrl = encoded;
+			console.log(`[${ROUTE}] Metadata enrichment completed successfully:`, {
+				url,
+			});
 		}
 
-		// Step 5: Update Supabase
-		const { error } = await supabase
+		// Update database with enriched data
+		const { error: updateError } = await supabase
 			.from(MAIN_TABLE_NAME)
 			.update({ ogImage, meta_data: newMeta })
-			.eq("url", url)
-			.eq("user_id", user_id);
+			.eq("id", id);
 
-		if (error) {
-			console.error("Error updating Supabase main table");
-			isFailed = true;
+		if (updateError) {
+			console.error(`[${ROUTE}] Error updating bookmark:`, updateError);
+			Sentry.captureException(updateError, {
+				tags: {
+					operation: "update_bookmark_metadata",
+					userId: user_id,
+				},
+				extra: {
+					bookmarkId: id,
+					url,
+					ogImage,
+				},
+			});
+			response.status(500).json({
+				error: "Failed to update bookmark metadata",
+			});
+			return;
 		}
 
-		// Delete message from queue
+		console.log(`[${ROUTE}] Bookmark updated successfully:`, { url });
+
+		// Delete message from queue on success
 		if (!isFailed) {
 			const { error: deleteError } = await supabase
 				.schema("pgmq_public")
@@ -126,20 +220,61 @@ export default async function handler(
 				});
 
 			if (deleteError) {
-				console.error("Error deleting message from queue");
+				console.error(`[${ROUTE}] Error deleting message from queue:`, {
+					error: deleteError,
+					messageId: message.msg_id,
+					queueName: queue_name,
+				});
+				Sentry.captureException(deleteError, {
+					tags: {
+						operation: "delete_queue_message",
+						userId: user_id,
+					},
+					extra: {
+						bookmarkId: id,
+						queueName: queue_name,
+						messageId: message.msg_id,
+						url,
+					},
+				});
+			} else {
+				console.log(`[${ROUTE}] Queue message deleted:`, {
+					messageId: message.msg_id,
+				});
 			}
+		} else {
+			console.warn(`[${ROUTE}] Keeping message in queue due to failures:`, {
+				messageId: message.msg_id,
+				url,
+			});
 		}
 
+		console.log(`[${ROUTE}] Request completed:`, {
+			url,
+			success: true,
+			isFailed,
+		});
+
 		response.status(200).json({
 			success: true,
 			isFailed,
 			ogImage,
 			meta_data: newMeta,
 		});
-	} catch (error: any) {
-		console.error("Error in process-og-image:", error);
+	} catch (error) {
+		console.error(`[${ROUTE}] Unexpected error:`, error);
+		Sentry.captureException(error, {
+			tags: {
+				operation: "ai_enrichment_unexpected",
+			},
+			extra: {
+				bookmarkId: request.body?.id,
+				url: request.body?.url,
+				userId: request.body?.user_id,
+			},
+		});
 		response.status(500).json({
-			error: error?.message || "Internal server error",
+			error: "An unexpected error occurred",
 		});
 	}
 }
diff --git a/src/pages/api/v1/twitter/syncFolders.ts b/src/pages/api/v1/twitter/syncFolders.ts
index 0d30eabd..ee2f847d 100644
--- a/src/pages/api/v1/twitter/syncFolders.ts
+++ b/src/pages/api/v1/twitter/syncFolders.ts
@@ -51,31 +51,7 @@ export default async function handler(
 		return;
 	}
 
-	// 1. Check for duplicates
-	const { data: existing, error: existingError } = await supabase
-		.from(CATEGORIES_TABLE_NAME)
-		.select("category_name, icon")
-		.eq("user_id", userId)
-		.in(
-			"category_name",
-			categories.map((category: { name: string }) => category.name),
-		)
-		.eq("icon", "bookmark");
-
-	if (!isNull(existingError)) {
-		response.status(500).json({ data: null, error: existingError });
-		return;
-	}
-
-	if (existing && existing.length > 0) {
-		response.status(400).json({
-			data: null,
-			error: { message: DUPLICATE_CATEGORY_NAME_ERROR },
-		});
-		return;
-	}
-
-	// 2. Insert all categories
+	// Insert all categories
 	const rowsToInsert = categories.map((category: { name: string }) => ({
 		category_name: category.name,
 		user_id: userId,
@@ -125,6 +101,30 @@ export default async function handler(
 	}
 
 	if (!isNull(error)) {
+		// Handle unique constraint violation (case-insensitive duplicate)
+		// Postgres error code 23505 = unique_violation
+		const isPostgrestError =
+			error && typeof error === "object" && "code" in error;
+		const errorMessage =
+			isPostgrestError && "message" in error ? String(error.message) : "";
+		if (
+			(isPostgrestError && (error as PostgrestError).code === "23505") ||
+			errorMessage.includes("unique_user_category_name_ci")
+		) {
+			console.warn(
+				"Duplicate category name attempt (case-insensitive) in bulk insert:",
+				{
+					userId,
+					categoryCount: categories.length,
+				},
+			);
+			response.status(409).json({
+				data: null,
+				error: { message: DUPLICATE_CATEGORY_NAME_ERROR },
+			});
+			return;
+		}
+
 		response.status(500).json({ data: null, error });
 		return;
 	}
diff --git a/src/pages/public/[user_name]/[id].tsx b/src/pages/public/[user_name]/[id].tsx
index 21b5cb57..dbcea92a 100644
--- a/src/pages/public/[user_name]/[id].tsx
+++ b/src/pages/public/[user_name]/[id].tsx
@@ -1,4 +1,5 @@
 import { type GetServerSideProps, type NextPage } from "next";
+import * as Sentry from "@sentry/nextjs";
 import axios from "axios";
 import { isEmpty, isNull } from "lodash";
 
@@ -51,8 +52,6 @@ const CategoryName: NextPage<PublicCategoryPageProps> = (props) => (
 					isOgImgLoading={false}
 					isPublicPage
 					listData={props?.data as SingleListData[]}
-					onDeleteClick={() => {}}
-					onMoveOutOfTrashClick={() => {}}
 					showAvatar={false}
 					userId=""
 				/>
@@ -66,20 +65,36 @@ const CategoryName: NextPage<PublicCategoryPageProps> = (props) => (
 );
 
 export const getServerSideProps: GetServerSideProps = async (context) => {
-	const response = await axios.post<GetPublicCategoryBookmarksApiResponseType>(
-		`${getBaseUrl()}${NEXT_API_URL}${FETCH_PUBLIC_CATEGORY_BOOKMARKS_API}?category_slug=${
-			context?.query?.id as string
-		}&user_name=${context?.query?.user_name as string}`,
-	);
+	const ROUTE = "/public/[user_name]/[id]";
+	const categorySlug = context?.query?.id as string;
+	const userName = context?.query?.user_name as string;
 
-	if (!response?.data?.is_public) {
-		// this page is not a public page
-		return {
-			notFound: true,
-		};
-	}
+	try {
+		const response =
+			await axios.post<GetPublicCategoryBookmarksApiResponseType>(
+				`${getBaseUrl()}${NEXT_API_URL}${FETCH_PUBLIC_CATEGORY_BOOKMARKS_API}?category_slug=${categorySlug}&user_name=${userName}`,
+			);
+
+		if (!response?.data?.is_public) {
+			console.warn(`[${ROUTE}] Category is not public`, {
+				categorySlug,
+				userName,
+			});
+			return { notFound: true };
+		}
+
+		if (isEmpty(response?.data?.data) || isNull(response?.data?.data)) {
+			return {
+				props: {
+					data: response?.data?.data,
+					category_views: response?.data?.category_views,
+					icon: response?.data?.icon,
+					icon_color: response?.data?.icon_color,
+					category_name: response?.data?.category_name,
+				},
+			};
+		}
 
-	if (isEmpty(response?.data?.data) || isNull(response?.data?.data)) {
 		return {
 			props: {
 				data: response?.data?.data,
@@ -89,17 +104,22 @@ export const getServerSideProps: GetServerSideProps = async (context) => {
 				category_name: response?.data?.category_name,
 			},
 		};
+	} catch (error) {
+		// Network failures, API errors are system errors (5xx) - console.error + Sentry
+		console.error(`[${ROUTE}] Failed to fetch public category bookmarks`, {
+			error,
+			categorySlug,
+			userName,
+		});
+		Sentry.captureException(error, {
+			tags: {
+				operation: "fetch_public_category",
+				context: "server_side_rendering",
+			},
+			extra: { categorySlug, userName },
+		});
+		return { notFound: true };
 	}
-
-	return {
-		props: {
-			data: response?.data?.data,
-			category_views: response?.data?.category_views,
-			icon: response?.data?.icon,
-			icon_color: response?.data?.icon_color,
-			category_name: response?.data?.category_name,
-		},
-	};
 };
 
 export default CategoryName;
diff --git a/src/pages/public/[user_name]/[id]/preview/[bookmark_id].tsx b/src/pages/public/[user_name]/[id]/preview/[bookmark_id].tsx
new file mode 100644
index 00000000..6ac0a681
--- /dev/null
+++ b/src/pages/public/[user_name]/[id]/preview/[bookmark_id].tsx
@@ -0,0 +1,174 @@
+import { type GetStaticPaths, type GetStaticProps } from "next";
+import { useRouter } from "next/router";
+import * as Sentry from "@sentry/nextjs";
+import { z } from "zod";
+
+import "yet-another-react-lightbox/styles.css";
+
+import { useState } from "react";
+
+import { CustomLightBox } from "../../../../../components/lightbox/LightBox";
+import {
+	type FetchDataResponse,
+	type SingleListData,
+} from "../../../../../types/apiTypes";
+import {
+	FETCH_PUBLIC_BOOKMARK_BY_ID_API,
+	getBaseUrl,
+} from "../../../../../utils/constants";
+import { HttpStatus } from "../../../../../utils/error-utils/common";
+import { buildPublicCategoryUrl } from "../../../../../utils/url-builders";
+
+type FetchPublicBookmarkByIdResponse = FetchDataResponse<SingleListData | null>;
+
+const PublicPreviewParamsSchema = z.object({
+	bookmark_id: z
+		.string()
+		.regex(/^\d+$/u, "Bookmark ID must be numeric")
+		.transform(Number),
+	user_name: z
+		.string()
+		.regex(/^[\w-]{1,39}$/u, "Invalid username format")
+		.min(1)
+		.max(39),
+	id: z
+		.string()
+		.regex(/^[\da-z-]+$/iu, "Invalid category slug format")
+		.min(1)
+		.max(100),
+});
+
+export type PublicPreviewProps = {
+	bookmark: SingleListData;
+};
+
+const PublicPreview = (props: PublicPreviewProps) => {
+	const { bookmark } = props;
+	const router = useRouter();
+	const { user_name, id: categorySlug } = router.query;
+
+	const [isOpen, setIsOpen] = useState(true);
+
+	const handleClose = () => {
+		setIsOpen(false);
+		if (user_name && categorySlug) {
+			const { pathname, query, as } = buildPublicCategoryUrl({
+				user_name: user_name as string,
+				category_slug: categorySlug as string,
+			});
+			void router.push({ pathname, query }, as, { shallow: true });
+		}
+	};
+
+	return (
+		<CustomLightBox
+			activeIndex={0}
+			bookmarks={[bookmark]}
+			handleClose={handleClose}
+			isOpen={isOpen}
+			setActiveIndex={() => {}}
+		/>
+	);
+};
+
+export const getStaticPaths: GetStaticPaths = async () => ({
+	paths: [],
+	fallback: "blocking",
+});
+
+export const getStaticProps: GetStaticProps<PublicPreviewProps> = async (
+	context,
+) => {
+	const ROUTE = "/public/[user_name]/[id]/preview/[bookmark_id]";
+
+	const validation = PublicPreviewParamsSchema.safeParse(context.params);
+	if (!validation.success) {
+		console.warn(`[${ROUTE}] Invalid route parameters`, {
+			errors: validation.error.flatten(),
+		});
+		return { notFound: true };
+	}
+
+	const { bookmark_id, user_name, id: categorySlug } = validation.data;
+
+	try {
+		const response = await fetch(
+			`${getBaseUrl()}${FETCH_PUBLIC_BOOKMARK_BY_ID_API}?bookmark_id=${bookmark_id}&user_name=${user_name}&category_slug=${categorySlug}`,
+		);
+
+		if (response.status === HttpStatus.NOT_FOUND) {
+			console.warn(`[${ROUTE}] Bookmark not found`, {
+				bookmark_id,
+				user_name,
+				categorySlug,
+			});
+			return { notFound: true };
+		}
+
+		if (!response.ok) {
+			console.error(
+				`[${ROUTE}] Failed to fetch public bookmark: HTTP ${response.status}`,
+				{
+					status: response.status,
+					statusText: response.statusText,
+					bookmark_id,
+					user_name,
+					categorySlug,
+				},
+			);
+			Sentry.captureException(
+				new Error(`HTTP ${response.status}: ${response.statusText}`),
+				{
+					tags: {
+						operation: "fetch_public_bookmark",
+						context: "incremental_static_regeneration",
+					},
+					extra: {
+						status: response.status,
+						statusText: response.statusText,
+						bookmark_id,
+						user_name,
+						categorySlug,
+					},
+				},
+			);
+			return { notFound: true };
+		}
+
+		const data = (await response.json()) as FetchPublicBookmarkByIdResponse;
+
+		if (!data?.data || data?.error) {
+			console.warn(`[${ROUTE}] Bookmark data not found or contains error`, {
+				error: data?.error,
+				bookmark_id,
+				user_name,
+				categorySlug,
+			});
+			return { notFound: true };
+		}
+
+		return {
+			props: {
+				bookmark: data.data,
+			},
+			revalidate: 300,
+		};
+	} catch (error) {
+		console.error(`[${ROUTE}] Unexpected error fetching public bookmark`, {
+			error,
+			bookmark_id,
+			user_name,
+			categorySlug,
+		});
+		Sentry.captureException(error, {
+			tags: {
+				operation: "fetch_public_bookmark",
+				context: "incremental_static_regeneration",
+			},
+			extra: { bookmark_id, user_name, categorySlug },
+		});
+		return { notFound: true };
+	}
+};
+
+export default PublicPreview;
diff --git a/src/types/apiTypes.ts b/src/types/apiTypes.ts
index ef930ad4..34965b6d 100644
--- a/src/types/apiTypes.ts
+++ b/src/types/apiTypes.ts
@@ -33,11 +33,12 @@ export type SingleListData = {
 	 * Array of categories (many-to-many)
 	 */
 	addedCategories?: CategoriesData[];
-	addedTags: UserTagsData[];
+	addedTags: Array<UserTagsData | TempTag>;
 	description: string;
 	id: number;
 	inserted_at: string;
 	meta_data: ImgMetadataType;
+	make_discoverable: string | null;
 	ogImage: string;
 	ogimage?: string;
 	screenshot: string;
@@ -92,6 +93,15 @@ export type UserTagsData = {
 	user_id: string;
 };
 
+/**
+ * Minimal tag type for optimistic updates.
+ * Contains only the fields set during temporary tag creation.
+ */
+export type TempTag = {
+	id: number;
+	name: string;
+};
+
 export type FetchUserTagsDataResponse = {
 	data: UserTagsData[];
 	error: PostgrestError | null;
@@ -261,12 +271,6 @@ export type MoveBookmarkToTrashApiPayload = {
 	isTrash: boolean;
 };
 
-export type AddUserCategoryApiPayload = {
-	category_order: number[];
-	name: string;
-	session: SupabaseSessionType;
-};
-
 export type DeleteUserCategoryApiPayload = {
 	category_id: number;
 	category_order: number[];
@@ -274,17 +278,6 @@ export type DeleteUserCategoryApiPayload = {
 
 export type UpdateCategoryOrderApiPayload = { order: number[] };
 
-export type UpdateCategoryApiPayload = {
-	category_id: number | string | null;
-	updateData: {
-		category_name?: CategoriesData["category_name"];
-		category_views?: BookmarkViewDataTypes;
-		icon?: string | null;
-		icon_color?: CategoriesData["icon_color"];
-		is_public?: boolean;
-	};
-};
-
 export type UpdateUserProfileApiPayload = {
 	updateData: ProfilesTableForPayloadTypes;
 };
@@ -319,14 +312,6 @@ export type UpdateSharedCategoriesUserAccessApiPayload = {
 	updateData: { category_views?: BookmarkViewDataTypes; edit_access?: boolean };
 };
 
-export type AddTagToBookmarkApiPayload = {
-	selectedData:
-		| Pick<BookmarksTagData, "bookmark_id" | "tag_id">
-		| Array<Pick<BookmarksTagData, "bookmark_id" | "tag_id">>;
-};
-
-export type AddUserTagsApiPayload = { tagsData: { name: string } };
-
 export type UploadFileApiPayload = {
 	category_id: CategoryIdUrlTypes;
 	file: FileType;
diff --git a/src/types/database-generated.types.ts b/src/types/database-generated.types.ts
index 55ce59db..6f6dd9b9 100644
--- a/src/types/database-generated.types.ts
+++ b/src/types/database-generated.types.ts
@@ -147,6 +147,7 @@ export type Database = {
 					description: string | null;
 					id: number;
 					inserted_at: string;
+					make_discoverable: string | null;
 					meta_data: Json | null;
 					ogImage: string | null;
 					screenshot: string | null;
@@ -162,6 +163,7 @@ export type Database = {
 					description?: string | null;
 					id?: number;
 					inserted_at?: string;
+					make_discoverable?: string | null;
 					meta_data?: Json | null;
 					ogImage?: string | null;
 					screenshot?: string | null;
@@ -177,6 +179,7 @@ export type Database = {
 					description?: string | null;
 					id?: number;
 					inserted_at?: string;
+					make_discoverable?: string | null;
 					meta_data?: Json | null;
 					ogImage?: string | null;
 					screenshot?: string | null;
@@ -317,6 +320,20 @@ export type Database = {
 					out_category_id: number;
 				}>;
 			};
+			create_and_assign_tag: {
+				Args: { p_bookmark_id: number; p_tag_name: string };
+				Returns: Array<{
+					bookmark_tag_bookmark_id: number;
+					bookmark_tag_created_at: string;
+					bookmark_tag_id: number;
+					bookmark_tag_tag_id: number;
+					bookmark_tag_user_id: string;
+					tag_created_at: string;
+					tag_id: number;
+					tag_name: string;
+					tag_user_id: string;
+				}>;
+			};
 			remove_category_from_bookmark: {
 				Args: { p_bookmark_id: number; p_category_id: number };
 				Returns: Array<{
@@ -353,7 +370,7 @@ export type Database = {
 			};
 			search_bookmarks_debugging:
 				| {
-						Args: { search_text: string; url_scope: string };
+						Args: { search_text: string };
 						Returns: Array<{
 							category_id: number;
 							description: string;
@@ -371,7 +388,7 @@ export type Database = {
 						}>;
 				  }
 				| {
-						Args: { search_text: string };
+						Args: { search_text: string; url_scope: string };
 						Returns: Array<{
 							category_id: number;
 							description: string;
@@ -391,14 +408,13 @@ export type Database = {
 			search_bookmarks_url_tag_scope:
 				| {
 						Args: {
-							category_scope?: number;
 							search_text?: string;
 							tag_scope?: string[];
 							url_scope?: string;
 						};
 						Returns: Array<{
-							added_categories: Json;
 							added_tags: Json;
+							category_id: number;
 							description: string;
 							id: number;
 							inserted_at: string;
@@ -415,16 +431,18 @@ export type Database = {
 				  }
 				| {
 						Args: {
+							category_scope?: number;
 							search_text?: string;
 							tag_scope?: string[];
 							url_scope?: string;
 						};
 						Returns: Array<{
+							added_categories: Json;
 							added_tags: Json;
-							category_id: number;
 							description: string;
 							id: number;
 							inserted_at: string;
+							make_discoverable: string;
 							meta_data: Json;
 							ogimage: string;
 							screenshot: string;
diff --git a/src/types/database.types.ts b/src/types/database.types.ts
index 78e51521..201a753a 100644
--- a/src/types/database.types.ts
+++ b/src/types/database.types.ts
@@ -7,6 +7,16 @@ export type { Json } from "./database-generated.types";
 export type Database = MergeDeep<
 	DatabaseGenerated,
 	{
-		// Override the type for a specific column in a view:
+		public: {
+			Functions: {
+				// Fix: Generated types don't infer nullable columns in RETURNS TABLE
+				// The make_discoverable column can be NULL but Supabase CLI assumes NOT NULL
+				search_bookmarks_url_tag_scope: {
+					Returns: Array<{
+						make_discoverable: string | null;
+					}>;
+				};
+			};
+		};
 	}
 >;
diff --git a/src/utils/cache-debug-helpers.ts b/src/utils/cache-debug-helpers.ts
new file mode 100644
index 00000000..0371f826
--- /dev/null
+++ b/src/utils/cache-debug-helpers.ts
@@ -0,0 +1,25 @@
+import * as Sentry from "@sentry/nextjs";
+
+/**
+ * Log cache misses with dev console warning and Sentry breadcrumb.
+ * Provides observability for silent cache update failures.
+ * @param context - Context label (e.g., "Cache Update", "Optimistic Update")
+ * @param message - Descriptive message about the cache miss
+ * @param data - Additional data to include in the log
+ */
+export function logCacheMiss(
+	context: string,
+	message: string,
+	data: Record<string, unknown>,
+): void {
+	if (process.env.NODE_ENV === "development") {
+		console.warn(`[${context}] ${message}`, data);
+	}
+
+	Sentry.addBreadcrumb({
+		category: context.toLowerCase().replaceAll(/\s+/gu, "-"),
+		message,
+		level: "warning",
+		data,
+	});
+}
diff --git a/src/utils/commonData.tsx b/src/utils/commonData.tsx
index 484cc47f..c01846d5 100644
--- a/src/utils/commonData.tsx
+++ b/src/utils/commonData.tsx
@@ -12,6 +12,7 @@ import VideoIcon from "../icons/videoIcon";
 import { type BookmarksCountTypes } from "../types/apiTypes";
 
 import {
+	DISCOVER_URL,
 	DOCUMENTS_URL,
 	EVERYTHING_URL,
 	IMAGES_URL,
@@ -23,6 +24,7 @@ import {
 	UNCATEGORIZED_URL,
 	VIDEOS_URL,
 } from "./constants";
+import { DiscoverIcon } from "@/icons/discover-icon";
 
 // TODO: check if this is needed (for code cleanup)
 const object = [
@@ -3600,12 +3602,21 @@ export const optionsMenuListArray = (
 		count: bookmarksCountData?.data?.everything,
 		iconColor: "",
 	},
+	{
+		icon: <DiscoverIcon />,
+		name: menuListItemName.discover,
+		href: `/${DISCOVER_URL}`,
+		current: currentPath === DISCOVER_URL,
+		id: 1,
+		count: undefined,
+		iconColor: "",
+	},
 	{
 		icon: <InboxIconGray />,
 		name: menuListItemName.inbox,
 		href: `/${UNCATEGORIZED_URL}`,
 		current: currentPath === UNCATEGORIZED_URL,
-		id: 1,
+		id: 2,
 		count: bookmarksCountData?.data?.uncategorized,
 		iconColor: "",
 	},
@@ -3614,7 +3625,7 @@ export const optionsMenuListArray = (
 		name: menuListItemName.trash,
 		href: `/${TRASH_URL}`,
 		current: currentPath === TRASH_URL,
-		id: 2,
+		id: 3,
 		count: bookmarksCountData?.data?.trash,
 		iconColor: "",
 	},
@@ -3623,7 +3634,7 @@ export const optionsMenuListArray = (
 		name: menuListItemName.settings,
 		href: `/${SETTINGS_URL}`,
 		current: currentPath === SETTINGS_URL,
-		id: 3,
+		id: 4,
 		count: undefined,
 		iconColor: "",
 	},
@@ -3632,7 +3643,7 @@ export const optionsMenuListArray = (
 		name: menuListItemName.image,
 		href: `/${IMAGES_URL}`,
 		current: currentPath === IMAGES_URL,
-		id: 4,
+		id: 5,
 		count: bookmarksCountData?.data?.images,
 		iconColor: "",
 	},
@@ -3641,7 +3652,7 @@ export const optionsMenuListArray = (
 		name: menuListItemName.videos,
 		href: `/${VIDEOS_URL}`,
 		current: currentPath === VIDEOS_URL,
-		id: 5,
+		id: 6,
 		count: bookmarksCountData?.data?.videos,
 		iconColor: "",
 	},
@@ -3650,7 +3661,7 @@ export const optionsMenuListArray = (
 		name: menuListItemName.links,
 		href: `/${LINKS_URL}`,
 		current: currentPath === LINKS_URL,
-		id: 6,
+		id: 7,
 		count: bookmarksCountData?.data?.links,
 		iconColor: "",
 	},
@@ -3659,7 +3670,7 @@ export const optionsMenuListArray = (
 		name: menuListItemName.documents,
 		href: `/${DOCUMENTS_URL}`,
 		current: currentPath === DOCUMENTS_URL,
-		id: 7,
+		id: 8,
 		count: bookmarksCountData?.data?.documents,
 		iconColor: "",
 	},
@@ -3668,7 +3679,7 @@ export const optionsMenuListArray = (
 		name: menuListItemName.tweets,
 		href: `/${TWEETS_URL}`,
 		current: currentPath === TWEETS_URL,
-		id: 8,
+		id: 9,
 		count: bookmarksCountData?.data?.tweets,
 		iconColor: "",
 	},
diff --git a/src/utils/constants.ts b/src/utils/constants.ts
index 646d6348..6e6f9766 100644
--- a/src/utils/constants.ts
+++ b/src/utils/constants.ts
@@ -24,6 +24,15 @@ export const STORAGE_SCREENSHOT_IMAGES_PATH =
 export const STORAGE_FILES_PATH = FILES_STORAGE_NAME + "/public";
 export const STORAGE_USER_PROFILE_PATH = USER_PROFILE_STORAGE_NAME + "/public";
 
+// Video upload limits
+export const VIDEO_DOWNLOAD_TIMEOUT_MS = 60_000;
+
+// Image download timeout
+export const IMAGE_DOWNLOAD_TIMEOUT_MS = 10_000;
+
+// Video download timeout
+export const MAX_VIDEO_SIZE_BYTES = 50 * 1024 * 1024;
+
 // regx
 
 // Supports any valid TLD (2+ characters)
@@ -74,6 +83,8 @@ export const FETCH_BOOKMARK_BY_ID_API = "/v1/bookmarks/get/fetch-by-id?id=";
 export const DELETE_BOOKMARK_DATA_API = "/bookmark/delete-bookmark";
 export const ADD_BOOKMARK_MIN_DATA = "/bookmark/add-bookmark-min-data";
 export const ADD_URL_SCREENSHOT_API = "/bookmark/add-url-screenshot";
+export const FETCH_BOOKMARKS_DISCOVERABLE_API =
+	"/bookmark/fetch-bookmarks-discoverable";
 export const WORKER_SCREENSHOT_API = "/v1/screenshot";
 export const AI_ENRICHMENT_API = "/v1/ai-enrichment";
 export const MOVE_BOOKMARK_TO_TRASH_API = "/bookmark/move-bookmark-to-trash";
@@ -83,12 +94,16 @@ export const SEARCH_BOOKMARKS = "/bookmark/search-bookmarks";
 export const FETCH_BOOKMARKS_COUNT = "/bookmark/fetch-bookmarks-count";
 export const ADD_REMAINING_BOOKMARK_API =
 	"/bookmark/add-remaining-bookmark-data";
+export const TOGGLE_BOOKMARK_DISCOVERABLE_API =
+	"/bookmark/toggle-discoverable-on-bookmark";
+export const FETCH_PUBLIC_BOOKMARK_BY_ID_API =
+	"/api/bookmark/fetch-public-bookmark-by-id";
 
 // tags api
 export const FETCH_USER_TAGS_API = "/tags/fetch-user-tags";
-export const CREATE_USER_TAGS_API = "/tags/create-user-tags";
 export const ADD_TAG_TO_BOOKMARK_API = "/tags/add-tag-to-bookmark";
 export const REMOVE_TAG_FROM_BOOKMARK_API = "/tags/remove-tag-from-bookmark";
+export const CREATE_AND_ASSIGN_TAG_API = "/tags/create-and-assign-tag";
 // category api
 export const FETCH_USER_CATEGORIES_API = "/category/fetch-user-categories";
 export const CREATE_USER_CATEGORIES_API = "/category/create-user-category";
@@ -155,6 +170,7 @@ export const AUTH_URLS = "auth";
 // Others
 export const EVERYTHING_URL = "everything";
 export const UNCATEGORIZED_URL = "uncategorized";
+export const DISCOVER_URL = "discover";
 export const SEARCH_URL = "search";
 export const INBOX_URL = "inbox";
 export const TRASH_URL = "trash";
@@ -184,7 +200,7 @@ export const GET_API_KEY_KEY = "get_api_key";
 export const ADD_UPDATE_BOOKMARK_ACCESS_ERROR =
 	"You dont have access to add to this category, this bookmark will be added without a category";
 export const DUPLICATE_CATEGORY_NAME_ERROR =
-	"You already have a category with this name , please add any other name";
+	"You already have a category with this name. Please use a different name.";
 export const NO_BOOKMARKS_ID_ERROR = "Bookmark ID is required";
 
 // accepted file type constants
@@ -278,6 +294,7 @@ export const defaultBlur = "Uf4:~MrTiwbcpfi]Z~kDb_agaJoco}jbaeax";
 
 export const menuListItemName = {
 	everything: "Everything",
+	discover: "Discover",
 	inbox: "Inbox",
 	trash: "Trash",
 	settings: "Settings",
@@ -407,7 +424,7 @@ export const PUBLIC_PATHS = new Set(["/error", "/public"]);
 export const isPublicPath = (pathname: string) =>
 	[...PUBLIC_PATHS].some((path) => pathname.startsWith(path));
 
-export const MAX_TAG_NAME_LENGTH = 20;
-export const MIN_TAG_NAME_LENGTH = 1;
+export const MAX_TAG_COLLECTION_NAME_LENGTH = 20;
+export const MIN_TAG_COLLECTION_NAME_LENGTH = 1;
 export const WHITE_COLOR = colorPickerColors[0];
 export const BLACK_COLOR = colorPickerColors[1];
diff --git a/src/utils/helpers.server.ts b/src/utils/helpers.server.ts
new file mode 100644
index 00000000..1c86f7dd
--- /dev/null
+++ b/src/utils/helpers.server.ts
@@ -0,0 +1,406 @@
+import * as Sentry from "@sentry/nextjs";
+import { type SupabaseClient } from "@supabase/supabase-js";
+import uniqid from "uniqid";
+
+import {
+	MAX_VIDEO_SIZE_BYTES,
+	R2_MAIN_BUCKET_NAME,
+	STORAGE_FILES_PATH,
+	VIDEO_DOWNLOAD_TIMEOUT_MS,
+} from "./constants";
+import { storageHelpers } from "./storageClient";
+import imageToText from "@/async/ai/imageToText";
+import ocr from "@/async/ai/ocr";
+import { blurhashFromURL } from "@/utils/getBlurHash";
+
+type EnrichMetadataParams = {
+	existingMetadata: Record<string, unknown>;
+	ogImage: string;
+	isTwitterBookmark: boolean;
+	videoUrl?: string | null;
+	userId: string;
+	supabase: SupabaseClient;
+	url: string;
+};
+
+type EnrichMetadataResult = {
+	metadata: Record<string, unknown>;
+	isFailed: boolean;
+};
+
+/**
+ * Enrich bookmark metadata with AI-generated content.
+ *
+ * Performs the following enrichments:
+ * - Twitter video upload to R2 (if applicable)
+ * - Image caption generation via AI
+ * - OCR text extraction from image
+ * - Blurhash generation for progressive image loading
+ * @param params - Enrichment parameters
+ * @param params.existingMetadata - The existing bookmark metadata
+ * @param params.ogImage - The Open Graph image URL to process
+ * @param params.isTwitterBookmark - Whether this is a Twitter bookmark
+ * @param params.videoUrl - Optional Twitter video URL to upload to R2
+ * @param params.userId - The user ID for R2 upload path
+ * @param params.supabase - Supabase client for AI operations
+ * @param params.url - The bookmark URL for logging
+ * @returns Updated metadata and failure flag
+ */
+
+// this function cannot be exported from helper.ts because it uses processBlurhash functions,
+// in processBlurhash, blurhashFromURL is used which uses sharp , which is not supported in the browser
+// Client-side dashboard components import functions from helpers.ts
+// Webpack tries to bundle the entire helpers.ts file for the browser, including sharp, which fails
+export const enrichMetadata = async ({
+	existingMetadata,
+	ogImage,
+	isTwitterBookmark,
+	videoUrl,
+	userId,
+	supabase,
+	url,
+}: EnrichMetadataParams): Promise<EnrichMetadataResult> => {
+	// Run all AI operations in parallel
+	const [videoResult, ocrResult, captionResult, blurhashResult] =
+		await Promise.allSettled([
+			// Video upload (conditional)
+			isTwitterBookmark && videoUrl && typeof videoUrl === "string"
+				? (async () => {
+						console.log("[enrichMetadata] Uploading Twitter video to R2:", {
+							url,
+						});
+						const r2VideoUrl = await uploadVideoToR2(videoUrl, userId);
+						if (r2VideoUrl) {
+							console.log("[enrichMetadata] Twitter video uploaded to R2:", {
+								url,
+								r2VideoUrl,
+							});
+							return r2VideoUrl;
+						}
+
+						// Upload failed but not critical - keep processing
+						// Video upload is best-effort. If the URL is expired, the UI will
+						// fall back to displaying the thumbnail image instead.
+						console.warn(
+							"[enrichMetadata] Video upload failed, using original URL:",
+							{ url, videoUrl },
+						);
+						return videoUrl;
+					})()
+				: Promise.resolve(null),
+			// OCR extraction
+			processOcr(ogImage, supabase, userId, url),
+			// Image caption generation
+			processImageCaption(ogImage, supabase, userId, url),
+			// Blurhash generation
+			processBlurhash(ogImage, url, userId),
+		]);
+
+	// Extract video URL from result
+	const video_url =
+		videoResult.status === "fulfilled" ? videoResult.value : null;
+
+	// Extract OCR result
+	const { isOcrFailed, ocrResult: ocrData } =
+		ocrResult.status === "fulfilled"
+			? ocrResult.value
+			: { isOcrFailed: true, ocrResult: null };
+
+	// Extract caption result
+	const { isImageCaptionFailed, image_caption } =
+		captionResult.status === "fulfilled"
+			? captionResult.value
+			: { isImageCaptionFailed: true, image_caption: null };
+
+	// Extract blurhash result
+	const { isBlurhashFailed, blurhash } =
+		blurhashResult.status === "fulfilled"
+			? blurhashResult.value
+			: { isBlurhashFailed: true, blurhash: null };
+
+	const metadata = {
+		...existingMetadata,
+		ocr: ocrData,
+		image_caption,
+		width: blurhash?.width,
+		height: blurhash?.height,
+		ogImgBlurUrl: blurhash?.encoded,
+		video_url,
+	};
+
+	const isFailed = isOcrFailed || isImageCaptionFailed || isBlurhashFailed;
+
+	console.log("[enrichMetadata] Enrichment completed:", {
+		url,
+		isFailed,
+		hasImageCaption: Boolean(metadata.image_caption),
+		hasOcr: Boolean(metadata.ocr),
+		hasBlurhash: Boolean(metadata.ogImgBlurUrl),
+		hasVideo: Boolean(metadata.video_url),
+	});
+
+	return { metadata, isFailed };
+};
+
+const processOcr = async (
+	ogImage: string,
+	supabase: SupabaseClient,
+	userId: string,
+	url: string,
+) => {
+	console.log("[processOcr] Extracting text via OCR:", { url, ogImage });
+	// Extract text from the image
+	try {
+		const ocrResult = await ocr(ogImage, supabase, userId);
+		if (!ocrResult) {
+			console.error("[processOcr] OCR returned empty result:", {
+				url,
+				ogImage,
+			});
+			Sentry.captureMessage("OCR returned empty result", {
+				level: "error",
+				tags: {
+					operation: "ocr_empty",
+					userId,
+				},
+				extra: {
+					url,
+					ogImage,
+				},
+			});
+			return { isOcrFailed: true, ocrResult: null };
+		} else {
+			console.log("[processOcr] OCR extraction completed successfully:", {
+				url,
+			});
+			return { isOcrFailed: false, ocrResult };
+		}
+	} catch (error) {
+		console.error("[processOcr] OCR threw error:", { url, ogImage, error });
+		Sentry.captureException(error, {
+			tags: {
+				operation: "ocr_extraction",
+				userId,
+			},
+			extra: {
+				url,
+				ogImage,
+			},
+		});
+		return { isOcrFailed: true, ocrResult: null };
+	}
+};
+
+const processImageCaption = async (
+	ogImage: string,
+	supabase: SupabaseClient,
+	userId: string,
+	url: string,
+) => {
+	console.log("[processImageCaption] Generating image caption:", {
+		url,
+		ogImage,
+	});
+	// Generate caption for the image
+	try {
+		const caption = await imageToText(ogImage, supabase, userId);
+		if (!caption) {
+			console.error(
+				"[processImageCaption] imageToText returned empty result:",
+				{ url, ogImage },
+			);
+			Sentry.captureMessage("Image caption generation returned empty result", {
+				level: "error",
+				tags: {
+					operation: "image_caption_empty",
+					userId,
+				},
+				extra: {
+					url,
+					ogImage,
+				},
+			});
+			return { isImageCaptionFailed: true, image_caption: null };
+		} else {
+			console.log(
+				"[processImageCaption] Image caption generated successfully:",
+				{ url },
+			);
+			return { isImageCaptionFailed: false, image_caption: caption };
+		}
+	} catch (error) {
+		console.error("[processImageCaption] imageToText threw error:", {
+			url,
+			ogImage,
+			error,
+		});
+		Sentry.captureException(error, {
+			tags: {
+				operation: "image_caption_generation",
+				userId,
+			},
+			extra: {
+				url,
+				ogImage,
+			},
+		});
+		return { isImageCaptionFailed: true, image_caption: null };
+	}
+};
+
+const processBlurhash = async (
+	ogImage: string,
+	url: string,
+	userId: string,
+) => {
+	console.log("[processBlurhash] Generating blurhash:", { url, ogImage });
+	try {
+		const { width, height, encoded } = await blurhashFromURL(ogImage);
+		if (!encoded || !width || !height) {
+			console.error(
+				"[processBlurhash] blurhashFromURL returned empty result:",
+				{
+					url,
+					ogImage,
+				},
+			);
+			Sentry.captureMessage("Blurhash generation returned empty result", {
+				level: "error",
+				tags: {
+					operation: "blurhash_empty",
+					userId,
+				},
+				extra: {
+					url,
+					ogImage,
+				},
+			});
+			return { isBlurhashFailed: true, blurhash: null };
+		} else {
+			console.log("[processBlurhash] Blurhash generated successfully:", {
+				url,
+				width,
+				height,
+			});
+			return { isBlurhashFailed: false, blurhash: { width, height, encoded } };
+		}
+	} catch (error) {
+		console.error("[processBlurhash] blurhashFromURL threw error:", {
+			url,
+			ogImage,
+			error,
+		});
+		Sentry.captureException(error, {
+			tags: {
+				operation: "blurhash_generation",
+				userId,
+			},
+			extra: {
+				url,
+				ogImage,
+			},
+		});
+		return { isBlurhashFailed: true, blurhash: null };
+	}
+};
+
+/**
+ * Downloads a video from external URL and uploads to R2
+ * @param videoUrl - External video URL
+ * @param user_id - User ID for storage path
+ * @returns R2 public URL or null if failed
+ */
+export const uploadVideoToR2 = async (
+	videoUrl: string,
+	user_id: string,
+): Promise<string | null> => {
+	try {
+		const videoResponse: Response = await fetch(videoUrl, {
+			headers: {
+				"User-Agent": "Mozilla/5.0 (compatible; RecollectBot/1.0)",
+				Accept: "video/*,*/*;q=0.8",
+			},
+			signal: AbortSignal.timeout(VIDEO_DOWNLOAD_TIMEOUT_MS),
+		});
+
+		if (!videoResponse.ok) {
+			throw new Error(`HTTP error! status: ${videoResponse.status}`);
+		}
+
+		// Pre-download size check (Content-Length header - can be omitted/spoofed)
+		const contentLength = videoResponse.headers.get("content-length");
+		if (
+			contentLength &&
+			Number.parseInt(contentLength, 10) > MAX_VIDEO_SIZE_BYTES
+		) {
+			throw new Error(`Video size exceeds ${MAX_VIDEO_SIZE_BYTES} bytes limit`);
+		}
+
+		const arrayBuffer: ArrayBuffer = await videoResponse.arrayBuffer();
+
+		// Post-download size check (Content-Length can be omitted/spoofed)
+		if (arrayBuffer.byteLength > MAX_VIDEO_SIZE_BYTES) {
+			throw new Error(
+				`Video size ${arrayBuffer.byteLength} bytes exceeds ${MAX_VIDEO_SIZE_BYTES} bytes limit`,
+			);
+		}
+
+		// Generate unique filename
+		const videoName = `twitter-video-${uniqid.time()}.mp4`;
+		const storagePath = `${STORAGE_FILES_PATH}/${user_id}/${videoName}`;
+
+		// Determine content type from response or default to mp4
+		const contentType =
+			videoResponse.headers.get("content-type") || "video/mp4";
+
+		// Upload to R2
+		const videoBuffer = Buffer.from(arrayBuffer);
+		const { error: uploadError } = await storageHelpers.uploadObject(
+			R2_MAIN_BUCKET_NAME,
+			storagePath,
+			videoBuffer,
+			contentType,
+		);
+
+		if (uploadError) {
+			Sentry.captureException(uploadError, {
+				tags: { operation: "twitter_video_upload" },
+				extra: { videoUrl, userId: user_id },
+			});
+			console.error("R2 video upload failed:", uploadError);
+			return null;
+		}
+
+		// Get public URL
+		const { data: storageData } = storageHelpers.getPublicUrl(storagePath);
+
+		return storageData?.publicUrl || null;
+	} catch (error) {
+		console.error("Error in uploadVideoToR2:", error);
+
+		Sentry.captureException(error, {
+			tags: { operation: "twitter_video_download" },
+			extra: { videoUrl, userId: user_id },
+		});
+
+		return null;
+	}
+};
+
+const ALLOWED_TWITTER_DOMAINS = ["video.twimg.com", "pbs.twimg.com"];
+
+/**
+ *
+ * @param urlString - The URL to validate
+ * @returns void - Throws an error if the URL is not valid
+ */
+export const validateTwitterMediaUrl = (urlString: string): void => {
+	const url = new URL(urlString);
+	if (url.protocol !== "https:") {
+		throw new Error("Only HTTPS allowed");
+	}
+
+	if (!ALLOWED_TWITTER_DOMAINS.includes(url.hostname)) {
+		throw new Error("Domain not in allowlist");
+	}
+};
diff --git a/src/utils/helpers.ts b/src/utils/helpers.ts
index 799c05e6..493c3a4b 100644
--- a/src/utils/helpers.ts
+++ b/src/utils/helpers.ts
@@ -23,6 +23,7 @@ import {
 	acceptedFileTypes,
 	bookmarkType,
 	CATEGORIES_TABLE_NAME,
+	DISCOVER_URL,
 	documentFileTypes,
 	DOCUMENTS_URL,
 	EVERYTHING_URL,
@@ -66,7 +67,8 @@ export const getCategoryIdFromSlug = (
 		slug === VIDEOS_URL ||
 		slug === LINKS_URL ||
 		slug === DOCUMENTS_URL ||
-		slug === TWEETS_URL
+		slug === TWEETS_URL ||
+		slug === DISCOVER_URL
 	) {
 		return slug;
 	}
@@ -186,6 +188,7 @@ export const isUserInACategory = (url: string) => {
 		DOCUMENTS_URL,
 		LINKS_URL,
 		TWEETS_URL,
+		DISCOVER_URL,
 	];
 
 	return !nonCategoryPages?.includes(url);
@@ -425,8 +428,8 @@ export const getPreviewPathInfo = (
  * @param categoryData - Object containing category data
  * @param categoryData.data - Array of category data to search through
  * @param categoryData.error - Optional error object from the data fetch
- * @returns number | string | null - Returns:
- *   - null if the current route is for everything or search
+ * @returns number | string | undefined - Returns:
+ *   - undefined if the current route is for everything or search
  *   - category ID (number) if a matching category is found
  *   - the original category slug (string) if no matching category is found
  */
@@ -443,9 +446,10 @@ export const searchSlugKey = (categoryData: {
 		(item) => item?.category_slug === categorySlug,
 	)?.id;
 
-	// Special case: return null for 'everything' or 'search' routes
+	// Special case: return undefined for 'everything' or 'search' routes
+	// This matches the behavior of useGetCurrentCategoryId()/CATEGORY_ID
 	if (categorySlug === EVERYTHING_URL || categorySlug === SEARCH_URL) {
-		return null;
+		return undefined;
 	}
 
 	// If we found a matching category with a numeric ID, return the ID
diff --git a/src/utils/query-cache-helpers.ts b/src/utils/query-cache-helpers.ts
new file mode 100644
index 00000000..e59351c9
--- /dev/null
+++ b/src/utils/query-cache-helpers.ts
@@ -0,0 +1,131 @@
+import { produce, type Draft } from "immer";
+
+import {
+	type PaginatedBookmarks,
+	type SingleListData,
+	type UserTagsData,
+} from "@/types/apiTypes";
+import { logCacheMiss } from "@/utils/cache-debug-helpers";
+
+/**
+ * Update a specific bookmark within paginated infinite query data using Immer.
+ * Returns new data with the bookmark updated, or unchanged if not found.
+ * @param data - The paginated bookmarks data
+ * @param bookmarkId - The ID of the bookmark to update
+ * @param updater - Function that mutates the bookmark (Immer handles immutability)
+ */
+export function updateBookmarkInPaginatedData(
+	data: PaginatedBookmarks | undefined,
+	bookmarkId: number,
+	updater: (bookmark: Draft<SingleListData>) => void,
+): PaginatedBookmarks | undefined {
+	if (!data?.pages) {
+		return data;
+	}
+
+	let bookmarkFound = false;
+
+	const result = produce(data, (draft) => {
+		for (const page of draft.pages) {
+			// Skip undefined pages or pages without data array
+			if (!page?.data) {
+				continue;
+			}
+
+			const bookmark = page.data.find((bm) => bm.id === bookmarkId);
+			if (bookmark) {
+				updater(bookmark);
+				bookmarkFound = true;
+				// Early exit after bookmark found and updated
+				return;
+			}
+		}
+	});
+
+	if (!bookmarkFound) {
+		logCacheMiss("Cache Update", "Bookmark not found in paginated cache", {
+			bookmarkId,
+			pageCount: data.pages.length,
+		});
+	}
+
+	return result;
+}
+
+/**
+ * Swap a temp tag ID with the real tag from server response.
+ * Use inside an Immer updater function.
+ * @param bookmark - Draft bookmark from Immer
+ * @param tempId - The temporary ID used for optimistic update
+ * @param realTag - The real tag data from server response
+ * @param realTag.id - The real tag ID
+ * @param realTag.name - The real tag name
+ * @returns true if temp tag was found and swapped, false otherwise
+ */
+export function swapTempTagId(
+	bookmark: Draft<SingleListData>,
+	tempId: number,
+	realTag: { id: number; name: string | null },
+): boolean {
+	const tag = bookmark.addedTags?.find((existing) => existing.id === tempId);
+	if (tag) {
+		tag.id = realTag.id;
+		tag.name = realTag.name ?? tag.name;
+		return true;
+	}
+
+	logCacheMiss("Cache Update", "Temp tag not found in bookmark", {
+		bookmarkId: bookmark.id,
+		tempId,
+		realTagId: realTag.id,
+		existingTagIds: bookmark.addedTags?.map((tag) => tag.id) ?? [],
+	});
+	return false;
+}
+
+/**
+ * Update user tags cache with Immer.
+ * Replaces a temp tag with real tag data from server.
+ * @param data - The user tags cache data
+ * @param tempId - The temporary ID to replace
+ * @param realTag - The real tag data from server
+ * @param realTag.id - The real tag ID
+ * @param realTag.name - The real tag name
+ * @param [realTag.user_id] - The user ID (optional)
+ * @param [realTag.created_at] - The creation timestamp (optional)
+ */
+export function swapTempTagInUserTagsCache(
+	data: { data: UserTagsData[] } | undefined,
+	tempId: number,
+	realTag: {
+		id: number;
+		name: string | null;
+		user_id?: string;
+		created_at?: string;
+	},
+): { data: UserTagsData[] } | undefined {
+	if (!data?.data) {
+		return data;
+	}
+
+	return produce(data, (draft) => {
+		const tag = draft.data.find((existing) => existing.id === tempId);
+		if (!tag) {
+			logCacheMiss("Cache Update", "Temp tag not found in user tags cache", {
+				tempId,
+				tagCount: draft.data.length,
+			});
+			return;
+		}
+
+		tag.id = realTag.id;
+		tag.name = realTag.name ?? tag.name;
+		if (realTag.user_id) {
+			tag.user_id = realTag.user_id;
+		}
+
+		if (realTag.created_at) {
+			tag.created_at = realTag.created_at;
+		}
+	});
+}
diff --git a/src/utils/url-builders.ts b/src/utils/url-builders.ts
new file mode 100644
index 00000000..806a3176
--- /dev/null
+++ b/src/utils/url-builders.ts
@@ -0,0 +1,101 @@
+import { CATEGORY_ID_PATHNAME, PREVIEW_PATH } from "./constants";
+
+/**
+ * Public page info structure
+ */
+export type PublicPageInfo = {
+	category_slug: string;
+	user_name: string;
+};
+
+/**
+ * Route push parameters for Next.js router
+ */
+export type RoutePushParams = {
+	as: string;
+	pathname: string;
+	query: Record<string, string | number>;
+};
+
+/**
+ * Builds preview URL for public pages
+ * @param params - Parameters object
+ * @param params.bookmarkId - The bookmark ID to preview
+ * @param params.publicInfo - Public page information (user_name, category_slug)
+ * @returns Next.js router push parameters
+ */
+export const buildPublicPreviewUrl = (params: {
+	bookmarkId: number | string;
+	publicInfo: PublicPageInfo;
+}): RoutePushParams => {
+	const { bookmarkId, publicInfo } = params;
+	const { user_name, category_slug } = publicInfo;
+
+	return {
+		pathname: `/public/[user_name]/[id]`,
+		query: {
+			user_name,
+			id: category_slug,
+			bookmark_id: bookmarkId,
+		},
+		as: `/public/${user_name}/${category_slug}${PREVIEW_PATH}/${bookmarkId}`,
+	};
+};
+
+/**
+ * Builds category URL for public pages (without preview)
+ * @param publicInfo - Public page info
+ * @returns Next.js router push parameters
+ */
+export const buildPublicCategoryUrl = (
+	publicInfo: PublicPageInfo,
+): RoutePushParams => {
+	const { user_name, category_slug } = publicInfo;
+
+	return {
+		pathname: `/public/[user_name]/[id]`,
+		query: {
+			user_name,
+			id: category_slug,
+		},
+		as: `/public/${user_name}/${category_slug}`,
+	};
+};
+
+/**
+ * Builds preview URL for authenticated pages
+ * @param params - Parameters object
+ * @param params.bookmarkId - The bookmark ID to preview
+ * @param params.categorySlug - The category slug
+ * @returns Next.js router push parameters
+ */
+export const buildAuthenticatedPreviewUrl = (params: {
+	bookmarkId: number | string;
+	categorySlug: string;
+}): RoutePushParams => {
+	const { bookmarkId, categorySlug } = params;
+
+	return {
+		pathname: `${CATEGORY_ID_PATHNAME}`,
+		query: {
+			category_id: categorySlug,
+			id: bookmarkId,
+		},
+		as: `/${categorySlug}${PREVIEW_PATH}/${bookmarkId}`,
+	};
+};
+
+/**
+ * Builds category URL for authenticated pages (without preview)
+ * @param categorySlug - Category slug
+ * @returns Next.js router push parameters
+ */
+export const buildAuthenticatedCategoryUrl = (
+	categorySlug: string,
+): RoutePushParams => ({
+	pathname: `${CATEGORY_ID_PATHNAME}`,
+	query: {
+		category_id: categorySlug,
+	},
+	as: `/${categorySlug}`,
+});
diff --git a/src/utils/url.ts b/src/utils/url.ts
index 835a3ece..10d93ce0 100644
--- a/src/utils/url.ts
+++ b/src/utils/url.ts
@@ -7,6 +7,9 @@ import { type NextRouter } from "next/router";
  * - URL: /technology?sort=latest
  * - Returns: "technology"
  *
+ * - URL: /public/username/category-slug
+ * - Returns: "category-slug"
+ *
  * - URL: /
  * - Returns: null
  * @param router The Next.js router instance
@@ -20,6 +23,14 @@ export const getCategorySlugFromRouter = (
 		return null;
 	}
 
+	const pathSegments = router?.asPath?.split("/")?.filter(Boolean) || [];
+
+	// Handle public routes: /public/[user_name]/[category_slug]
+	if (pathSegments[0] === "public" && pathSegments.length >= 3) {
+		return pathSegments[2]?.split("?")?.[0] || null;
+	}
+
+	// Handle authenticated routes: /[category_slug]
 	// router.asPath gives the full path with query string (e.g., "/technology?sort=latest")
 	// Step 1: Split by "/" → ["", "technology?sort=latest"]
 	// Step 2: Take index [1] → "technology?sort=latest"
@@ -27,3 +38,38 @@ export const getCategorySlugFromRouter = (
 	// Step 4: Take index [0] → "technology"
 	return router?.asPath?.split("/")?.[1]?.split("?")?.[0] || null;
 };
+
+/**
+ * Extracts user_name and category slug from public page routes.
+ *
+ * Example:
+ * - URL: /public/john/technology
+ * - Returns: { user_name: "john", category_slug: "technology" }
+ *
+ * - URL: /public/john/technology/preview/123
+ * - Returns: { user_name: "john", category_slug: "technology" }
+ * @param router The Next.js router instance
+ * @returns Object with user_name and category_slug, or null if not a public route
+ */
+export const getPublicPageInfo = (
+	router: NextRouter,
+): { user_name: string; category_slug: string } | null => {
+	// Ensure we are running on the client (window is not available on server-side)
+	if (typeof window === "undefined") {
+		return null;
+	}
+
+	const pathSegments = router?.asPath?.split("/")?.filter(Boolean) || [];
+
+	// Check if this is a public route: /public/[user_name]/[category_slug]
+	if (pathSegments[0] === "public" && pathSegments.length >= 3) {
+		const user_name = pathSegments[1];
+		const category_slug = pathSegments[2]?.split("?")?.[0];
+
+		if (user_name && category_slug) {
+			return { user_name, category_slug };
+		}
+	}
+
+	return null;
+};
diff --git a/src/utils/worker.ts b/src/utils/worker.ts
index 71b1bf5c..5f366700 100644
--- a/src/utils/worker.ts
+++ b/src/utils/worker.ts
@@ -5,6 +5,7 @@ import {
 	AI_ENRICHMENT_API,
 	getBaseUrl,
 	NEXT_API_URL,
+	tweetType,
 	WORKER_SCREENSHOT_API,
 } from "./constants";
 
@@ -77,6 +78,8 @@ export const processImageQueue = async (
 
 				const mediaType = message?.message?.meta_data?.mediaType;
 
+				const isTwitterBookmark = message.message.type === tweetType;
+
 				const isRaindropBookmark =
 					message.message.meta_data.is_raindrop_bookmark;
 
@@ -92,6 +95,7 @@ export const processImageQueue = async (
 							id,
 							url,
 							user_id,
+							isTwitterBookmark,
 							ogImage,
 							isRaindropBookmark,
 							message,
diff --git a/supabase/migrations/20251222083107_case_insensitive_unique_constraints.sql b/supabase/migrations/20251222083107_case_insensitive_unique_constraints.sql
new file mode 100644
index 00000000..40753b73
--- /dev/null
+++ b/supabase/migrations/20251222083107_case_insensitive_unique_constraints.sql
@@ -0,0 +1,323 @@
+-- ============================================================================
+-- MIGRATION: Add case-insensitive unique constraints for categories and tags
+-- Created: 2025-12-22
+-- Purpose: Prevent duplicate category/tag names with different cases (e.g., "Test" and "test")
+-- ============================================================================
+--
+-- This migration:
+--   1. Merges duplicate categories (keeps entry with most bookmarks, tie-break by lowest id)
+--   2. Merges duplicate tags (keeps entry with most bookmarks, tie-break by lowest id)
+--   3. Creates case-insensitive unique index on categories (user_id, LOWER(category_name))
+--   4. Creates case-insensitive unique index on tags (user_id, LOWER(name))
+--
+-- These constraints ensure that users cannot create duplicate category/tag names
+-- that differ only by case, preventing confusion and data inconsistency.
+--
+-- ============================================================================
+
+BEGIN;
+SET search_path = public, pg_temp;
+
+-- ============================================================================
+-- PART 1: Merge duplicate categories
+-- ============================================================================
+
+-- 1.1 Pre-flight: Log duplicate category count
+DO $$
+DECLARE
+    v_duplicate_groups int;
+    v_total_duplicates int;
+BEGIN
+    -- Count groups that have duplicates
+    SELECT COUNT(*) INTO v_duplicate_groups
+    FROM (
+        SELECT user_id, LOWER(category_name) as lower_name
+        FROM public.categories
+        GROUP BY user_id, LOWER(category_name)
+        HAVING COUNT(*) > 1
+    ) dups;
+
+    -- Count total duplicate entries (entries that will be removed)
+    SELECT COALESCE(SUM(cnt - 1), 0) INTO v_total_duplicates
+    FROM (
+        SELECT user_id, LOWER(category_name) as lower_name, COUNT(*) as cnt
+        FROM public.categories
+        GROUP BY user_id, LOWER(category_name)
+        HAVING COUNT(*) > 1
+    ) dups;
+
+    RAISE NOTICE 'Categories: Found % duplicate groups with % total entries to merge', v_duplicate_groups, v_total_duplicates;
+END $$;
+
+-- 1.2 Reassign bookmark_categories from duplicates to keepers
+-- Uses CTE to identify keepers (most bookmarks, tie-break by lowest id)
+WITH category_bookmark_counts AS (
+    SELECT
+        c.id,
+        c.user_id,
+        LOWER(c.category_name) as lower_name,
+        COUNT(bc.bookmark_id) as bookmark_count
+    FROM public.categories c
+    LEFT JOIN public.bookmark_categories bc ON bc.category_id = c.id
+    GROUP BY c.id, c.user_id, LOWER(c.category_name)
+),
+keepers AS (
+    SELECT DISTINCT ON (user_id, lower_name)
+        id as keeper_id,
+        user_id,
+        lower_name
+    FROM category_bookmark_counts
+    ORDER BY user_id, lower_name, bookmark_count DESC, id ASC
+),
+duplicates AS (
+    SELECT c.id as duplicate_id, k.keeper_id
+    FROM public.categories c
+    JOIN keepers k ON k.user_id = c.user_id AND k.lower_name = LOWER(c.category_name)
+    WHERE c.id != k.keeper_id
+)
+-- Update bookmark_categories: point duplicates to keepers
+-- ON CONFLICT DO NOTHING handles case where keeper already has that bookmark
+INSERT INTO public.bookmark_categories (bookmark_id, category_id, user_id, created_at)
+SELECT bc.bookmark_id, d.keeper_id, bc.user_id, bc.created_at
+FROM public.bookmark_categories bc
+JOIN duplicates d ON bc.category_id = d.duplicate_id
+ON CONFLICT (bookmark_id, category_id) DO NOTHING;
+
+-- 1.3 Delete bookmark_categories entries pointing to duplicates (now reassigned)
+WITH category_bookmark_counts AS (
+    SELECT
+        c.id,
+        c.user_id,
+        LOWER(c.category_name) as lower_name,
+        COUNT(bc.bookmark_id) as bookmark_count
+    FROM public.categories c
+    LEFT JOIN public.bookmark_categories bc ON bc.category_id = c.id
+    GROUP BY c.id, c.user_id, LOWER(c.category_name)
+),
+keepers AS (
+    SELECT DISTINCT ON (user_id, lower_name)
+        id as keeper_id,
+        user_id,
+        lower_name
+    FROM category_bookmark_counts
+    ORDER BY user_id, lower_name, bookmark_count DESC, id ASC
+),
+duplicates AS (
+    SELECT c.id as duplicate_id
+    FROM public.categories c
+    JOIN keepers k ON k.user_id = c.user_id AND k.lower_name = LOWER(c.category_name)
+    WHERE c.id != k.keeper_id
+)
+DELETE FROM public.bookmark_categories
+WHERE category_id IN (SELECT duplicate_id FROM duplicates);
+
+-- 1.4 Delete duplicate categories (keeping the keeper)
+WITH category_bookmark_counts AS (
+    SELECT
+        c.id,
+        c.user_id,
+        LOWER(c.category_name) as lower_name,
+        COUNT(bc.bookmark_id) as bookmark_count
+    FROM public.categories c
+    LEFT JOIN public.bookmark_categories bc ON bc.category_id = c.id
+    GROUP BY c.id, c.user_id, LOWER(c.category_name)
+),
+keepers AS (
+    SELECT DISTINCT ON (user_id, lower_name)
+        id as keeper_id,
+        user_id,
+        lower_name
+    FROM category_bookmark_counts
+    ORDER BY user_id, lower_name, bookmark_count DESC, id ASC
+),
+duplicates AS (
+    SELECT c.id as duplicate_id
+    FROM public.categories c
+    JOIN keepers k ON k.user_id = c.user_id AND k.lower_name = LOWER(c.category_name)
+    WHERE c.id != k.keeper_id
+)
+DELETE FROM public.categories
+WHERE id IN (SELECT duplicate_id FROM duplicates);
+
+-- 1.5 Post-migration verification for categories
+DO $$
+DECLARE
+    v_remaining_duplicates int;
+BEGIN
+    SELECT COUNT(*) INTO v_remaining_duplicates
+    FROM (
+        SELECT user_id, LOWER(category_name) as lower_name
+        FROM public.categories
+        GROUP BY user_id, LOWER(category_name)
+        HAVING COUNT(*) > 1
+    ) dups;
+
+    IF v_remaining_duplicates > 0 THEN
+        RAISE EXCEPTION 'Category merge failed: % duplicate groups still exist. Rolling back.', v_remaining_duplicates;
+    END IF;
+
+    RAISE NOTICE 'Categories: All duplicates merged successfully';
+END $$;
+
+-- ============================================================================
+-- PART 2: Merge duplicate tags
+-- ============================================================================
+
+-- 2.1 Pre-flight: Log duplicate tag count
+DO $$
+DECLARE
+    v_duplicate_groups int;
+    v_total_duplicates int;
+BEGIN
+    -- Count groups that have duplicates
+    SELECT COUNT(*) INTO v_duplicate_groups
+    FROM (
+        SELECT user_id, LOWER(name) as lower_name
+        FROM public.tags
+        GROUP BY user_id, LOWER(name)
+        HAVING COUNT(*) > 1
+    ) dups;
+
+    -- Count total duplicate entries (entries that will be removed)
+    SELECT COALESCE(SUM(cnt - 1), 0) INTO v_total_duplicates
+    FROM (
+        SELECT user_id, LOWER(name) as lower_name, COUNT(*) as cnt
+        FROM public.tags
+        GROUP BY user_id, LOWER(name)
+        HAVING COUNT(*) > 1
+    ) dups;
+
+    RAISE NOTICE 'Tags: Found % duplicate groups with % total entries to merge', v_duplicate_groups, v_total_duplicates;
+END $$;
+
+-- 2.2 Reassign bookmark_tags from duplicates to keepers
+-- Uses CTE to identify keepers (most bookmarks, tie-break by lowest id)
+WITH tag_bookmark_counts AS (
+    SELECT
+        t.id,
+        t.user_id,
+        LOWER(t.name) as lower_name,
+        COUNT(bt.bookmark_id) as bookmark_count
+    FROM public.tags t
+    LEFT JOIN public.bookmark_tags bt ON bt.tag_id = t.id
+    GROUP BY t.id, t.user_id, LOWER(t.name)
+),
+keepers AS (
+    SELECT DISTINCT ON (user_id, lower_name)
+        id as keeper_id,
+        user_id,
+        lower_name
+    FROM tag_bookmark_counts
+    ORDER BY user_id, lower_name, bookmark_count DESC, id ASC
+),
+duplicates AS (
+    SELECT t.id as duplicate_id, k.keeper_id
+    FROM public.tags t
+    JOIN keepers k ON k.user_id = t.user_id AND k.lower_name = LOWER(t.name)
+    WHERE t.id != k.keeper_id
+)
+-- Update bookmark_tags: point duplicates to keepers
+-- ON CONFLICT DO NOTHING handles case where keeper already has that bookmark
+INSERT INTO public.bookmark_tags (bookmark_id, tag_id, user_id, created_at)
+SELECT bt.bookmark_id, d.keeper_id, bt.user_id, bt.created_at
+FROM public.bookmark_tags bt
+JOIN duplicates d ON bt.tag_id = d.duplicate_id
+ON CONFLICT (bookmark_id, tag_id) DO NOTHING;
+
+-- 2.3 Delete bookmark_tags entries pointing to duplicates (now reassigned)
+WITH tag_bookmark_counts AS (
+    SELECT
+        t.id,
+        t.user_id,
+        LOWER(t.name) as lower_name,
+        COUNT(bt.bookmark_id) as bookmark_count
+    FROM public.tags t
+    LEFT JOIN public.bookmark_tags bt ON bt.tag_id = t.id
+    GROUP BY t.id, t.user_id, LOWER(t.name)
+),
+keepers AS (
+    SELECT DISTINCT ON (user_id, lower_name)
+        id as keeper_id,
+        user_id,
+        lower_name
+    FROM tag_bookmark_counts
+    ORDER BY user_id, lower_name, bookmark_count DESC, id ASC
+),
+duplicates AS (
+    SELECT t.id as duplicate_id
+    FROM public.tags t
+    JOIN keepers k ON k.user_id = t.user_id AND k.lower_name = LOWER(t.name)
+    WHERE t.id != k.keeper_id
+)
+DELETE FROM public.bookmark_tags
+WHERE tag_id IN (SELECT duplicate_id FROM duplicates);
+
+-- 2.4 Delete duplicate tags (keeping the keeper)
+WITH tag_bookmark_counts AS (
+    SELECT
+        t.id,
+        t.user_id,
+        LOWER(t.name) as lower_name,
+        COUNT(bt.bookmark_id) as bookmark_count
+    FROM public.tags t
+    LEFT JOIN public.bookmark_tags bt ON bt.tag_id = t.id
+    GROUP BY t.id, t.user_id, LOWER(t.name)
+),
+keepers AS (
+    SELECT DISTINCT ON (user_id, lower_name)
+        id as keeper_id,
+        user_id,
+        lower_name
+    FROM tag_bookmark_counts
+    ORDER BY user_id, lower_name, bookmark_count DESC, id ASC
+),
+duplicates AS (
+    SELECT t.id as duplicate_id
+    FROM public.tags t
+    JOIN keepers k ON k.user_id = t.user_id AND k.lower_name = LOWER(t.name)
+    WHERE t.id != k.keeper_id
+)
+DELETE FROM public.tags
+WHERE id IN (SELECT duplicate_id FROM duplicates);
+
+-- 2.5 Post-migration verification for tags
+DO $$
+DECLARE
+    v_remaining_duplicates int;
+BEGIN
+    SELECT COUNT(*) INTO v_remaining_duplicates
+    FROM (
+        SELECT user_id, LOWER(name) as lower_name
+        FROM public.tags
+        GROUP BY user_id, LOWER(name)
+        HAVING COUNT(*) > 1
+    ) dups;
+
+    IF v_remaining_duplicates > 0 THEN
+        RAISE EXCEPTION 'Tag merge failed: % duplicate groups still exist. Rolling back.', v_remaining_duplicates;
+    END IF;
+
+    RAISE NOTICE 'Tags: All duplicates merged successfully';
+END $$;
+
+-- ============================================================================
+-- PART 3: Create case-insensitive unique indexes
+-- ============================================================================
+
+-- 3.1 Create case-insensitive unique index for categories
+-- Prevents "Test" and "test" from existing for the same user
+CREATE UNIQUE INDEX IF NOT EXISTS unique_user_category_name_ci
+    ON public.categories (user_id, LOWER(category_name));
+
+COMMENT ON INDEX public.unique_user_category_name_ci IS
+'Case-insensitive unique constraint ensuring users cannot create duplicate category names that differ only by case (e.g., "Test" and "test").';
+
+-- 3.2 Create case-insensitive unique index for tags
+-- Prevents "JavaScript" and "javascript" from existing for the same user
+CREATE UNIQUE INDEX IF NOT EXISTS unique_user_tag_name_ci
+    ON public.tags (user_id, LOWER(name));
+
+COMMENT ON INDEX public.unique_user_tag_name_ci IS
+'Case-insensitive unique constraint ensuring users cannot create duplicate tag names that differ only by case (e.g., "JavaScript" and "javascript").';
+
+COMMIT;
diff --git a/supabase/migrations/20251231200324_create_and_assign_tag_rpc.sql b/supabase/migrations/20251231200324_create_and_assign_tag_rpc.sql
new file mode 100644
index 00000000..28c2c8da
--- /dev/null
+++ b/supabase/migrations/20251231200324_create_and_assign_tag_rpc.sql
@@ -0,0 +1,89 @@
+-- ============================================================================
+-- MIGRATION: Create atomic create_and_assign_tag RPC function
+-- Created: 2025-12-31
+-- Purpose: Atomically create a tag and assign it to a bookmark in a single transaction
+-- ============================================================================
+--
+-- This migration:
+--   1. Creates create_and_assign_tag RPC with FOR UPDATE locking
+--   2. Verifies bookmark ownership before creating tag (prevents orphaned tags)
+--   3. Returns both created records for client-side cache updates
+--
+-- ============================================================================
+
+BEGIN;
+SET search_path = public, pg_temp;
+
+-- Atomic function to create a tag and assign it to a bookmark
+-- Unlike set_bookmark_categories which only modifies junction tables,
+-- this function creates a NEW entity (tag) before the junction insert.
+-- Therefore, we MUST verify ownership in the RPC to prevent orphaned tags
+-- if the bookmark_tags insert fails.
+CREATE OR REPLACE FUNCTION public.create_and_assign_tag(
+  p_bookmark_id bigint,
+  p_tag_name text
+)
+RETURNS TABLE(
+  tag_id bigint,
+  tag_name text,
+  tag_user_id uuid,
+  tag_created_at timestamptz,
+  bookmark_tag_id bigint,
+  bookmark_tag_bookmark_id bigint,
+  bookmark_tag_tag_id bigint,
+  bookmark_tag_user_id uuid,
+  bookmark_tag_created_at timestamptz
+)
+LANGUAGE plpgsql
+SECURITY INVOKER
+SET search_path = public, pg_temp
+AS $$
+DECLARE
+  v_user_id uuid := (SELECT auth.uid());
+  v_tag_record record;
+  v_bookmark_tag_record record;
+BEGIN
+  -- Step 1: Verify bookmark ownership with FOR UPDATE lock
+  -- This is critical: we must verify BEFORE creating the tag to prevent orphaned tags
+  PERFORM 1 FROM public.everything
+  WHERE id = p_bookmark_id AND user_id = v_user_id
+  FOR UPDATE;
+
+  IF NOT FOUND THEN
+    RAISE EXCEPTION 'Bookmark not found or not owned by user'
+      USING ERRCODE = '42501'; -- insufficient_privilege
+  END IF;
+
+  -- Step 2: Insert tag (will fail on duplicate name via unique constraint)
+  INSERT INTO public.tags (name, user_id)
+  VALUES (p_tag_name, v_user_id)
+  RETURNING * INTO v_tag_record;
+
+  -- Step 3: Insert bookmark_tag junction
+  INSERT INTO public.bookmark_tags (bookmark_id, tag_id, user_id)
+  VALUES (p_bookmark_id, v_tag_record.id, v_user_id)
+  RETURNING * INTO v_bookmark_tag_record;
+
+  -- Return both records as a flat row
+  RETURN QUERY SELECT
+    v_tag_record.id,
+    v_tag_record.name,
+    v_tag_record.user_id,
+    v_tag_record.created_at,
+    v_bookmark_tag_record.id,
+    v_bookmark_tag_record.bookmark_id,
+    v_bookmark_tag_record.tag_id,
+    v_bookmark_tag_record.user_id,
+    v_bookmark_tag_record.created_at;
+END;
+$$;
+
+-- Permissions: Only authenticated users can call this function
+REVOKE EXECUTE ON FUNCTION public.create_and_assign_tag(bigint, text) FROM PUBLIC;
+REVOKE EXECUTE ON FUNCTION public.create_and_assign_tag(bigint, text) FROM anon;
+GRANT EXECUTE ON FUNCTION public.create_and_assign_tag(bigint, text) TO authenticated;
+
+COMMENT ON FUNCTION public.create_and_assign_tag IS
+'Atomically creates a tag and assigns it to a bookmark in a single transaction. Uses FOR UPDATE locking to prevent race conditions. Verifies bookmark ownership before creating tag to prevent orphaned tags. Both operations succeed or both fail.';
+
+COMMIT;
diff --git a/supabase/migrations/20260105000100_add_discover_changes.sql b/supabase/migrations/20260105000100_add_discover_changes.sql
new file mode 100644
index 00000000..a72a736a
--- /dev/null
+++ b/supabase/migrations/20260105000100_add_discover_changes.sql
@@ -0,0 +1,280 @@
+-- ============================================================================
+-- MIGRATION: Add discoverability feature for bookmarks
+-- Created: 2026-01-05
+-- Purpose: Enable bookmarks to be publicly discoverable via make_discoverable column
+-- ============================================================================
+--
+-- This migration:
+--   1. Adds make_discoverable column to everything table
+--   2. Updates search_bookmarks_url_tag_scope RPC to return new column
+--   3. Creates RLS policies for anonymous and authenticated discover access
+--
+-- NOTE: Indexes are intentionally not created here to avoid table locks.
+-- Add indexes later if performance monitoring shows need.
+--
+-- ============================================================================
+
+BEGIN;
+SET search_path = public, pg_temp;
+
+-- ============================================================================
+-- PART 1: Add make_discoverable column
+-- ============================================================================
+
+-- 1. Add make_discoverable column to everything table
+-- NULL means not discoverable, timestamp means when it was made discoverable
+-- Users can explicitly set this to a timestamp for bookmarks they want to make public
+ALTER TABLE "public"."everything"
+ADD COLUMN IF NOT EXISTS "make_discoverable" timestamp with time zone DEFAULT NULL;
+
+COMMENT ON COLUMN "public"."everything"."make_discoverable" IS
+'Controls whether this bookmark is publicly discoverable. When NOT NULL and trash is false, the bookmark is visible to anonymous/public users via the public_discover_access RLS policy. The timestamp indicates when the bookmark was made discoverable.';
+
+-- ============================================================================
+-- PART 2: Update search function
+-- ============================================================================
+
+-- 1. Update search_bookmarks_url_tag_scope function to include make_discoverable in RETURNS TABLE
+-- Need to DROP first because PostgreSQL doesn't allow changing return type with CREATE OR REPLACE
+SET check_function_bodies = off;
+
+DROP FUNCTION IF EXISTS public.search_bookmarks_url_tag_scope(character varying, character varying, text[], bigint);
+
+-- 2. Create updated function with make_discoverable column
+-- NOTE: Uses `extensions` in search_path instead of `pg_temp` because
+-- the function returns `extensions.citext` type which requires access to that schema
+CREATE FUNCTION public.search_bookmarks_url_tag_scope(
+    search_text character varying DEFAULT '',
+    url_scope character varying DEFAULT '',
+    tag_scope text[] DEFAULT NULL,
+    category_scope bigint DEFAULT NULL
+)
+RETURNS TABLE(
+    id bigint,
+    user_id uuid,
+    inserted_at timestamp with time zone,
+    title extensions.citext,
+    url text,
+    description text,
+    ogimage text,
+    screenshot text,
+    trash boolean,
+    type text,
+    meta_data jsonb,
+    sort_index text,
+    added_tags jsonb,
+    added_categories jsonb,
+    make_discoverable timestamp with time zone
+)
+LANGUAGE plpgsql
+VOLATILE
+SECURITY INVOKER
+SET search_path = public, extensions
+AS $function$
+BEGIN
+    SET LOCAL pg_trgm.similarity_threshold = 0.6;
+
+    RETURN QUERY
+    WITH
+    -- Pre-aggregate tags (single pass, avoids N+1)
+    bookmark_tags_agg AS (
+        SELECT
+            bt.bookmark_id,
+            bt.user_id,
+            jsonb_agg(jsonb_build_object('id', t.id, 'name', t.name)) AS tags_json
+        FROM public.bookmark_tags bt
+        JOIN public.tags t ON t.id = bt.tag_id
+        GROUP BY bt.bookmark_id, bt.user_id
+    ),
+    -- Pre-aggregate categories (single pass, avoids N+1)
+    bookmark_cats_agg AS (
+        SELECT
+            bc.bookmark_id,
+            bc.user_id,
+            jsonb_agg(
+                jsonb_build_object(
+                    'id', c.id,
+                    'category_name', c.category_name,
+                    'category_slug', c.category_slug,
+                    'icon', c.icon,
+                    'icon_color', c.icon_color
+                )
+                ORDER BY bc.created_at ASC
+            ) AS categories_json
+        FROM public.bookmark_categories bc
+        JOIN public.categories c ON c.id = bc.category_id
+        GROUP BY bc.bookmark_id, bc.user_id
+    )
+    SELECT
+        b.id,
+        b.user_id,
+        b.inserted_at,
+        b.title,
+        b.url,
+        b.description,
+        b."ogImage",
+        b.screenshot,
+        b.trash,
+        b.type,
+        b.meta_data,
+        b.sort_index,
+        COALESCE(bta.tags_json, '[]'::jsonb) AS added_tags,
+        COALESCE(bca.categories_json, '[]'::jsonb) AS added_categories,
+        b.make_discoverable
+    FROM public.everything b
+    LEFT JOIN bookmark_tags_agg bta ON bta.bookmark_id = b.id AND bta.user_id = b.user_id
+    LEFT JOIN bookmark_cats_agg bca ON bca.bookmark_id = b.id AND bca.user_id = b.user_id
+    WHERE
+        -- URL scope filter (optional)
+        (
+            url_scope IS NULL
+            OR url_scope = ''
+            OR b.url ILIKE '%' || url_scope || '%'
+        )
+
+        AND
+        -- Tag scope filter (optional, supports multiple tags with AND logic)
+        (
+            tag_scope IS NULL
+            OR array_length(tag_scope, 1) IS NULL
+            OR (
+                SELECT COUNT(DISTINCT LOWER(t.name))
+                FROM public.bookmark_tags bt
+                JOIN public.tags t ON t.id = bt.tag_id
+                WHERE bt.bookmark_id = b.id
+                  AND LOWER(t.name) = ANY(
+                      SELECT LOWER(unnest(tag_scope))
+                  )
+            ) = array_length(tag_scope, 1)  -- Must match ALL searched tags (AND logic)
+        )
+
+        AND
+        -- Category scope filter via junction table (optional)
+        (
+            category_scope IS NULL
+            OR EXISTS (
+                SELECT 1
+                FROM public.bookmark_categories bc
+                WHERE bc.bookmark_id = b.id
+                  AND bc.category_id = category_scope
+            )
+        )
+
+        AND
+        -- Main search_text logic (optional)
+        (
+            search_text IS NULL
+            OR search_text = ''
+            OR (
+                search_text % ANY(STRING_TO_ARRAY(COALESCE(b.title::text, '') || ' ' || COALESCE(b.description, ''), ' '))
+                OR b.url ILIKE '%' || search_text || '%'
+                OR EXISTS (
+                    SELECT 1
+                    FROM jsonb_each_text(COALESCE(b.meta_data, '{}'::jsonb)) AS x(key, value)
+                    WHERE key IN ('img_caption', 'ocr')
+                      AND value ILIKE '%' || search_text || '%'
+                )
+            )
+        )
+
+    ORDER BY
+        CASE
+            WHEN search_text IS NULL OR search_text = '' THEN 0
+            ELSE (
+                similarity(COALESCE(b.url, ''), search_text) * 0.6 +
+                similarity(COALESCE(b.title::text, ''), search_text) * 0.5 +
+                similarity(COALESCE(b.description, ''), search_text) * 0.3 +
+                similarity(COALESCE(b.meta_data->>'ocr', ''), search_text) * 0.1 +
+                similarity(COALESCE(b.meta_data->>'img_caption', ''), search_text) * 0.15
+            )
+        END DESC,
+        b.inserted_at DESC;
+END;
+$function$;
+
+RESET check_function_bodies;
+
+-- 3. Set permissions (maintain existing access pattern)
+REVOKE EXECUTE ON FUNCTION public.search_bookmarks_url_tag_scope(character varying, character varying, text[], bigint) FROM PUBLIC;
+GRANT EXECUTE ON FUNCTION public.search_bookmarks_url_tag_scope(character varying, character varying, text[], bigint) TO authenticated;
+GRANT EXECUTE ON FUNCTION public.search_bookmarks_url_tag_scope(character varying, character varying, text[], bigint) TO anon;
+
+-- 4. Add function documentation
+COMMENT ON FUNCTION public.search_bookmarks_url_tag_scope(character varying, character varying, text[], bigint) IS
+'Bookmark search with URL/tag/category filters. Returns make_discoverable timestamp for discoverability feature. Uses CTEs to avoid N+1 queries when aggregating tags and categories.';
+
+-- ============================================================================
+-- PART 3: Create RLS policies
+-- ============================================================================
+
+-- 1. Drop existing policies if they exist
+DROP POLICY IF EXISTS "anon_discover_access" ON "public"."everything";
+DROP POLICY IF EXISTS "authenticated_discover_access" ON "public"."everything";
+
+-- 2. Policy for anonymous (unauthenticated) users
+CREATE POLICY "anon_discover_access"
+ON "public"."everything"
+AS permissive
+FOR SELECT
+TO anon
+USING (
+    make_discoverable IS NOT NULL
+    AND trash = false
+);
+
+COMMENT ON POLICY "anon_discover_access" ON public.everything IS
+'Allows anonymous (unauthenticated) users to read bookmarks marked as discoverable and not in trash.';
+
+-- 3. Policy for authenticated users
+CREATE POLICY "authenticated_discover_access"
+ON "public"."everything"
+AS permissive
+FOR SELECT
+TO authenticated
+USING (
+    make_discoverable IS NOT NULL
+    AND trash = false
+);
+
+COMMENT ON POLICY "authenticated_discover_access" ON public.everything IS
+'Allows authenticated users to read bookmarks marked as discoverable and not in trash.';
+
+-- ============================================================================
+-- PART 4: Post-migration verification
+-- ============================================================================
+
+DO $$
+BEGIN
+    -- Verify column was added
+    IF NOT EXISTS (
+        SELECT 1 FROM information_schema.columns
+        WHERE table_schema = 'public'
+          AND table_name = 'everything'
+          AND column_name = 'make_discoverable'
+    ) THEN
+        RAISE EXCEPTION 'Migration failed: make_discoverable column not created';
+    END IF;
+
+    -- Verify policies were created
+    IF NOT EXISTS (
+        SELECT 1 FROM pg_policies
+        WHERE schemaname = 'public'
+          AND tablename = 'everything'
+          AND policyname = 'anon_discover_access'
+    ) THEN
+        RAISE EXCEPTION 'Migration failed: anon_discover_access policy not created';
+    END IF;
+
+    IF NOT EXISTS (
+        SELECT 1 FROM pg_policies
+        WHERE schemaname = 'public'
+          AND tablename = 'everything'
+          AND policyname = 'authenticated_discover_access'
+    ) THEN
+        RAISE EXCEPTION 'Migration failed: authenticated_discover_access policy not created';
+    END IF;
+
+    RAISE NOTICE 'Migration verified: make_discoverable column and RLS policies created successfully';
+END $$;
+
+COMMIT;
